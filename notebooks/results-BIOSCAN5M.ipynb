{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnxDlvP8szOj"
   },
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9BelQPaJVo2"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn\n",
    "import sklearn.metrics\n",
    "import torchvision.datasets\n",
    "import wandb\n",
    "from IPython.display import display\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIGS_DIR = \"figs\"\n",
    "os.makedirs(FIGS_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AH-GlrfS4Pf"
   },
   "outputs": [],
   "source": [
    "VALIDATION_DATASETS = [\"imagenet\", \"imagenette\", \"imagewoof\"]\n",
    "RESNET50_MODELS = [\n",
    "    # \"random_resnet50\",\n",
    "    \"resnet50\",\n",
    "    \"mocov3_resnet50\",\n",
    "    \"dino_resnet50\",\n",
    "    \"vicreg_resnet50\",\n",
    "    \"clip_RN50\",\n",
    "]\n",
    "VITB16_MODELS = [\n",
    "    # \"random_vitb16\",\n",
    "    \"vitb16\",\n",
    "    \"mocov3_vit_base\",\n",
    "    \"dino_vitb16\",\n",
    "    \"timm_vit_base_patch16_224.mae\",\n",
    "    \"mae_pretrain_vit_base_global\",\n",
    "    \"clip_vitb16\",\n",
    "]\n",
    "FT_RESNET50_MODELS = [\n",
    "    \"ft_mocov3_resnet50\",\n",
    "    \"ft_dino_resnet50\",\n",
    "    \"ft_vicreg_resnet50\",\n",
    "]\n",
    "FT_VITB16_MODELS = [\n",
    "    \"ft_mocov3_vit_base\",\n",
    "    \"ft_dino_vitb16\",\n",
    "    \"mae_finetuned_vit_base_global\",\n",
    "]\n",
    "FT_MODELS = FT_RESNET50_MODELS + FT_VITB16_MODELS\n",
    "ALL_MODELS = RESNET50_MODELS + VITB16_MODELS + FT_RESNET50_MODELS + FT_VITB16_MODELS\n",
    "\n",
    "RESNET50_MODELS_INTERLEAVED = [\n",
    "    \"random_resnet50\",\n",
    "    \"resnet50\",\n",
    "    \"mocov3_resnet50\",\n",
    "    \"ft_mocov3_resnet50\",\n",
    "    \"dino_resnet50\",\n",
    "    \"ft_dino_resnet50\",\n",
    "    \"vicreg_resnet50\",\n",
    "    \"ft_vicreg_resnet50\",\n",
    "]\n",
    "VITB16_MODELS_INTERLEAVED = [\n",
    "    \"random_vitb16\",\n",
    "    \"vitb16\",\n",
    "    \"mocov3_vit_base\",\n",
    "    \"ft_mocov3_vit_base\",\n",
    "    \"dino_vitb16\",\n",
    "    \"ft_dino_vitb16\",\n",
    "    \"timm_vit_base_patch16_224.mae\",\n",
    "    \"mae_pretrain_vit_base_global\",\n",
    "    \"mae_finetuned_vit_base_global\",\n",
    "]\n",
    "\n",
    "DNA_MODELS = [\n",
    "    \"barcodebert\",\n",
    "    \"dnabert-2\",\n",
    "    \"dnabert-s\",\n",
    "    \"hyenadna\",\n",
    "    \"NucleotideTransformer\",\n",
    "]\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"LouvainCommunities\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"SpectralClustering\",\n",
    "    \"HDBSCAN\",\n",
    "    \"OPTICS\",\n",
    "]\n",
    "ALL_CLUSTERERS = copy.deepcopy(CLUSTERERS)\n",
    "DISTANCE_METRICS = [\n",
    "    \"euclidean\",\n",
    "    \"l1\",\n",
    "    \"chebyshev\",\n",
    "    \"cosine\",\n",
    "    \"arccos\",\n",
    "    \"braycurtis\",\n",
    "    \"canberra\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE2FT = {\n",
    "    k: \"ft_\" + k\n",
    "    for k in [\n",
    "        \"mocov3_resnet50\",\n",
    "        \"dino_resnet50\",\n",
    "        \"vicreg_resnet50\",\n",
    "        \"mocov3_vit_base\",\n",
    "        \"dino_vitb16\",\n",
    "    ]\n",
    "}\n",
    "PRE2FT[\"mae_pretrain_vit_base_global\"] = \"mae_finetuned_vit_base_global\"\n",
    "FT2PRE = {v: k for k, v in PRE2FT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mJrqF3FAbEG"
   },
   "outputs": [],
   "source": [
    "DATASET2LS = {\n",
    "    \"imagenet\": \"-.\",\n",
    "    \"imagenette\": \"--\",\n",
    "    \"imagewoof\": \":\",\n",
    "}\n",
    "ARCH2MARKER = {\n",
    "    \"ResNet-50\": \"s\",\n",
    "    \"ViT-B\": \"^\",\n",
    "    \"none\": \"o\",\n",
    "}\n",
    "ARCH2LS = {\n",
    "    \"ResNet-50\": \"-\",\n",
    "    \"ViT-B\": \"-\",\n",
    "    \"none\": \":\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqPoCd4kbokG"
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    \"all\": {\n",
    "        \"dim_reducer\": \"None\",\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "        \"zscore\": False,\n",
    "        \"normalize\": False,\n",
    "        \"zscore2\": False,\n",
    "        \"ndim_correction\": False,\n",
    "    },\n",
    "    \"AgglomerativeClustering\": {\n",
    "        \"clusterer\": \"AgglomerativeClustering\",\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "        \"aggclust_linkage\": \"ward\",\n",
    "        \"dim_reducer_man\": \"UMAP\",\n",
    "        \"ndim_reduced_man\": 50,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "BEST_PARAMS = {\n",
    "    clusterer: {model: copy.deepcopy(DEFAULT_PARAMS[clusterer]) for model in models} for clusterer in [\"AgglomerativeClustering\"]\n",
    "}\n",
    "BEST_PARAMS[\"_version\"] = \"recommended\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSVZM4cns-gm"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w21wu6JUk4d"
   },
   "outputs": [],
   "source": [
    "def categorical_cmap(nc, nsc, cmap=\"tab10\", continuous=False):\n",
    "    \"\"\"\n",
    "    Create a colormap with a certain number of shades of colours.\n",
    "\n",
    "    Based on https://stackoverflow.com/a/47232942/1960959\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nc : int\n",
    "        Number of categories.\n",
    "    nsc : int\n",
    "        Number of shades per category.\n",
    "    cmap : str, default=tab10\n",
    "        Original colormap to extend into multiple shades.\n",
    "    continuous : bool, default=False\n",
    "        Whether ``cmap`` is continous. Otherwise it is treated\n",
    "        as categorical with adjacent colors unrelated.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.colors.ListedColormap\n",
    "        New cmap which alternates between ``nsc`` shades of ``nc``\n",
    "        colors from ``cmap``.\n",
    "    \"\"\"\n",
    "    if nc > plt.get_cmap(cmap).N:\n",
    "        raise ValueError(\"Too many categories for colormap.\")\n",
    "    if continuous:\n",
    "        ccolors = plt.get_cmap(cmap)(np.linspace(0, 1, nc))\n",
    "    else:\n",
    "        ccolors = plt.get_cmap(cmap)(np.arange(nc, dtype=int))\n",
    "    cols = np.zeros((nc * nsc, 3))\n",
    "    for i, c in enumerate(ccolors):\n",
    "        chsv = matplotlib.colors.rgb_to_hsv(c[:3])\n",
    "        arhsv = np.tile(chsv, nsc).reshape(nsc, 3)\n",
    "        arhsv[:, 1] = np.linspace(chsv[1], 0.25, nsc)\n",
    "        arhsv[:, 2] = np.linspace(chsv[2], 1, nsc)\n",
    "        rgb = matplotlib.colors.hsv_to_rgb(arhsv)\n",
    "        cols[i * nsc : (i + 1) * nsc, :] = rgb\n",
    "    cmap = matplotlib.colors.ListedColormap(cols)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "Zt-xAviSUwWV",
    "outputId": "0feb0c9b-c97d-4ec7-955f-8fdcc521be3c"
   },
   "outputs": [],
   "source": [
    "categorical_cmap(len(RESNET50_MODELS), len(VALIDATION_DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zs_ssl_clustering.datasets import image_dataset_sizes\n",
    "\n",
    "\n",
    "def clip_imgsize(dataset, target_image_size):\n",
    "    if target_image_size is None:\n",
    "        return target_image_size\n",
    "    dataset_imsize = image_dataset_sizes(dataset)[1]\n",
    "    if dataset_imsize is None:\n",
    "        return target_image_size\n",
    "    if hasattr(dataset_imsize, \"__len__\"):\n",
    "        dataset_imsize = min(dataset_imsize)\n",
    "    return min(target_image_size, dataset_imsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixup_filter(filters):\n",
    "    dataset = filters.get(\"dataset_name\", filters.get(\"dataset\", None))\n",
    "    if dataset and \"image_size\" in filters:\n",
    "        filters[\"image_size\"] = clip_imgsize(dataset, filters[\"image_size\"])\n",
    "    if dataset and \"min_samples\" in filters:\n",
    "        if dataset.lower() in [\"celeba\", \"utkface\", \"bioscan1m\"]:\n",
    "            filters[\"min_samples\"] = 2\n",
    "    return filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5hY2oc2I-PO"
   },
   "outputs": [],
   "source": [
    "def select_rows(df, filters, allow_missing=True, fixup=True):\n",
    "    if fixup:\n",
    "        filters = fixup_filter(filters)\n",
    "    select = np.ones(len(df), dtype=bool)\n",
    "    for col, val in filters.items():\n",
    "        if col == \"dataset\":\n",
    "            col = \"dataset_name\"\n",
    "        if col == \"clusterer\":\n",
    "            col = \"clusterer_name\"\n",
    "        if val is None or val == \"None\" or val == \"none\":\n",
    "            select_i = pd.isna(df[col])\n",
    "            select_i |= df[col] == \"None\"\n",
    "            select_i |= df[col] == \"none\"\n",
    "        else:\n",
    "            select_i = df[col] == val\n",
    "            select_i |= df[col] == str(val)\n",
    "            if allow_missing or val == \"None\" or val == \"none\":\n",
    "                select_i |= pd.isna(df[col])\n",
    "        select &= select_i\n",
    "    return df[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iOVrUnC_Jg-"
   },
   "outputs": [],
   "source": [
    "def find_differing_columns(df, cols=None):\n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "    my_cols = []\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        if df[col].nunique(dropna=False) > 1:\n",
    "            my_cols.append(col)\n",
    "    return my_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI7MkSQiz89O"
   },
   "outputs": [],
   "source": [
    "def filter2command(*filters, partition=\"val\"):\n",
    "    f = {}\n",
    "    for filter in filters:\n",
    "        for k, v in filter.items():\n",
    "            f[k] = v\n",
    "    dataset = f.get(\"dataset\", \"\")\n",
    "    clusterer = f.get(\"clusterer\", \"\")\n",
    "\n",
    "    mem = 2  # RAM in gigabytes\n",
    "\n",
    "    if clusterer in [\"LouvainCommunities\"]:\n",
    "        if dataset in [\"inaturalist\"]:\n",
    "            # 100,000 samples\n",
    "            mem = 3_700\n",
    "        elif dataset in [\"imagenet-sketch\", \"imagenet\"]:\n",
    "            # 50,000 samples\n",
    "            mem = 926\n",
    "        elif dataset in [\"places365\"]:\n",
    "            # 36,500 samples\n",
    "            mem = 494\n",
    "        elif dataset in [\"imagenet-r\"]:\n",
    "            # 30,000 samples\n",
    "            mem = 333\n",
    "        elif dataset in [\"svhn\"]:\n",
    "            # 26,000 samples\n",
    "            mem = 250\n",
    "        elif dataset in [\"bioscan1m\", \"nabirds\"]:\n",
    "            # 24,600 samples\n",
    "            mem = 224\n",
    "        elif dataset in [\"celeba\"]:\n",
    "            # 20,000 samples\n",
    "            mem = 128\n",
    "        elif dataset in [\n",
    "            \"imagenetv2\",\n",
    "            \"cifar10\",\n",
    "            \"cifar100\",\n",
    "            \"lsun\",\n",
    "            \"mnist\",\n",
    "            \"fashionmnist\",\n",
    "            \"stanfordcars\",\n",
    "            \"breakhis\",\n",
    "        ]:\n",
    "            # 8,000 - 10,000 samples\n",
    "            mem = 32\n",
    "        elif dataset in [\"flowers102\", \"utkface\"]:\n",
    "            # 5,925 - 6,200 samples\n",
    "            mem = 18\n",
    "        elif dataset.startswith(\"in9\") or dataset in [\"eurosat\"]:\n",
    "            # 4,500 samples\n",
    "            mem = 8\n",
    "        elif dataset in [\"imagenette\", \"imagewoof\", \"aircraft\"]:\n",
    "            # 3,333 - 3,930 samples\n",
    "            mem = 6\n",
    "        elif dataset in [\"imagenet-o\", \"dtd\"]:\n",
    "            # 2,000 samples\n",
    "            mem = 4\n",
    "        else:\n",
    "            mem = 12\n",
    "\n",
    "    elif clusterer in [\"AffinityPropagation\"]:\n",
    "        if dataset in [\"inaturalist\"]:\n",
    "            # 100,000 samples\n",
    "            mem = 292\n",
    "        elif dataset in [\"imagenet-sketch\", \"imagenet\"]:\n",
    "            # 50,000 samples\n",
    "            mem = 72\n",
    "        elif dataset in [\"places365\", \"imagenet-r\", \"svhn\", \"bioscan1m\", \"nabirds\"]:\n",
    "            # 24,600 - 36,500 samples\n",
    "            mem = 48\n",
    "        elif dataset in [\"celeba\"]:\n",
    "            # 20,000 samples\n",
    "            mem = 12\n",
    "        elif dataset in [\n",
    "            \"imagenetv2\",\n",
    "            \"cifar10\",\n",
    "            \"cifar100\",\n",
    "            \"lsun\",\n",
    "            \"mnist\",\n",
    "            \"fashionmnist\",\n",
    "            \"stanfordcars\",\n",
    "        ]:\n",
    "            # 8,000 - 10,000 samples\n",
    "            mem = 6\n",
    "        elif dataset.startswith(\"in9\") or dataset in [\n",
    "            \"flowers102\",\n",
    "            \"utkface\",\n",
    "            \"eurosat\",\n",
    "            \"aircraft\",\n",
    "            \"breakhis\",\n",
    "            \"imagenet-o\",\n",
    "            \"dtd\",\n",
    "        ]:\n",
    "            # 1,900 - 6,200 samples\n",
    "            mem = 2\n",
    "        elif dataset in [\"imagenette\", \"imagewoof\"]:\n",
    "            # 3,930 samples\n",
    "            mem = 1\n",
    "        else:\n",
    "            mem = 8\n",
    "\n",
    "    elif clusterer in [\"AgglomerativeClustering\", \"SpectralClustering\"]:\n",
    "        if dataset in [\"inaturalist\"]:\n",
    "            # 100,000 samples\n",
    "            mem = 72\n",
    "        elif dataset in [\"imagenet-sketch\", \"imagenet\"]:\n",
    "            # 50,000 samples\n",
    "            mem = 20\n",
    "        elif dataset in [\"places365\", \"imagenet-r\", \"svhn\", \"bioscan1m\", \"nabirds\"]:\n",
    "            # 24,600 - 36,500 samples\n",
    "            mem = 16\n",
    "        elif dataset in [\"celeba\"]:\n",
    "            # 20,000 samples\n",
    "            mem = 12\n",
    "        elif dataset in [\n",
    "            \"imagenetv2\",\n",
    "            \"cifar10\",\n",
    "            \"cifar100\",\n",
    "            \"lsun\",\n",
    "            \"mnist\",\n",
    "            \"fashionmnist\",\n",
    "            \"stanfordcars\",\n",
    "        ]:\n",
    "            # 8,000 - 10,000 samples\n",
    "            mem = 6\n",
    "        elif dataset.startswith(\"in9\") or dataset in [\n",
    "            \"flowers102\",\n",
    "            \"utkface\",\n",
    "            \"eurosat\",\n",
    "            \"aircraft\",\n",
    "            \"breakhis\",\n",
    "            \"imagenet-o\",\n",
    "            \"dtd\",\n",
    "        ]:\n",
    "            # 1,900 - 6,200 samples\n",
    "            mem = 4\n",
    "        elif dataset in [\"imagenette\", \"imagewoof\"]:\n",
    "            # 3,930 samples\n",
    "            mem = 2\n",
    "        else:\n",
    "            mem = 8\n",
    "        if clusterer == \"SpectralClustering\":\n",
    "            snn = f.get(\"spectral_n_neighbors\", 100)\n",
    "            if snn <= 10:\n",
    "                mem = mem * 8 / 20\n",
    "            elif snn <= 20:\n",
    "                mem = mem * 3 / 4\n",
    "            mem = int(np.ceil(mem))\n",
    "\n",
    "    elif clusterer in [\"HDBSCAN\", \"KMeans\"]:\n",
    "        if dataset in [\"inaturalist\"]:\n",
    "            # 100,000 samples\n",
    "            mem = 6\n",
    "        elif dataset in [\"imagenet-sketch\", \"imagenet\"]:\n",
    "            # 50,000 samples\n",
    "            mem = 4\n",
    "        elif dataset in [\"places365\", \"imagenet-r\", \"svhn\", \"bioscan1m\", \"nabirds\"]:\n",
    "            # 24,600 - 36,500 samples\n",
    "            mem = 4\n",
    "        elif dataset in [\"celeba\"]:\n",
    "            # 20,000 samples\n",
    "            mem = 4\n",
    "        elif dataset in [\n",
    "            \"imagenetv2\",\n",
    "            \"cifar10\",\n",
    "            \"cifar100\",\n",
    "            \"lsun\",\n",
    "            \"mnist\",\n",
    "            \"fashionmnist\",\n",
    "            \"stanfordcars\",\n",
    "        ]:\n",
    "            # 8,000 - 10,000 samples\n",
    "            mem = 2\n",
    "        elif dataset.startswith(\"in9\") or dataset in [\n",
    "            \"flowers102\",\n",
    "            \"utkface\",\n",
    "            \"eurosat\",\n",
    "            \"aircraft\",\n",
    "            \"breakhis\",\n",
    "            \"imagenet-o\",\n",
    "            \"dtd\",\n",
    "        ]:\n",
    "            # 1,900 - 6,200 samples\n",
    "            mem = 2\n",
    "        elif dataset in [\"imagenette\", \"imagewoof\"]:\n",
    "            # 3,930 samples\n",
    "            mem = 1\n",
    "        else:\n",
    "            mem = 4\n",
    "\n",
    "    if mem > 300:\n",
    "        return \"\"\n",
    "    if mem > 129:\n",
    "        pass\n",
    "\n",
    "    mem = f\"{mem}G\"\n",
    "\n",
    "    if partition == \"val\":\n",
    "        seed = 100\n",
    "    elif partition == \"test\":\n",
    "        seed = 1\n",
    "    else:\n",
    "        seed = 0\n",
    "    s = (\n",
    "        f\"sbatch --array={seed} --mem={mem}\"\n",
    "        f' --job-name=\"zsc-{f.get(\"model\", \"\")}-{dataset}-{clusterer}\"'\n",
    "        f\" slurm/cluster.slrm --partition={partition}\"\n",
    "    )\n",
    "    for k, v in f.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k == \"zscore\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-zscore\"\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --zscore\"\n",
    "            continue\n",
    "        if k == \"normalize\":\n",
    "            if v == \"False\" or not v:\n",
    "                pass\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --normalize\"\n",
    "            continue\n",
    "        if k == \"zscore2\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-zscore2\"\n",
    "            elif v == \"average\":\n",
    "                s += \" --azscore2\"\n",
    "            elif v == \"standard\" or v:\n",
    "                s += \" --zscore2\"\n",
    "            continue\n",
    "        if k == \"ndim_correction\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-ndim-correction\"\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --ndim-correction\"\n",
    "            continue\n",
    "        if k == \"louvain_remove_self_loops\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --louvain-keep-self\"\n",
    "            elif v == \"True\" or v:\n",
    "                pass\n",
    "            continue\n",
    "        s += f\" --{k.replace('_', '-')}={v}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOKljXoMNGG7"
   },
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude CLIP from analysis\n",
    "# RESNET50_MODELS = [v for v in RESNET50_MODELS if not v.startswith(\"clip\")]\n",
    "# VITB16_MODELS = [v for v in VITB16_MODELS if not v.startswith(\"clip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CuPbp58ONv4Z"
   },
   "outputs": [],
   "source": [
    "TEST_DATASETS = [\n",
    "    \"bioscan5m\",\n",
    "]\n",
    "DATASET2SH = {\n",
    "    \"bioscan1m\": \"BS-5M\",\n",
    "}\n",
    "MODEL_GROUPS = {\n",
    "    \"ResNet-50\": RESNET50_MODELS,\n",
    "    \"ViT-B\": VITB16_MODELS,\n",
    "    \"ResNet-50 [FT]\": FT_RESNET50_MODELS,\n",
    "    \"ViT-B [FT]\": FT_VITB16_MODELS,\n",
    "    \"all\": ALL_MODELS,\n",
    "}\n",
    "MODEL2SH = {\n",
    "    None: r\"\\textit{DNA-only}\",\n",
    "    # \"none\": \"Raw image\",\n",
    "    \"random_resnet50\": \"Rand.\",  # \"Random\",\n",
    "    \"random_vitb16\": \"Rand.\",  # \"Random\",\n",
    "    \"resnet50\": \"X-Ent.\",\n",
    "    \"mocov3_resnet50\": \"MoCo-v3\",\n",
    "    \"dino_resnet50\": \"DINO\",\n",
    "    \"vicreg_resnet50\": \"VICReg\",\n",
    "    \"clip_RN50\": \"CLIP\",\n",
    "    \"vitb16\": \"X-Ent.\",\n",
    "    \"mocov3_vit_base\": \"MoCo-v3\",\n",
    "    \"dino_vitb16\": \"DINO\",\n",
    "    \"timm_vit_base_patch16_224.mae\": \"MAE (CLS)\",\n",
    "    \"mae_pretrain_vit_base_global\": \"MAE (avg)\",\n",
    "    \"clip_vitb16\": \"CLIP\",\n",
    "    \"ft_mocov3_resnet50\": \"MoCo-v3 [FT]\",\n",
    "    \"ft_dino_resnet50\": \"DINO [FT]\",\n",
    "    \"ft_vicreg_resnet50\": \"VICReg [FT]\",\n",
    "    \"ft_mocov3_vit_base\": \"MoCo-v3 [FT]\",\n",
    "    \"ft_dino_vitb16\": \"DINO [FT]\",\n",
    "    \"mae_finetuned_vit_base_global\": \"MAE (avg) [FT]\",\n",
    "}\n",
    "DNAMODEL2SH = {\n",
    "    None: r\"\\textit{Image-only}\",\n",
    "    \"barcodebert\": \"BarcodeBERT\",\n",
    "    \"dnabert-2\": \"DNABERT-2\",\n",
    "    \"dnabert-s\": \"DNABERT-S\",\n",
    "    \"hyenadna\": \"HyenaDNA\",\n",
    "    \"NucleotideTransformer\": \"NT\",\n",
    "}\n",
    "CLUSTERER2SH = {\n",
    "    \"KMeans\": \"K-Means\",\n",
    "    \"SpectralClustering\": \"Spectral\",\n",
    "    \"AffinityPropagation\": \"Affinity Prop\",\n",
    "    \"AgglomerativeClustering\": \"Agg.\",  # \"AC\",\n",
    "    \"AC w/ C\": \"AC w/  C\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL2ARCH = {}\n",
    "for k in RESNET50_MODELS + FT_RESNET50_MODELS:\n",
    "    MODEL2ARCH[k] = \"ResNet-50\"\n",
    "for k in VITB16_MODELS + FT_VITB16_MODELS:\n",
    "    MODEL2ARCH[k] = \"ViT-B\"\n",
    "\n",
    "MODEL2SH_ARCH = dict(MODEL2SH)\n",
    "for k, v in MODEL2SH.items():\n",
    "    if k is None:\n",
    "        MODEL2SH_ARCH[k] = v\n",
    "        continue\n",
    "    if \"resnet\" in k or \"RN50\" in k:\n",
    "        MODEL2SH_ARCH[k] = f\"ResNet-50 {v}\"\n",
    "    elif \"vit\" in k:\n",
    "        MODEL2SH_ARCH[k] = f\"ViT-B {v}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERER2COLORSTR = {\n",
    "    \"KMeans\": \"tab:purple\",\n",
    "    \"SpectralClustering\": \"tab:cyan\",\n",
    "    \"AC w/ C\": \"tab:red\",\n",
    "    \"AC w/o C\": \"tab:orange\",\n",
    "    \"AffinityPropagation\": \"tab:green\",\n",
    "    \"HDBSCAN\": \"tab:blue\",\n",
    "}\n",
    "CLUSTERER2COLORRGB = {k: matplotlib.colors.to_rgb(v) for k, v in CLUSTERER2COLORSTR.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL2COLORSTR = {\n",
    "    \"none\": \"black\",\n",
    "    \"random_resnet50\": \"dimgrey\",\n",
    "    \"random_vitb16\": \"dimgrey\",\n",
    "    \"resnet50\": \"tab:red\",\n",
    "    \"mocov3_resnet50\": \"tab:green\",\n",
    "    \"dino_resnet50\": \"tab:purple\",\n",
    "    \"vicreg_resnet50\": \"tab:orange\",\n",
    "    \"clip_RN50\": \"tab:olive\",\n",
    "    \"vitb16\": \"tab:red\",\n",
    "    \"mocov3_vit_base\": \"tab:green\",\n",
    "    \"dino_vitb16\": \"tab:purple\",\n",
    "    \"timm_vit_base_patch16_224.mae\": \"tab:blue\",\n",
    "    \"mae_pretrain_vit_base_global\": \"tab:brown\",\n",
    "    \"clip_vitb16\": \"tab:olive\",\n",
    "    \"mae_finetuned_vit_base_global\": \"tab:brown\",\n",
    "    \"barcodebert\": \"tab:brown\",\n",
    "    \"dnabert-2\": \"tab:orange\",\n",
    "    \"dnabert-s\": \"tab:red\",\n",
    "    \"hyenadna\": \"tab:cyan\",\n",
    "    \"NucleotideTransformer\": \"tab:green\",\n",
    "}\n",
    "MODEL2COLORRGB = {k: matplotlib.colors.to_rgb(v) for k, v in MODEL2COLORSTR.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in FT_MODELS:\n",
    "    MODEL2COLORRGB[model] = tuple(c * 0.8 for c in MODEL2COLORRGB[FT2PRE[model]])\n",
    "# for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "#     MODEL2COLORRGB[model] = tuple(1 - (1 - c) * 0.7 for c in MODEL2COLORRGB[model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS:\n",
    "    MODEL2COLORRGB[model] = tuple(1 - (1 - c) * 0.7 for c in MODEL2COLORRGB[model])\n",
    "for model in VITB16_MODELS:\n",
    "    MODEL2COLORRGB[model] = tuple(c * 0.8 for c in MODEL2COLORRGB[model])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRNXaeD-tWUo"
   },
   "source": [
    "## Fetch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df_long = pd.DataFrame({\"id\": []})\n",
    "config_keys = set()\n",
    "summary_keys = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous results from CSV file\n",
    "CSV_FNAME = \"test_runs_df.csv\"\n",
    "if os.path.isfile(CSV_FNAME):\n",
    "    pass\n",
    "    # runs_df_long = test_runs_df = pd.read_csv(CSV_FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dytOzTA3NMeF",
    "outputId": "19a7efdd-c32a-4f3d-c467-092870aba23e"
   },
   "outputs": [],
   "source": [
    "# Project is specified by <entity/project-name>\n",
    "api = wandb.Api(timeout=720)\n",
    "runs = api.runs(\n",
    "    \"uoguelph_mlrg/zs-ssl-clustering_BIOSCAN-5M_fixpth_fixDNA\",\n",
    "    filters={\n",
    "        \"state\": \"Finished\",\n",
    "    },\n",
    "    per_page=10_000,\n",
    ")\n",
    "len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(runs_df_long)} runs currently in dataframe\")\n",
    "rows_to_add = []\n",
    "existing_ids = set(runs_df_long[\"id\"].values)\n",
    "for run in tqdm(runs):\n",
    "    if run.id in existing_ids:\n",
    "        if len(rows_to_add) >= len(runs) - len(runs_df_long):\n",
    "            break\n",
    "        continue\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary = run.summary._json_dict\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config = {k: v for k, v in run.config.items() if not k.startswith(\"_\")}\n",
    "    # .name is the human-readable name of the run.\n",
    "    row = {\"id\": run.id, \"name\": run.name}\n",
    "    row.update({k: v for k, v in config.items() if not k.startswith(\"_\")})\n",
    "    row.update({k: v for k, v in summary.items()})\n",
    "    if \"_timestamp\" in summary:\n",
    "        row[\"_timestamp\"] = summary[\"_timestamp\"]\n",
    "    rows_to_add.append(row)\n",
    "    config_keys = config_keys.union(config.keys())\n",
    "    summary_keys = summary_keys.union(summary.keys())\n",
    "\n",
    "if not len(rows_to_add):\n",
    "    print(\"No new runs to add\")\n",
    "else:\n",
    "    print(f\"Adding {len(rows_to_add)} runs\")\n",
    "    runs_df_long = pd.concat([runs_df_long, pd.DataFrame.from_records(rows_to_add)])\n",
    "print(f\"{len(runs_df_long)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entries without an AMI metric\n",
    "test_runs_df = runs_df_long[~runs_df_long[\"AMI\"].isna()]\n",
    "len(test_runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6bohRRomX9gO"
   },
   "outputs": [],
   "source": [
    "config_keys = config_keys.difference({\"workers\", \"memory_avail_GB\", \"memory_total_GB\", \"memory_slurm\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k_KrOF5GNj9l",
    "outputId": "7649f12f-19ed-4113-bc66-88681d41ba3a"
   },
   "outputs": [],
   "source": [
    "test_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change list-type columns to a single string\n",
    "test_runs_df[\"modality\"] = test_runs_df[\"modality\"].apply(lambda x: x if isinstance(x, str) else \"+\".join(x))\n",
    "test_runs_df[\"partition\"] = test_runs_df[\"partition\"].apply(lambda x: x if isinstance(x, str) else \"+\".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_runs_df[\"prenorm\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_runs_df.loc[test_runs_df[\"prenorm\"].isna(), \"prenorm\"] = \"none\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k_KrOF5GNj9l",
    "outputId": "7649f12f-19ed-4113-bc66-88681d41ba3a"
   },
   "outputs": [],
   "source": [
    "test_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV file, so we can optionally skip downloading them\n",
    "test_runs_df.to_csv(CSV_FNAME, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(test_runs_df.loc[test_runs_df[\"partition\"] == \"test+test_unseen\", \"_runtime\"]) / 60 / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result loading utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mocov3_resnet50\"\n",
    "dataset = \"bioscan5m\"\n",
    "clusterer = \"AgglomerativeClustering\"\n",
    "metric_key = \"AMI\"\n",
    "\n",
    "my_override_fields = {}\n",
    "\n",
    "filter1 = {\"model\": model, \"dataset\": dataset}\n",
    "filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "filter2.update(filter1)\n",
    "filter2.update(my_override_fields)\n",
    "filter2 = fixup_filter(filter2)\n",
    "sdf = select_rows(test_runs_df, filter2, allow_missing=False)\n",
    "my_val = np.nanmedian(sdf[metric_key])\n",
    "\n",
    "print(f\"{metric_key} = {my_val * 100:.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_results_table(\n",
    "    models=(None,),\n",
    "    dna_models=(None,),\n",
    "    clusterers=(\"AgglomerativeClustering\",),\n",
    "    datasets=(\"bioscan5m\",),\n",
    "    metric_keys=\"AMI\",\n",
    "    partition=\"test+test_unseen\",\n",
    "    override_fields=None,\n",
    "    return_cmds=False,\n",
    "    verbosity=0,\n",
    "):\n",
    "    if override_fields is None:\n",
    "        override_fields = {}\n",
    "\n",
    "    do_squeeze = False\n",
    "    if isinstance(metric_keys, str):\n",
    "        do_squeeze = True\n",
    "        metric_keys = [metric_keys]\n",
    "\n",
    "    result_table = np.nan * np.ones((len(models), len(dna_models), len(clusterers), len(datasets), len(metric_keys)))\n",
    "    cmds = []\n",
    "\n",
    "    for i_model, model in enumerate(models):\n",
    "        for i_dna, dna_model in enumerate(dna_models):\n",
    "            for i_clusterer, clusterer in enumerate(clusterers):\n",
    "                for i_dataset, dataset in enumerate(datasets):\n",
    "                    if model is None and dna_model is None:\n",
    "                        continue\n",
    "                    filter1 = {\"dataset\": dataset, \"partition\": partition}\n",
    "                    filter1[\"modality\"] = \"image+dna\"\n",
    "                    if model is None:\n",
    "                        filter1[\"modality\"] = \"dna\"\n",
    "                    else:\n",
    "                        filter1[\"model\"] = model\n",
    "                    if dna_model is None:\n",
    "                        filter1[\"modality\"] = \"image\"\n",
    "                    else:\n",
    "                        filter1[\"model_dna\"] = dna_model\n",
    "                    filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "                    filter2.update(filter1)\n",
    "                    filter2.update(override_fields)\n",
    "                    filter2 = fixup_filter(filter2)\n",
    "                    sdf = select_rows(test_runs_df, filter2, allow_missing=False)\n",
    "                    missing_val = False\n",
    "                    if len(sdf) > 0:\n",
    "                        if len(sdf) > 1:\n",
    "                            print(f\"{len(sdf)} entries for {filter1}\")\n",
    "                        for i_key, key in enumerate(metric_keys):\n",
    "                            val = np.nanmedian(sdf[key])\n",
    "                            result_table[i_model, i_dna, i_clusterer, i_dataset, i_key] = val\n",
    "                            if np.isnan(val):\n",
    "                                missing_val = True\n",
    "                    if len(sdf) < 1 or missing_val:\n",
    "                        if verbosity >= 1:\n",
    "                            print(f\"No data for {model}-{dna_model}-{dataset}-{clusterer}\\n{filter2}\")\n",
    "                        cmds.append(filter2command(filter2, partition=\"test\"))\n",
    "\n",
    "    if do_squeeze:\n",
    "        result_table = np.squeeze(result_table, axis=-1)\n",
    "\n",
    "    if return_cmds:\n",
    "        return result_table, cmds\n",
    "    else:\n",
    "        return result_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_generator(indict, pre=None):\n",
    "    pre = pre[:] if pre else []\n",
    "    if isinstance(indict, dict):\n",
    "        for key, value in indict.items():\n",
    "            if isinstance(value, dict):\n",
    "                for d in dict_generator(value, pre + [key]):\n",
    "                    yield d\n",
    "            elif isinstance(value, list) or isinstance(value, tuple):\n",
    "                for v in value:\n",
    "                    for d in dict_generator(v, pre + [key]):\n",
    "                        yield d\n",
    "            else:\n",
    "                yield pre + [key, value]\n",
    "    else:\n",
    "        yield pre + [indict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_flat_hierarchy_from_dict(indict, pad_right=True):\n",
    "    groups_flattened = list(dict_generator(indict))\n",
    "    depth = max(len(m) for m in groups_flattened)\n",
    "    if pad_right:\n",
    "        groups_flattened = [m + [\"\"] * (depth - len(m)) for m in groups_flattened]\n",
    "    else:\n",
    "        groups_flattened = [[\"\"] * (depth - len(m)) + m for m in groups_flattened]\n",
    "\n",
    "    return groups_flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-modality results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterers = [\"AgglomerativeClustering\"]\n",
    "# test_datasets = [\"bioscan5m\"]\n",
    "test_datasets = [\"bioscan5m\"]\n",
    "metric_key = \"AMI\"\n",
    "# override_fields = {\"prenorm\": \"none\"}\n",
    "override_fields = {\"prenorm\": \"elementwise_zscore\", \"n_clusters\": None}\n",
    "merge_model_group_column = False\n",
    "partition = \"test+test_unseen\"\n",
    "# partition = \"test_unseen\"\n",
    "\n",
    "use_rank = False\n",
    "show_pc = True\n",
    "show_fmt = \"{:4.0f}\"\n",
    "highlight_best = True\n",
    "use_si_num = False\n",
    "eps = 0.005\n",
    "fixed_sc_base = None\n",
    "show_ft = False\n",
    "show_color = False\n",
    "\n",
    "if metric_key == \"num_cluster_pred\":\n",
    "    clusterers = [\"AC w/o C\", \"AffinityPropagation\", \"HDBSCAN\"]\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:4.0f}\"\n",
    "    highlight_best = False\n",
    "    use_si_num = True\n",
    "\n",
    "if metric_key.startswith(\"silhouette\"):\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:5.2f}\"\n",
    "\n",
    "\n",
    "model_groups = {\n",
    "    \"\": [None],\n",
    "    \"RN50\": RESNET50_MODELS,  # + FT_RESNET50_MODELS,\n",
    "    \"ViT-B\": VITB16_MODELS,  # + FT_VITB16_MODELS,\n",
    "}\n",
    "\n",
    "dna_model_groups = {\n",
    "    \"\": [None],\n",
    "    \"DNA Encoder\": DNA_MODELS,\n",
    "}\n",
    "\n",
    "if len(clusterers) == 1:\n",
    "    clustererstr = clusterers[0]\n",
    "    if metric_key.endswith(\"_true\"):\n",
    "        clustererstr = \"GT\"\n",
    "else:\n",
    "    clustererstr = f\"{len(clusterers)}c-avg\"\n",
    "\n",
    "model_groups_flattened = make_flat_hierarchy_from_dict(model_groups, pad_right=False)\n",
    "model_groups_flattened = np.array(model_groups_flattened)\n",
    "model_groups_flattened = model_groups_flattened[:, -1]\n",
    "\n",
    "dna_models = dna_model_groups_flattened = [xi for v in dna_model_groups.values() for xi in v]\n",
    "\n",
    "print(\"Image Encoders:\")\n",
    "print(model_groups_flattened)\n",
    "print()\n",
    "print(\"DNA Encoders:\")\n",
    "print(dna_model_groups_flattened)\n",
    "print()\n",
    "print(\"Datasets:\")\n",
    "print(test_datasets)\n",
    "print()\n",
    "print(\"Clusterers:\")\n",
    "print(clusterers)\n",
    "print()\n",
    "\n",
    "result_table, cmds = build_results_table(\n",
    "    model_groups_flattened,\n",
    "    dna_model_groups_flattened,\n",
    "    clusterers,\n",
    "    test_datasets,\n",
    "    metric_keys=metric_key,\n",
    "    partition=partition,\n",
    "    override_fields=override_fields,\n",
    "    return_cmds=True,\n",
    ")\n",
    "# Shaped [models, dna_models, clusterers, datasets]\n",
    "print(\"result_table.shape\", result_table.shape)\n",
    "\n",
    "# Take mean over clusterers and datasets\n",
    "result_table = np.nanmean(result_table, axis=-1)\n",
    "result_table = np.nanmean(result_table, axis=-1)\n",
    "# Shaped [models, dna_models]\n",
    "\n",
    "print(\"result_table.shape\", result_table.shape)\n",
    "\n",
    "print(model_groups)\n",
    "\n",
    "\n",
    "best_results = {k: [] for k in dna_model_groups_flattened}\n",
    "best_results_grouped = {k: defaultdict(list) for k in dna_model_groups_flattened}\n",
    "\n",
    "for dummy in [True, False]:\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {clustererstr}, {partition}, {test_datasets[0]}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    latex_table += r\"% Using hparams \" + BEST_PARAMS[\"_version\"] + \"\\n\"\n",
    "    label = clustererstr\n",
    "    label = metric_key.replace(\"_\", \"-\") + \":\" + label\n",
    "    latex_table += r\"\\label{tab:\" + label + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"%\\resizebox{\\columnwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{\"\n",
    "    if not merge_model_group_column:\n",
    "        latex_table += \"l\"\n",
    "    if show_ft:\n",
    "        latex_table += \"l\"\n",
    "    latex_table += \"l\" + r\"r\" * len(dna_models) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    # Begin dataset group header row\n",
    "    if len(dna_model_groups) > 1:\n",
    "        if not merge_model_group_column:\n",
    "            latex_table += r\"& \"\n",
    "        latex_table += f\"{'':<11s}\"\n",
    "        if show_ft:\n",
    "            latex_table += r\" &   \"\n",
    "        for datagroupname, datagroupset in dna_model_groups.items():\n",
    "            latex_table += r\" & \\multicolumn{\" + str(len(datagroupset)) + r\"}{c}{\" + datagroupname + r\"}\"\n",
    "        latex_table += r\"\\\\\" + \"\\n\"\n",
    "        icol = 3\n",
    "        if not merge_model_group_column:\n",
    "            icol += 1\n",
    "        if show_ft:\n",
    "            icol += 1\n",
    "        for datagroupname, datagroupset in dna_model_groups.items():\n",
    "            if datagroupname == \"\":\n",
    "                continue\n",
    "            latex_table += r\"\\cmidrule(l){\" + f\"{icol}-{icol + len(datagroupset) - 1}\" + r\"}\"\n",
    "            icol += len(datagroupset)\n",
    "        latex_table += \"\\n\"\n",
    "    # Begin main header row, with actual dataset names\n",
    "    if merge_model_group_column:\n",
    "        latex_table += r\"\\quad \"\n",
    "    else:\n",
    "        latex_table += r\"Arch. & \"\n",
    "    latex_table += f\"{'Image encoder':<11s}\"\n",
    "    if show_ft:\n",
    "        latex_table += r\" & FT \"\n",
    "    for dna_model in dna_model_groups_flattened:\n",
    "        latex_table += r\"& \\rotatebox{90}{\"\n",
    "        latex_table += \"{:^15s}\".format(DNAMODEL2SH.get(dna_model, dna_model))  # map to a shorthand\n",
    "        latex_table += r\"}\"\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    # Begin table contents\n",
    "    latex_table += r\"\\midrule\" + \"\\n\"\n",
    "    i_model_o = -1\n",
    "\n",
    "    i_model_o = -1\n",
    "    for i_group, group in enumerate(model_groups):\n",
    "        if i_group > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "        if merge_model_group_column:\n",
    "            if not group:\n",
    "                latex_table += r\"\\quad \"\n",
    "            else:\n",
    "                latex_table += r\"\\textbf{\" + group + r\"} --- \"\n",
    "        elif not group:\n",
    "            latex_table += \"---\" + \"\\n\"\n",
    "        else:\n",
    "            latex_table += group + \"\\n\"\n",
    "        for i_model, model in enumerate(list(model_groups[group])):\n",
    "            i_model_o += 1\n",
    "            model_sh = MODEL2SH.get(model, model)\n",
    "            if not show_ft:\n",
    "                pass\n",
    "            elif model_sh.endswith(\" [FT]\"):\n",
    "                model_sh = f\"{model_sh[:-4]:<10s}\" + r\" & \\checkmark\"\n",
    "            else:\n",
    "                model_sh = f\"{model_sh:<10s}\" + \" &\"\n",
    "            if merge_model_group_column and i_model > 0:\n",
    "                latex_table += r\"\\quad \"\n",
    "            if not merge_model_group_column:\n",
    "                latex_table += \"& \"\n",
    "            latex_table += f\"{model_sh:<23s}\"\n",
    "            for i_dna, dna_model in enumerate(dna_model_groups_flattened):\n",
    "                latex_table += \" &\"\n",
    "                my_val = result_table[i_model_o, i_dna]\n",
    "                if dummy:\n",
    "                    best_results[dna_model].append(my_val)\n",
    "                    best_results_grouped[dna_model][group].append(my_val)\n",
    "                    continue\n",
    "                if np.isnan(my_val):\n",
    "                    latex_table += r\"   --  \"\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dna_model])\n",
    "                if len(best_results[dna_model]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dna_model])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                is_best_grp = my_val + eps >= np.max(best_results_grouped[dna_model][group])\n",
    "                is_best_grp &= len(best_results_grouped[dna_model][group]) > 1\n",
    "                sc_base = np.nanmedian(best_results[dna_model])\n",
    "                if fixed_sc_base is not None:\n",
    "                    sc_base = fixed_sc_base\n",
    "                sc_top = np.max(best_results[dna_model])\n",
    "                sc = 100 * max(0, (my_val - sc_base) / (sc_top - sc_base))\n",
    "                if show_color and sc_top >= sc_base:\n",
    "                    latex_table += r\"\\cc{cbg!\" + f\"{sc:.0f}\" + \"}\"\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += r\"\\num{\" if use_si_num else r\"$\"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    # latex_table += \"     \"\n",
    "                    pass\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best_grp:\n",
    "                    latex_table += r\"\\tcg{\"\n",
    "                else:\n",
    "                    # latex_table += \"     \"\n",
    "                    pass\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                if highlight_best:\n",
    "                    latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                    latex_table += r\"}\" if is_best_grp else \" \"\n",
    "                latex_table += r\"}\" if use_si_num else r\"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"%}\" + \"\\n\"\n",
    "\n",
    "print()\n",
    "print(f\"There are {len(cmds)} commands to execute to generate missing datapoints\")\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {metric_key}, {clustererstr}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot AMI over taxonomic rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from zs_ssl_clustering.io import sanitize_filename\n",
    "\n",
    "\n",
    "def get_pred_path(row):\n",
    "    \"\"\"\n",
    "    Generate path to y_pred file.\n",
    "    \"\"\"\n",
    "    run_id = row[\"name\"].split(\"__\")[-1]\n",
    "    partition = row[\"partition\"]\n",
    "    partition = partition.replace(\"+\", \"-\")\n",
    "    fname = f\"{partition}-{row['dataset_name']}\"\n",
    "    if \"image\" in row[\"modality\"]:\n",
    "        fname += f\"__{row['model']}\"\n",
    "    if \"dna\" in row[\"modality\"]:\n",
    "        fname += f\"__{row['model_dna']}\"\n",
    "    fname += f\"__{run_id}.npz\"\n",
    "    fname = sanitize_filename(fname)\n",
    "    fname = os.path.join(\n",
    "        row[\"predictions_dir\"],\n",
    "        sanitize_filename(f\"{partition}\"),\n",
    "        fname,\n",
    "    )\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bioscan5m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_levels = label_cols = [\n",
    "    \"class\",\n",
    "    \"order\",\n",
    "    \"family\",\n",
    "    \"subfamily\",\n",
    "    \"genus\",\n",
    "    \"species\",\n",
    "    \"dna_bin\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = bioscan5m.BIOSCAN5M(\"~/Datasets/BIOSCAN-5M\", modality=\"dna\", split=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.metadata = ds.metadata[ds.metadata[\"split\"].isin([\"test\", \"test_unseen\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(ds.metadata[\"class_index\"], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = np.stack(\n",
    "    [ds.metadata[f\"{taxa}_index\"].to_numpy() for taxa in label_cols],\n",
    "    axis=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"bioscan5m\"  # \"bioscan5m_per-barcode-dedupNs\"  # \"bioscan5m\" \"bioscan5m_per-barcode-dedupNs\"\n",
    "partition = \"test+test_unseen\"\n",
    "modality = \"image\"\n",
    "metric_key = \"AMI\"\n",
    "override_fields = {\n",
    "    \"predictions_dir\": \"y_pred\",\n",
    "    \"prenorm\": \"none\",\n",
    "}\n",
    "\n",
    "ds_args = {}\n",
    "if dataset == \"bioscan5m_per-barcode-dedupNs\":\n",
    "    ds_args[\"reduce_repeated_barcodes\"] = \"rstrip_Ns\"\n",
    "ds = bioscan5m.BIOSCAN5M(\"~/Datasets/BIOSCAN-5M\", modality=\"dna\", split=\"all\", **ds_args)\n",
    "if partition == \"test+test_unseen\":\n",
    "    ds.metadata = pd.concat([ds.metadata[ds.metadata[\"split\"] == \"test\"], ds.metadata[ds.metadata[\"split\"] == \"test_unseen\"]])\n",
    "else:\n",
    "    ds.metadata = ds.metadata[ds.metadata[\"split\"] == partition]\n",
    "\n",
    "attrs = np.stack(\n",
    "    [ds.metadata[f\"{taxa}_index\"].to_numpy() for taxa in label_cols],\n",
    "    axis=-1,\n",
    ")\n",
    "\n",
    "for i_attr in range(len(annotation_levels)):\n",
    "    print(annotation_levels[i_attr], len(np.unique(attrs[:, i_attr])))\n",
    "\n",
    "print(attrs[np.random.choice(10000, 10),], attrs.shape)\n",
    "\n",
    "print(MODEL_GROUPS)\n",
    "\n",
    "TEST_ATTRS = annotation_levels\n",
    "print(TEST_ATTRS)\n",
    "\n",
    "plot_data = {}\n",
    "for backbone in [\"ResNet-50\", \"ViT-B\"]:\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "\n",
    "    for model in list(MODEL_GROUPS[backbone]):\n",
    "        filter1 = {\"dataset\": dataset, \"partition\": partition, \"modality\": modality}\n",
    "        if modality == \"image\":\n",
    "            filter1[\"model\"] = model\n",
    "        if modality == \"dna\":\n",
    "            filter1[\"model_dna\"] = model\n",
    "\n",
    "        filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "        filter2.update(filter1)\n",
    "        filter2.update(override_fields)\n",
    "        filter2 = fixup_filter(filter2)\n",
    "        sdf = select_rows(test_runs_df, filter2, allow_missing=False)\n",
    "\n",
    "        if len(sdf) < 1:\n",
    "            print()\n",
    "            print(filter2)\n",
    "            print(f\"No data for {model}-{dataset}-{clusterer}\")  # \\n{filter} {filter2}\")\n",
    "            continue\n",
    "        if len(sdf) > 1:\n",
    "            perf = sdf.iloc[0][metric_key]\n",
    "            if sum(sdf[metric_key] != perf) > 0:\n",
    "                print()\n",
    "                print(\n",
    "                    f\"More than one result with {metric_key} values\",\n",
    "                    list(sdf[metric_key]),\n",
    "                )\n",
    "                print(f\"for search {filter}\\nand {filter2}\")\n",
    "                dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                print(f\"columns which differ: {dif_cols}\")\n",
    "                if dif_cols:\n",
    "                    for col in dif_cols:\n",
    "                        print(f\"  {col}: {list(sdf[col])}\")\n",
    "\n",
    "        y_pred = np.load(\"../\" + get_pred_path(sdf.iloc[0]))[\"y_pred\"]\n",
    "\n",
    "        data_vec = []\n",
    "        for i_attr, attr in enumerate(TEST_ATTRS):\n",
    "            if metric_key.lower() != \"ami\":\n",
    "                raise NotImplementedError()\n",
    "            my_val = sklearn.metrics.adjusted_mutual_info_score(attrs[:, i_attr], y_pred)\n",
    "            data_vec.append(my_val)\n",
    "        plot_data[model] = data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 2.5))\n",
    "\n",
    "x_ranges = np.arange(len(annotation_levels))\n",
    "x_labels = [\"BIN\" if x == \"dna_bin\" else x for x in annotation_levels]\n",
    "\n",
    "for model, data_vec in plot_data.items():\n",
    "    plt.plot(\n",
    "        x_ranges,\n",
    "        np.array(data_vec) * 100,\n",
    "        marker=ARCH2MARKER.get(MODEL2ARCH.get(model, \"\"), \"o\"),\n",
    "        ls=ARCH2LS.get(MODEL2ARCH.get(model, \"\"), \"-\"),\n",
    "        color=MODEL2COLORRGB.get(model, (0.0, 0.0, 0.0)),\n",
    "        label=MODEL2SH.get(model, model),\n",
    "    )\n",
    "\n",
    "axs = plt.gca()\n",
    "axs.grid(True, axis=\"y\", which=\"major\", linestyle=\"-\", alpha=0.8)\n",
    "axs.grid(True, axis=\"y\", which=\"minor\", linestyle=\"--\", alpha=0.3)\n",
    "axs.set_xticks(x_ranges)\n",
    "axs.set_xticklabels(x_labels, rotation=45)\n",
    "axs.set_yticks(np.arange(0, 110, 10))\n",
    "axs.set_yticks(np.arange(0, 110, 5), minor=True)\n",
    "axs.set_ylabel(\"AMI (%)\", fontsize=12)\n",
    "\n",
    "\n",
    "def colorMarker(m):\n",
    "    return plt.plot([], [], color=m)[0]\n",
    "\n",
    "\n",
    "plt_labels = model_names = list(MODEL_GROUPS[\"ResNet-50\"])[:-1] + MODEL_GROUPS[\"ViT-B\"][-3:]\n",
    "handles = [colorMarker(MODEL2COLORSTR[name]) for name in model_names]\n",
    "\n",
    "\n",
    "def backboneMarker(m, color=\"black\"):\n",
    "    return plt.plot([], [], marker=m, ls=\"none\", color=color)[0]\n",
    "\n",
    "\n",
    "handles.extend(\n",
    "    [\n",
    "        backboneMarker(ARCH2MARKER[\"ResNet-50\"], color=(0.4, 0.4, 0.4)),\n",
    "        backboneMarker(ARCH2MARKER[\"ViT-B\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt_labels += [\"RN50\", \"ViT-B\"]\n",
    "\n",
    "ncols = 3\n",
    "axs.legend(\n",
    "    handles,\n",
    "    [MODEL2SH.get(x, x) for x in plt_labels],\n",
    "    bbox_to_anchor=(0.0, 1.1, 1.0, 0.402),\n",
    "    loc=\"lower left\",\n",
    "    ncol=ncols,\n",
    "    mode=\"expand\",\n",
    "    borderaxespad=0.0,\n",
    ")\n",
    "\n",
    "fig.savefig(f\"zsc_{dataset}_{partition.replace('+', '-')}_image_taxonomic_performance.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"bioscan5m\"  # \"bioscan5m\"  \"bioscan5m_per-barcode-dedupNs\"\n",
    "partition = \"test+test_unseen\"\n",
    "modality = \"dna\"\n",
    "models = DNA_MODELS\n",
    "metric_key = \"AMI\"\n",
    "override_fields = {\n",
    "    \"predictions_dir\": \"y_pred\",\n",
    "    \"prenorm\": \"none\",\n",
    "}\n",
    "\n",
    "ds_args = {}\n",
    "if dataset == \"bioscan5m_per-barcode-dedupNs\":\n",
    "    ds_args[\"reduce_repeated_barcodes\"] = \"rstrip_Ns\"\n",
    "ds = bioscan5m.BIOSCAN5M(\"~/Datasets/BIOSCAN-5M\", modality=\"dna\", split=\"all\", **ds_args)\n",
    "if partition == \"test+test_unseen\":\n",
    "    ds.metadata = pd.concat([ds.metadata[ds.metadata[\"split\"] == \"test\"], ds.metadata[ds.metadata[\"split\"] == \"test_unseen\"]])\n",
    "else:\n",
    "    ds.metadata = ds.metadata[ds.metadata[\"split\"] == partition]\n",
    "\n",
    "attrs = np.stack(\n",
    "    [ds.metadata[f\"{taxa}_index\"].to_numpy() for taxa in label_cols],\n",
    "    axis=-1,\n",
    ")\n",
    "\n",
    "for i_attr in range(len(annotation_levels)):\n",
    "    print(annotation_levels[i_attr], len(np.unique(attrs[:, i_attr])))\n",
    "\n",
    "print(attrs[np.random.choice(10000, 10),], attrs.shape)\n",
    "\n",
    "\n",
    "print(MODEL_GROUPS)\n",
    "\n",
    "TEST_ATTRS = annotation_levels\n",
    "print(TEST_ATTRS)\n",
    "\n",
    "plot_data = {}\n",
    "for model in models:\n",
    "    filter1 = {\"dataset\": dataset, \"partition\": partition, \"modality\": modality}\n",
    "    if modality == \"image\":\n",
    "        filter1[\"model\"] = model\n",
    "    if modality == \"dna\":\n",
    "        filter1[\"model_dna\"] = model\n",
    "        filter1[\"model_dna\"] = model\n",
    "\n",
    "    filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "    filter2.update(filter1)\n",
    "    filter2.update(override_fields)\n",
    "    filter2 = fixup_filter(filter2)\n",
    "    sdf = select_rows(test_runs_df, filter2, allow_missing=False)\n",
    "\n",
    "    if len(sdf) < 1:\n",
    "        print()\n",
    "        print(filter2)\n",
    "        print(f\"No data for {model}-{dataset}-{clusterer}\")  # \\n{filter} {filter2}\")\n",
    "        continue\n",
    "    if len(sdf) > 1:\n",
    "        perf = sdf.iloc[0][metric_key]\n",
    "        if sum(sdf[metric_key] != perf) > 0:\n",
    "            print()\n",
    "            print(\n",
    "                f\"More than one result with {metric_key} values\",\n",
    "                list(sdf[metric_key]),\n",
    "            )\n",
    "            print(f\"for search {filter}\\nand {filter2}\")\n",
    "            dif_cols = find_differing_columns(sdf, config_keys)\n",
    "            print(f\"columns which differ: {dif_cols}\")\n",
    "            if dif_cols:\n",
    "                for col in dif_cols:\n",
    "                    print(f\"  {col}: {list(sdf[col])}\")\n",
    "\n",
    "    y_pred = np.load(\"../\" + get_pred_path(sdf.iloc[0]))[\"y_pred\"]\n",
    "\n",
    "    data_vec = []\n",
    "    for i_attr, attr in enumerate(TEST_ATTRS):\n",
    "        if metric_key.lower() != \"ami\":\n",
    "            raise NotImplementedError()\n",
    "        my_val = sklearn.metrics.adjusted_mutual_info_score(attrs[:, i_attr], y_pred)\n",
    "        data_vec.append(my_val)\n",
    "    plot_data[model] = data_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 2.5))\n",
    "\n",
    "x_ranges = np.arange(len(annotation_levels))\n",
    "x_labels = [\"BIN\" if x == \"dna_bin\" else x for x in annotation_levels]\n",
    "\n",
    "for model, data_vec in plot_data.items():\n",
    "    plt.plot(\n",
    "        x_ranges,\n",
    "        np.array(data_vec) * 100,\n",
    "        marker=\"o\",\n",
    "        ls=\"-\",\n",
    "        color=MODEL2COLORRGB.get(model, (0.0, 0.0, 0.0)),\n",
    "        label=DNAMODEL2SH.get(model, model),\n",
    "    )\n",
    "\n",
    "axs = plt.gca()\n",
    "axs.grid(True, axis=\"y\", which=\"major\", linestyle=\"-\", alpha=0.8)\n",
    "axs.grid(True, axis=\"y\", which=\"minor\", linestyle=\"--\", alpha=0.3)\n",
    "axs.set_xticks(x_ranges)\n",
    "axs.set_xticklabels(x_labels, rotation=45)\n",
    "axs.set_yticks(np.arange(0, 110, 10))\n",
    "# axs.set_yticks(np.arange(0, 110, 5), minor=True)\n",
    "axs.set_ylabel(\"AMI (%)\", fontsize=12)\n",
    "\n",
    "\n",
    "def colorMarker(m):\n",
    "    return plt.plot([], [], color=m)[0]\n",
    "\n",
    "\n",
    "plt_labels = model_names = list(plot_data.keys())\n",
    "handles = [colorMarker(MODEL2COLORRGB[name]) for name in model_names]\n",
    "\n",
    "ncols = 3\n",
    "axs.legend(\n",
    "    handles,\n",
    "    [DNAMODEL2SH.get(x, x) for x in plt_labels],\n",
    "    bbox_to_anchor=(0.0, 1.1, 1.0, 0.402),\n",
    "    loc=\"lower left\",\n",
    "    ncol=ncols,\n",
    "    mode=\"expand\",\n",
    "    borderaxespad=0.0,\n",
    ")\n",
    "\n",
    "fig.savefig(f\"zsc_{dataset}_{partition.replace('+', '-')}_DNA_taxonomic_performance.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
