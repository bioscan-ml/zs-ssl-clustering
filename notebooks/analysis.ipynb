{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mViY7L8lcked"
   },
   "source": [
    "# Hyper parameter searches on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9BelQPaJVo2"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AH-GlrfS4Pf"
   },
   "outputs": [],
   "source": [
    "VALIDATION_DATASETS = [\"imagenet\", \"imagenette\", \"imagewoof\"]\n",
    "RESNET50_MODELS = [\n",
    "    \"resnet50\",\n",
    "    \"mocov3_resnet50\",\n",
    "    \"vicreg_resnet50\",\n",
    "    \"dino_resnet50\",\n",
    "    \"clip_RN50\",\n",
    "]\n",
    "VITB16_MODELS = [\n",
    "    \"vitb16\",\n",
    "    \"mocov3_vit_base\",\n",
    "    \"timm_vit_base_patch16_224.mae\",\n",
    "    \"dino_vitb16\",\n",
    "    \"clip_vitb16\",\n",
    "]\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"SpectralClustering\",\n",
    "    \"HDBSCAN\",\n",
    "    \"OPTICS\",\n",
    "]\n",
    "DISTANCE_METRICS = [\n",
    "    \"euclidean\",\n",
    "    \"l1\",\n",
    "    \"chebyshev\",\n",
    "    \"cosine\",\n",
    "    \"arccos\",\n",
    "    \"braycurtis\",\n",
    "    \"canberra\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqPoCd4kbokG"
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    \"all\": {\n",
    "        \"dim_reducer\": \"None\",\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "        \"zscore\": False,\n",
    "        \"normalize\": False,\n",
    "    },\n",
    "    \"KMeans\": {\"clusterer\": \"KMeans\"},\n",
    "    \"AffinityPropagation\": {\n",
    "        \"clusterer\": \"AffinityPropagation\",\n",
    "        \"affinity_damping\": 0.5,\n",
    "        \"affinity_conv_iter\": 15,\n",
    "    },\n",
    "    \"SpectralClustering\": {\n",
    "        \"clusterer\": \"SpectralClustering\",\n",
    "        \"spectral_assigner\": \"kmeans\",\n",
    "    },\n",
    "    \"AgglomerativeClustering\": {\n",
    "        \"clusterer\": \"AgglomerativeClustering\",\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "        \"aggclust_linkage\": \"ward\",\n",
    "    },\n",
    "    \"HDBSCAN\": {\n",
    "        \"clusterer\": \"HDBSCAN\",\n",
    "        \"hdbscan_method\": \"eom\",\n",
    "        \"min_samples\": 5,\n",
    "        \"max_samples\": 0.2,\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "    },\n",
    "    \"OPTICS\": {\n",
    "        \"clusterer\": \"OPTICS\",\n",
    "        \"optics_method\": \"xi\",\n",
    "        \"optics_xi\": 0.05,\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w21wu6JUk4d"
   },
   "outputs": [],
   "source": [
    "def categorical_cmap(nc, nsc, cmap=\"tab10\", continuous=False):\n",
    "    \"\"\"\n",
    "    Create a colormap with a certain number of shades of colours.\n",
    "\n",
    "    https://stackoverflow.com/a/47232942/1960959\n",
    "    \"\"\"\n",
    "    if nc > plt.get_cmap(cmap).N:\n",
    "        raise ValueError(\"Too many categories for colormap.\")\n",
    "    if continuous:\n",
    "        ccolors = plt.get_cmap(cmap)(np.linspace(0, 1, nc))\n",
    "    else:\n",
    "        ccolors = plt.get_cmap(cmap)(np.arange(nc, dtype=int))\n",
    "    cols = np.zeros((nc * nsc, 3))\n",
    "    for i, c in enumerate(ccolors):\n",
    "        chsv = matplotlib.colors.rgb_to_hsv(c[:3])\n",
    "        arhsv = np.tile(chsv, nsc).reshape(nsc, 3)\n",
    "        arhsv[:, 1] = np.linspace(chsv[1], 0.25, nsc)\n",
    "        arhsv[:, 2] = np.linspace(chsv[2], 1, nsc)\n",
    "        rgb = matplotlib.colors.hsv_to_rgb(arhsv)\n",
    "        cols[i * nsc : (i + 1) * nsc, :] = rgb\n",
    "    cmap = matplotlib.colors.ListedColormap(cols)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "Zt-xAviSUwWV",
    "outputId": "e5937cf3-bd0f-4a35-c436-028dd8aef710"
   },
   "outputs": [],
   "source": [
    "categorical_cmap(len(RESNET50_MODELS), len(VALIDATION_DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "PuCnc-t9rQ4q",
    "outputId": "24fee90d-9881-484b-cf79-f1b0dc30f274"
   },
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "# Project is specified by <entity/project-name>\n",
    "runs = api.runs(\n",
    "    \"uoguelph_mlrg/zs-ssl-clustering\",\n",
    "    filters={\"state\": \"Finished\", \"config.partition\": \"val\"},\n",
    ")\n",
    "len(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JZz6EautFlEa"
   },
   "outputs": [],
   "source": [
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame(\n",
    "    {\"summary\": summary_list, \"config\": config_list, \"name\": name_list}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "NlpBD8JHHFn1"
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "config_keys = set()\n",
    "summary_keys = set()\n",
    "for summary, config, name in zip(summary_list, config_list, name_list):\n",
    "    row = {\"name\": name}\n",
    "    row.update({k: v for k, v in config.items() if not k.startswith(\"_\")})\n",
    "    row.update({k: v for k, v in summary.items() if not k.startswith(\"_\")})\n",
    "    rows.append(row)\n",
    "    config_keys = config_keys.union(config.keys())\n",
    "    summary_keys = summary_keys.union(summary.keys())\n",
    "\n",
    "runs_df = pd.DataFrame.from_records(rows)\n",
    "\n",
    "# Handle changed default value for spectral_assigner after config arg was introduced\n",
    "if \"spectral_assigner\" not in runs_df.columns:\n",
    "    runs_df[\"spectral_assigner\"] = None\n",
    "select = runs_df[\"clusterer_name\"] != \"SpectralClustering\"\n",
    "runs_df.loc[select, \"spectral_assigner\"] = None\n",
    "select = (runs_df[\"clusterer_name\"] == \"SpectralClustering\") & pd.isna(\n",
    "    runs_df[\"spectral_assigner\"]\n",
    ")\n",
    "runs_df.loc[select, \"spectral_assigner\"] = \"kmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "ji8V4jhStu_7",
    "outputId": "4a2c0c85-4e26-4230-a2de-543728b7ea47"
   },
   "outputs": [],
   "source": [
    "len(runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "H8v330NeKd5T",
    "outputId": "c5c2ca08-39e5-4a34-8f8c-b67eb745aa60"
   },
   "outputs": [],
   "source": [
    "config_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VrIuBBBcKfeh",
    "outputId": "919d7752-c6a8-4e9c-d3f5-7ab5f5f90559"
   },
   "outputs": [],
   "source": [
    "summary_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "mFRtnzmOH-6f",
    "outputId": "b8f6117f-6d1c-4c32-9f45-12c42ac6e4fa"
   },
   "outputs": [],
   "source": [
    "runs_df = runs_df[~runs_df[\"AMI\"].isna()]\n",
    "len(runs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 722
    },
    "id": "d1R2eJtxHrK-",
    "outputId": "8eda2e50-2dfc-4b4d-eda7-35ae069a10be"
   },
   "outputs": [],
   "source": [
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "i5hY2oc2I-PO"
   },
   "outputs": [],
   "source": [
    "def select_rows(df, filters, allow_missing=True):\n",
    "    select = np.ones(len(df), dtype=bool)\n",
    "    for col, val in filters.items():\n",
    "        if col == \"dataset\":\n",
    "            col = \"dataset_name\"\n",
    "        if col == \"clusterer\":\n",
    "            col = \"clusterer_name\"\n",
    "        if val is None or val == \"None\":\n",
    "            select_i = pd.isna(df[col])\n",
    "            select_i |= df[col] == \"None\"\n",
    "        else:\n",
    "            select_i = df[col] == val\n",
    "            select_i |= df[col] == str(val)\n",
    "            if allow_missing or val == \"None\":\n",
    "                select_i |= pd.isna(df[col])\n",
    "        select &= select_i\n",
    "    return df[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7iOVrUnC_Jg-"
   },
   "outputs": [],
   "source": [
    "def find_differing_columns(df, cols=None):\n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "    my_cols = []\n",
    "    for col in cols:\n",
    "        if df[col].nunique(dropna=False) > 1:\n",
    "            my_cols.append(col)\n",
    "    return my_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "wI7MkSQiz89O"
   },
   "outputs": [],
   "source": [
    "def filter2command(*filters, partition=\"val\"):\n",
    "    f = {}\n",
    "    for filter in filters:\n",
    "        for k, v in filter.items():\n",
    "            f[k] = v\n",
    "    dataset = f.get(\"dataset\", \"\")\n",
    "    clusterer = f.get(\"clusterer\", \"\")\n",
    "    mem = 4\n",
    "    if dataset != \"imagenet\":\n",
    "        pass\n",
    "    elif clusterer == \"AgglomerativeClustering\":\n",
    "        mem = 20\n",
    "    if partition == \"val\":\n",
    "        seed = 100\n",
    "    elif partition == \"test\":\n",
    "        seed = 1\n",
    "    else:\n",
    "        seed = 0\n",
    "    s = (\n",
    "        f\"sbatch --array={seed} --mem={mem}G\"\n",
    "        f' --job-name=\"zsc-{f.get(\"model\", \"\")}-{dataset}-{clusterer}\"'\n",
    "        f\" slurm/cluster.slrm --partition={partition}\"\n",
    "    )\n",
    "    for k, v in f.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k == \"zscore\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-zscore\"\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --zscore\"\n",
    "            continue\n",
    "        if k == \"normalize\":\n",
    "            if v == \"False\" or not v:\n",
    "                pass\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --normalize\"\n",
    "            continue\n",
    "        s += f\" --{k.replace('_', '-')}={v}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XfJUeBenJuUj",
    "outputId": "1f145a23-a23b-4f1e-8e09-e327e10ccf36"
   },
   "outputs": [],
   "source": [
    "sdf = select_rows(\n",
    "    runs_df,\n",
    "    {\n",
    "        \"model\": \"resnet50\",\n",
    "        \"dataset\": \"imagenette\",\n",
    "        \"clusterer\": \"KMeans\",\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "    },\n",
    "    allow_missing=False,\n",
    ")\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "mDfUksgsLUON",
    "outputId": "157a6f36-31b0-4cb3-ed87-98003003d444"
   },
   "outputs": [],
   "source": [
    "sdf[\"reduced_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "2tiDbsLBQ7RP",
    "outputId": "29cd27eb-5a96-4003-8bd7-3b9811ff1517"
   },
   "outputs": [],
   "source": [
    "sdf = sdf.sort_values(\"reduced_dim\")\n",
    "plt.plot(sdf[\"reduced_dim\"], sdf[\"AMI\"])\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "RbueTcNgI0fJ",
    "outputId": "65cc6312-f23e-4f6f-e215-227d5e0891a7"
   },
   "outputs": [],
   "source": [
    "plt.plot(sdf[\"pca_explained_ratio\"], sdf[\"AMI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "6tNLcKT-R_5d",
    "outputId": "5b011f18-b3b5-41b4-ac45-d705f5dda9d2"
   },
   "outputs": [],
   "source": [
    "sdf = sdf.sort_values(\"reduced_dim\")\n",
    "plt.plot(sdf[\"reduced_dim\"], sdf[\"pca_explained_ratio\"])\n",
    "plt.xlabel(\"Dimension\")\n",
    "plt.ylabel(\"Variance explained\")\n",
    "plt.title(\"imagenette: resnet50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "B-jCRw79VB-2"
   },
   "outputs": [],
   "source": [
    "cmap = categorical_cmap(len(RESNET50_MODELS), len(VALIDATION_DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "id": "mAHv_cRkVCp6",
    "outputId": "d6813773-01c7-495f-dbce-f385bc8728de"
   },
   "outputs": [],
   "source": [
    "cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "012WFlAoBhU1",
    "outputId": "43b81409-8f82-458d-ba23-c7daa40554aa"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "clusterer = \"KMeans\"\n",
    "plt.figure(figsize=(10, 8))\n",
    "i = 0\n",
    "for model in models:\n",
    "    for dataset in VALIDATION_DATASETS:\n",
    "        filter = {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"clusterer\": clusterer,\n",
    "            \"dim_reducer\": \"PCA\",\n",
    "            \"zscore\": True,\n",
    "        }\n",
    "        sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "        filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "        filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "        sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "        sdf = sdf.sort_values(\"reduced_dim\")\n",
    "        plt.plot(\n",
    "            sdf[\"reduced_dim\"],\n",
    "            sdf[\"pca_explained_ratio\"],\n",
    "            label=f\"{dataset}: {model}\",\n",
    "            c=cmap(i),\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "plt.xlabel(\"Number of dimensions\")\n",
    "plt.ylabel(\"Cummulative variance fraction explained\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "eDCL777RSuyg",
    "outputId": "b65cfb44-3ee4-43a6-fe8b-1df8f0304922"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "for clusterer in CLUSTERERS:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        for dataset in VALIDATION_DATASETS:\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"dim_reducer\": \"PCA\",\n",
    "                \"zscore\": True,\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "            sdf = sdf.sort_values(\"reduced_dim\")\n",
    "            plt.plot(\n",
    "                sdf[\"reduced_dim\"],\n",
    "                sdf[\"AMI\"],\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                c=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "    plt.xlabel(\"Dimension\")\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.title(clusterer)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FDw-t2JiY94W",
    "outputId": "854a6d46-7e8a-43fe-c187-5ae4f432f14b"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "for clusterer in CLUSTERERS:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        for dataset in VALIDATION_DATASETS:\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"dim_reducer\": \"PCA\",\n",
    "                \"zscore\": True,\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "            sdf = sdf.sort_values(\"pca_explained_ratio\")\n",
    "            plt.plot(\n",
    "                sdf[\"pca_explained_ratio\"],\n",
    "                sdf[\"AMI\"],\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                c=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "    plt.xlabel(\"Kept variance explained ratio\")\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.title(clusterer)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GLjhrk5MXdi-",
    "outputId": "ba4a7b21-79ad-4685-9ba3-12c7a2b9e85e"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "for clusterer in CLUSTERERS:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    i = 0\n",
    "    for model in models:\n",
    "        for dataset in VALIDATION_DATASETS:\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"dim_reducer_man\": \"UMAP\",\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "            sdf = select_rows(\n",
    "                sdf, {\"dim_reducer_man_metric\": \"euclidean\"}, allow_missing=True\n",
    "            )\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "            sdf = sdf.sort_values(\"reduced_dim\")\n",
    "            plt.plot(\n",
    "                sdf[\"reduced_dim\"],\n",
    "                sdf[\"AMI\"],\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                c=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "\n",
    "    plt.xlabel(\"Dimensions\")\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.title(clusterer)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "id": "wvAANYhkezsN",
    "outputId": "6ea682f4-85ab-4690-871e-d7f84d53f798"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "clusterer = \"HDBSCAN\"\n",
    "plt.figure(figsize=(10, 8))\n",
    "i = -1\n",
    "for model in models:\n",
    "    for dataset in VALIDATION_DATASETS:\n",
    "        i += 1\n",
    "        filter = {\n",
    "            \"model\": model,\n",
    "            \"dataset\": dataset,\n",
    "            \"clusterer\": clusterer,\n",
    "        }\n",
    "        sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "        filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "        filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "        filter2 = {k: v for k, v in filter2.items() if k not in [\"max_samples\"]}\n",
    "        sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "        sdf = sdf.sort_values(\"max_samples\")\n",
    "        if len(sdf) > 0 and sum(~pd.isna(sdf[\"max_samples\"])) > 0:\n",
    "            plt.plot(\n",
    "                sdf[\"max_samples\"],\n",
    "                sdf[\"AMI\"],\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                c=cmap(i),\n",
    "            )\n",
    "\n",
    "plt.xlabel(\"Max samples per cluster\")\n",
    "plt.ylabel(\"AMI\")\n",
    "plt.title(clusterer)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "kajP6Vzag_PI"
   },
   "outputs": [],
   "source": [
    "cmap = categorical_cmap(len(RESNET50_MODELS), len(VALIDATION_DATASETS))\n",
    "clusterer = \"HDBSCAN\"\n",
    "methods = [\"eom\", \"leaf\"]\n",
    "metrics = DISTANCE_METRICS\n",
    "\n",
    "data = np.NaN * np.ones(\n",
    "    (len(RESNET50_MODELS), len(VALIDATION_DATASETS), len(methods), len(metrics))\n",
    ")\n",
    "cmds = []\n",
    "for i_model, model in enumerate(RESNET50_MODELS):\n",
    "    for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "        for i_method, method in enumerate(methods):\n",
    "            for i_metric, metric in enumerate(metrics):\n",
    "                if metric == \"cosine\":\n",
    "                    continue\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                    \"distance_metric\": metric,\n",
    "                    \"hdbscan_method\": method,\n",
    "                }\n",
    "                if method == \"eom\":\n",
    "                    filter[\"max_samples\"] = 0.25\n",
    "                sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=True)\n",
    "                if len(sdf) < 1:\n",
    "                    print(\"No data for\", filter)\n",
    "                    cmds.append(filter2command(filter, filter2))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter} and {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        print()\n",
    "                data[i_model, i_dataset, i_method, i_metric] = sdf.iloc[0][\"AMI\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-DMe3q3OGXj",
    "outputId": "f1ba87c2-2150-4204-8343-54e515fb0d86"
   },
   "outputs": [],
   "source": [
    "np.mean(np.mean(data, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "7DJLRKy4PSy-",
    "outputId": "9f39d700-4e82-4c38-96dc-95bcdf7d1c95"
   },
   "outputs": [],
   "source": [
    "np.nanmean(np.nanmean(data, axis=1), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WNhRk0JUWbLi",
    "outputId": "d36431a5-ab35-4ecc-eda8-0159ca2e0ea2"
   },
   "outputs": [],
   "source": [
    "data[0, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8CZNU7o4WSNZ",
    "outputId": "1bfee8d8-d57b-4cfa-ea43-83a2fb9acc04"
   },
   "outputs": [],
   "source": [
    "max_data = np.nanmax(data)\n",
    "YLIM = [-0.05 * max_data, 1.05 * max_data]\n",
    "for i_method, method in enumerate(methods):\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = plt.axes()\n",
    "    i = 0\n",
    "    for i_model, model in enumerate(RESNET50_MODELS):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            plt.plot(\n",
    "                data[i_model, i_dataset, i_method, :],\n",
    "                \"x\",\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                c=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "    # plt.legend()\n",
    "    ax.set_xticks(np.arange(len(metrics)), metrics)\n",
    "    plt.ylim(YLIM)\n",
    "    plt.title(method)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MjRD8fabYz-5",
    "outputId": "ac51df5a-e7dd-4951-c15a-c7c5e7a07128"
   },
   "outputs": [],
   "source": [
    "width = 0.05\n",
    "max_data = np.nanmax(data)\n",
    "YLIM = [-0.05 * max_data, 1.05 * max_data]\n",
    "for i_method, method in enumerate(methods):\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    ax = plt.axes()\n",
    "    i = 0\n",
    "    for i_model, model in enumerate(RESNET50_MODELS):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            plt.bar(\n",
    "                np.arange(len(metrics)) + i * width,\n",
    "                data[i_model, i_dataset, i_method, :],\n",
    "                width=width,\n",
    "                label=f\"{dataset}: {model}\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "    # plt.legend()\n",
    "    ax.set_xticks(np.arange(len(metrics)) + width * (i + 1) / 2, metrics)\n",
    "    plt.ylim(YLIM)\n",
    "    plt.title(method)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "FSXafiTooibY",
    "outputId": "e4d86c75-17b9-47e0-81da-74b7db4f1c40"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "axis_values = [2, 5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "data_pca = np.NaN * np.ones(\n",
    "    (len(CLUSTERERS), len(models), len(VALIDATION_DATASETS), len(axis_values))\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    for i_model, model in enumerate(models):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            for i_value, axis_value in enumerate(axis_values):\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                    \"aggclust_dist_thresh\": None,\n",
    "                    \"dim_reducer\": \"PCA\",\n",
    "                    \"zscore\": True,\n",
    "                    \"ndim_reduced\": axis_value,\n",
    "                }\n",
    "                if clusterer == \"HDBSCAN\":\n",
    "                    filter[\"max_samples\"] = 0.25\n",
    "                sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    if dataset == \"imagenet\" and clusterer in [\n",
    "                        \"AffinityPropagation\",\n",
    "                        \"SpectralClustering\",\n",
    "                        \"OPTICS\",\n",
    "                    ]:\n",
    "                        continue\n",
    "                    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "                        continue\n",
    "                    print(\"No data for\", filter)\n",
    "                    cmds.append(filter2command(filter, filter2))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter} and {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        print()\n",
    "                data_pca[i_clusterer, i_model, i_dataset, i_value] = sdf.iloc[0][\"AMI\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Xtg_fWu4q3gT"
   },
   "outputs": [],
   "source": [
    "axis_values = pca_var_values = [0.75, 0.8, 0.85, 0.90, 0.95, 0.98, 0.99]\n",
    "\n",
    "data_pca_var = np.NaN * np.ones(\n",
    "    (len(CLUSTERERS), len(models), len(VALIDATION_DATASETS), len(axis_values))\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    for i_model, model in enumerate(models):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            for i_value, axis_value in enumerate(axis_values):\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                    \"aggclust_dist_thresh\": None,\n",
    "                    \"dim_reducer\": \"PCA\",\n",
    "                    \"zscore\": True,\n",
    "                    \"pca_variance\": axis_value,\n",
    "                }\n",
    "                sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    if dataset == \"imagenet\" and clusterer in [\n",
    "                        \"AffinityPropagation\",\n",
    "                        \"SpectralClustering\",\n",
    "                        \"OPTICS\",\n",
    "                    ]:\n",
    "                        continue\n",
    "                    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "                        continue\n",
    "                    print(\"No data for\", filter)\n",
    "                    cmds.append(filter2command(filter, filter2))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter} and {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        print()\n",
    "                data_pca_var[i_clusterer, i_model, i_dataset, i_value] = sdf.iloc[0][\n",
    "                    \"AMI\"\n",
    "                ]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "GOla9Pio28Op",
    "outputId": "7443f297-9683-4d64-b9ea-40c4097a87c4"
   },
   "outputs": [],
   "source": [
    "axis_values = [2, 5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "data_umap = np.NaN * np.ones(\n",
    "    (len(CLUSTERERS), len(models), len(VALIDATION_DATASETS), len(axis_values))\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    for i_model, model in enumerate(models):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            for i_value, axis_value in enumerate(axis_values):\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                    \"aggclust_dist_thresh\": None,\n",
    "                    \"dim_reducer_man\": \"UMAP\",\n",
    "                    \"ndim_reduced_man\": axis_value,\n",
    "                }\n",
    "                sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    if dataset == \"imagenet\" and clusterer in [\n",
    "                        \"AffinityPropagation\",\n",
    "                        \"SpectralClustering\",\n",
    "                        \"OPTICS\",\n",
    "                    ]:\n",
    "                        continue\n",
    "                    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "                        continue\n",
    "                    print(\"No data for\", filter)\n",
    "                    cmds.append(\n",
    "                        \"sbatch --array=100 --mem=8G\"\n",
    "                        f' --job-name=\"zsc-{model}-{dataset}-{clusterer}_UMAP-{axis_value}\"'\n",
    "                        f' slurm/cluster.slrm --partition=val --dataset=\"{dataset}\"'\n",
    "                        f' --model=\"{model}\" --clusterer=\"{clusterer}\"'\n",
    "                        f' --dim-reducer-man=UMAP --ndim-reduced-man=\"{axis_value}\"'\n",
    "                    )\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter} and {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        print()\n",
    "                data_umap[i_clusterer, i_model, i_dataset, i_value] = sdf.iloc[0][\"AMI\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WkqTgKta9m78",
    "outputId": "3ef19d42-dd9e-4f74-90e3-20cfb82426a9"
   },
   "outputs": [],
   "source": [
    "data_base = np.NaN * np.ones(\n",
    "    (len(CLUSTERERS), len(models), len(VALIDATION_DATASETS), 2)\n",
    ")\n",
    "\n",
    "cmds = []\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    for i_model, model in enumerate(models):\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            # no z-score\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"aggclust_dist_thresh\": None,\n",
    "                \"zscore\": False,\n",
    "                \"dim_reducer\": \"None\",\n",
    "                \"dim_reducer_man\": \"None\",\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=True)\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "            if len(sdf) < 1:\n",
    "                if dataset == \"imagenet\" and clusterer in [\n",
    "                    \"AffinityPropagation\",\n",
    "                    \"SpectralClustering\",\n",
    "                    \"OPTICS\",\n",
    "                ]:\n",
    "                    continue\n",
    "                if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "                    continue\n",
    "                print(\"No data for\", filter)\n",
    "                cmds.append(\n",
    "                    \"sbatch --array=100 --mem=8G\"\n",
    "                    f' --job-name=\"zsc-{model}-{dataset}-{clusterer}\"'\n",
    "                    f' slurm/cluster.slrm --partition=val --dataset=\"{dataset}\"'\n",
    "                    f' --model=\"{model}\" --clusterer=\"{clusterer}\"'\n",
    "                )\n",
    "                continue\n",
    "            if len(sdf) > 1:\n",
    "                perf = sdf.iloc[0][\"AMI\"]\n",
    "                if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                    print()\n",
    "                    print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                    print(f\"for search {filter} and {filter2}\")\n",
    "                    dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                    print(f\"columns which differ: {dif_cols}\")\n",
    "                    print()\n",
    "            data_base[i_clusterer, i_model, i_dataset, 0] = sdf.iloc[0][\"AMI\"]\n",
    "            # z-score\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"aggclust_dist_thresh\": None,\n",
    "                \"zscore\": True,\n",
    "                \"dim_reducer\": \"None\",\n",
    "                \"dim_reducer_man\": \"None\",\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **DEFAULT_PARAMS[clusterer])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "            if len(sdf) < 1:\n",
    "                if dataset == \"imagenet\" and clusterer in [\n",
    "                    \"AffinityPropagation\",\n",
    "                    \"SpectralClustering\",\n",
    "                    \"OPTICS\",\n",
    "                ]:\n",
    "                    continue\n",
    "                if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "                    continue\n",
    "                print(\"No data for\", filter)\n",
    "                cmds.append(\n",
    "                    \"sbatch --array=100 --mem=8G\"\n",
    "                    f' --job-name=\"zsc-{model}-{dataset}-{clusterer}-zscore\"'\n",
    "                    f' slurm/cluster.slrm --partition=val --dataset=\"{dataset}\"'\n",
    "                    f' --model=\"{model}\" --clusterer=\"{clusterer}\"'\n",
    "                    \" --zscore\"\n",
    "                )\n",
    "                continue\n",
    "            if len(sdf) > 1:\n",
    "                perf = sdf.iloc[0][\"AMI\"]\n",
    "                if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                    print()\n",
    "                    print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                    print(f\"for search {filter} and {filter2}\")\n",
    "                    dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                    print(f\"columns which differ: {dif_cols}\")\n",
    "                    print()\n",
    "            data_base[i_clusterer, i_model, i_dataset, 1] = sdf.iloc[0][\"AMI\"]\n",
    "\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_iZBvJuY0Tlq",
    "outputId": "8053dc66-64e2-412b-9b57-90553beaedd0"
   },
   "outputs": [],
   "source": [
    "np.nanmax(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHvpqopo3Iz5",
    "outputId": "0759ffbd-bdc3-49b6-bb97-b3b568c91a11"
   },
   "outputs": [],
   "source": [
    "np.nanmax(data_umap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f6OBSOKEJHP",
    "outputId": "c7aefd55-014f-48aa-fc87-7080f6e521af"
   },
   "outputs": [],
   "source": [
    "np.nanmax(data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "0RqhXFtdzPF9",
    "outputId": "ae696f7f-7267-4447-bdd2-9a5a094b7fe3"
   },
   "outputs": [],
   "source": [
    "data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Nrc_iZecEZEG",
    "outputId": "5b8b8e64-8cc9-4419-b652-08e15e9c788a"
   },
   "outputs": [],
   "source": [
    "cmap = categorical_cmap(4, len(VALIDATION_DATASETS))\n",
    "\n",
    "width = 0.2\n",
    "\n",
    "# data_pca[i_clusterer, i_model, i_dataset, i_value]\n",
    "best_pca = np.nanmax(data_pca, axis=-1)\n",
    "best_umap = np.nanmax(data_umap, axis=-1)\n",
    "\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "        continue\n",
    "    for i_model, model in enumerate(models):\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        ax = plt.axes()\n",
    "        my_data = np.NaN * np.ones((len(VALIDATION_DATASETS), 4))\n",
    "        for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "            i = 0\n",
    "            plt.bar(\n",
    "                i_dataset + i * width,\n",
    "                data_base[i_clusterer, i_model, i_dataset, 0],\n",
    "                width=width,\n",
    "                label=f\"{dataset}: original embeddings\",\n",
    "                color=cmap(i * 3 + i_dataset),\n",
    "            )\n",
    "            my_data[i_dataset, i] = data_base[i_clusterer, i_model, i_dataset, 0]\n",
    "            i += 1\n",
    "            plt.bar(\n",
    "                i_dataset + i * width,\n",
    "                data_base[i_clusterer, i_model, i_dataset, 1],\n",
    "                width=width,\n",
    "                label=f\"{dataset}: whitened embeddings\",\n",
    "                color=cmap(i * 3 + i_dataset),\n",
    "            )\n",
    "            my_data[i_dataset, i] = data_base[i_clusterer, i_model, i_dataset, 1]\n",
    "            i += 1\n",
    "            plt.bar(\n",
    "                i_dataset + i * width,\n",
    "                best_pca[i_clusterer, i_model, i_dataset],\n",
    "                width=width,\n",
    "                label=f\"{dataset}: PCA (best)\",\n",
    "                color=cmap(i * 3 + i_dataset),\n",
    "            )\n",
    "            my_data[i_dataset, i] = best_pca[i_clusterer, i_model, i_dataset]\n",
    "            i += 1\n",
    "            plt.bar(\n",
    "                i_dataset + i * width,\n",
    "                best_umap[i_clusterer, i_model, i_dataset],\n",
    "                width=width,\n",
    "                label=f\"{dataset}: UMAP (best)\",\n",
    "                color=cmap(i * 3 + i_dataset),\n",
    "            )\n",
    "            my_data[i_dataset, i] = best_umap[i_clusterer, i_model, i_dataset]\n",
    "\n",
    "        if clusterer in [\"AffinityPropagation\", \"SpectralClustering\", \"OPTICS\"]:\n",
    "            # Disregard imagenet results as it has too many samples to run\n",
    "            my_data = my_data[1:]\n",
    "\n",
    "        my_data = np.mean(my_data, axis=0)\n",
    "        hs = []\n",
    "        labels = [\n",
    "            \"original embeddings\",\n",
    "            \"whitened embeddings\",\n",
    "            \"PCA (best)\",\n",
    "            \"UMAP (best)\",\n",
    "        ]\n",
    "        i = 0\n",
    "        hs.append(\n",
    "            plt.bar(\n",
    "                1 + i_dataset + i * width,\n",
    "                my_data[i],\n",
    "                width=width,\n",
    "                label=labels[i],\n",
    "                color=cmap(i * 3),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "        hs.append(\n",
    "            plt.bar(\n",
    "                1 + i_dataset + i * width,\n",
    "                my_data[i],\n",
    "                width=width,\n",
    "                label=labels[i],\n",
    "                color=cmap(i * 3),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "        hs.append(\n",
    "            plt.bar(\n",
    "                1 + i_dataset + i * width,\n",
    "                my_data[i],\n",
    "                width=width,\n",
    "                label=labels[i],\n",
    "                color=cmap(i * 3),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "        hs.append(\n",
    "            plt.bar(\n",
    "                1 + i_dataset + i * width,\n",
    "                my_data[i],\n",
    "                width=width,\n",
    "                label=labels[i],\n",
    "                color=cmap(i * 3),\n",
    "            )\n",
    "        )\n",
    "        ax.set_xticks(\n",
    "            np.arange(len(VALIDATION_DATASETS) + 1) + width * i / 2,\n",
    "            VALIDATION_DATASETS + [\"mean\"],\n",
    "        )\n",
    "        plt.ylabel(\"AMI\")\n",
    "        try:\n",
    "            best_option = labels[np.nanargmax(my_data)]\n",
    "        except Exception:\n",
    "            best_option = \"n/a\"\n",
    "        plt.title(f\"{clusterer}, {model} [{best_option}]\")\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        # plt.legend(handles=hs)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPL41TyPT9_0",
    "outputId": "ba356b18-fe30-46c3-dff5-499f384ecdb3"
   },
   "outputs": [],
   "source": [
    "data_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YqnfKA7ksJw",
    "outputId": "5683371d-3dc4-461b-925c-4e567020afe6"
   },
   "outputs": [],
   "source": [
    "len(VALIDATION_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kBFncKpIUAfv",
    "outputId": "42b9e04e-6de4-4088-c0c8-d957ec7f55b9"
   },
   "outputs": [],
   "source": [
    "dim_choices_rows = []\n",
    "eps = 1e-3\n",
    "\n",
    "# cmap = categorical_cmap(len(models), len(CLUSTERERS))\n",
    "cmap = categorical_cmap(4, len(VALIDATION_DATASETS))\n",
    "\n",
    "axis_values = [2, 5, 10, 20, 50, 100, 200, 500]\n",
    "# axis_values = [2, 5, 10, 20, 50, 100, 200]\n",
    "\n",
    "i = 0\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "        continue\n",
    "    for i_model, model in enumerate(models):\n",
    "        i += 1\n",
    "        my_data_p = data_pca[i_clusterer, i_model]  # [:, :-1]\n",
    "        my_data_u = data_umap[i_clusterer, i_model]  # [:, :-1]\n",
    "        my_data_pvar = data_pca_var[i_clusterer, i_model]\n",
    "        if clusterer in [\"AffinityPropagation\", \"SpectralClustering\", \"OPTICS\"]:\n",
    "            # No imagenet results as it has too many samples\n",
    "            my_data_p = my_data_p[1:]\n",
    "            my_data_u = my_data_u[1:]\n",
    "            my_data_pvar = my_data_pvar[1:]\n",
    "        plt.figure()\n",
    "        # indiv\n",
    "        plt.plot(axis_values, my_data_p.T, \":\", color=cmap(2 * 3 + 2))\n",
    "        plt.plot(axis_values, my_data_u.T, \":\", color=cmap(3 * 3 + 2))\n",
    "        # mean\n",
    "        mu_data_p = np.mean(my_data_p, axis=0)\n",
    "        mu_data_u = np.mean(my_data_u, axis=0)\n",
    "        mu_data_pvar = np.mean(my_data_pvar, axis=0)\n",
    "        plt.plot(axis_values, mu_data_p, color=cmap(2 * 3))\n",
    "        plt.plot(axis_values, mu_data_u, color=cmap(3 * 3))\n",
    "        if (\n",
    "            sum(~np.isnan(mu_data_p)) == 0\n",
    "            or sum(~np.isnan(mu_data_u)) == 0\n",
    "            or sum(~np.isnan(mu_data_pvar)) == 0\n",
    "        ):\n",
    "            plt.title(f\"{clusterer}, {model} [MISSING DATA]\")\n",
    "            plt.xscale(\"log\")\n",
    "            plt.xlabel(\"Num dimensions\")\n",
    "            plt.ylabel(\"AMI\")\n",
    "            plt.ylim([-0.05, 1.05])\n",
    "            plt.show()\n",
    "            continue\n",
    "        best_pca_i = np.nanargmax(mu_data_p)\n",
    "        best_umap_i = np.nanargmax(mu_data_u)\n",
    "        best_pvar_i = np.nanargmax(mu_data_pvar)\n",
    "        if mu_data_p[best_pca_i] > mu_data_u[best_umap_i]:\n",
    "            best_reducer = \"PCA\"\n",
    "            best_d = axis_values[best_pca_i]\n",
    "            best_ami_plot = mu_data_p[best_pca_i]\n",
    "            plt.plot(best_d, best_ami_plot, \"kx\")\n",
    "            row = {\n",
    "                \"clusterer\": clusterer,\n",
    "                \"model\": model,\n",
    "                \"reducer\": \"PCA\",\n",
    "                \"dim\": best_d,\n",
    "            }\n",
    "        else:\n",
    "            best_reducer = \"UMAP\"\n",
    "            best_d = axis_values[best_umap_i]\n",
    "            best_ami_plot = mu_data_u[best_umap_i]\n",
    "            plt.plot(best_d, best_ami_plot, \"kx\")\n",
    "            row = {\n",
    "                \"clusterer\": clusterer,\n",
    "                \"model\": model,\n",
    "                \"reducer\": \"UMAP\",\n",
    "                \"dim\": best_d,\n",
    "            }\n",
    "        best_ami = np.nanmax(\n",
    "            [\n",
    "                max(data_base[i_clusterer, i_model, i_dataset]),\n",
    "                max(mu_data_p),\n",
    "                max(mu_data_u),\n",
    "                max(mu_data_pvar),\n",
    "            ]\n",
    "        )\n",
    "        if best_ami <= best_ami_plot:\n",
    "            extra_str = \"best\"\n",
    "        else:\n",
    "            extra_str = f\"< {best_ami:.3f} from\"\n",
    "            if best_ami == data_base[i_clusterer, i_model, i_dataset, 0]:\n",
    "                extra_str += \" full\"\n",
    "                if best_ami >= best_ami_plot + eps:\n",
    "                    row = {\"clusterer\": clusterer, \"model\": model, \"reducer\": \"OG\"}\n",
    "                    extra_str += \"*\"\n",
    "            if best_ami == data_base[i_clusterer, i_model, i_dataset, 1]:\n",
    "                extra_str += \" fullwhite\"\n",
    "                if best_ami >= best_ami_plot + eps:\n",
    "                    row = {\"clusterer\": clusterer, \"model\": model, \"reducer\": \"whiten\"}\n",
    "                    extra_str += \"*\"\n",
    "            if best_ami == max(mu_data_pvar):\n",
    "                extra_str += f\" PCA var={pca_var_values[best_pvar_i]}\"\n",
    "                if best_ami >= best_ami_plot + eps:\n",
    "                    row = {\n",
    "                        \"clusterer\": clusterer,\n",
    "                        \"model\": model,\n",
    "                        \"reducer\": \"PCA\",\n",
    "                        \"dim\": pca_var_values[best_pvar_i],\n",
    "                    }\n",
    "                    extra_str += \"*\"\n",
    "        plt.title(\n",
    "            f\"{clusterer}, {model}\"\n",
    "            f\"  [{best_reducer} {best_d}: AMI={best_ami_plot:.3f} ({extra_str})]\"\n",
    "        )\n",
    "        plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Num dimensions\")\n",
    "        plt.ylabel(\"AMI\")\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.show()\n",
    "        dim_choices_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ANCetb1cMRDE"
   },
   "outputs": [],
   "source": [
    "df_dim_choices = pd.DataFrame.from_records(dim_choices_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "id": "OwtO1oa6Mdgf",
    "outputId": "09547ec5-7564-4853-d7d3-7f4f93a9c8da"
   },
   "outputs": [],
   "source": [
    "df_dim_choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Y9aSjzsxOtm1",
    "outputId": "ba8d099d-17ae-48ef-d4ff-ab27e0de1ea8"
   },
   "outputs": [],
   "source": [
    "# cmap = categorical_cmap(len(models), len(CLUSTERERS))\n",
    "cmap = categorical_cmap(4, len(VALIDATION_DATASETS))\n",
    "\n",
    "i = 0\n",
    "for i_clusterer, clusterer in enumerate(CLUSTERERS):\n",
    "    if clusterer in [\"SpectralClustering\", \"OPTICS\"]:\n",
    "        continue\n",
    "    for i_model, model in enumerate(models):\n",
    "        i += 1\n",
    "        my_data_pvar = data_pca_var[i_clusterer, i_model]\n",
    "        if clusterer in [\"AffinityPropagation\", \"SpectralClustering\", \"OPTICS\"]:\n",
    "            # No imagenet results as it has too many samples\n",
    "            my_data_pvar = my_data_pvar[1:]\n",
    "        plt.figure()\n",
    "        # indiv\n",
    "        plt.plot(pca_var_values, my_data_pvar.T, \":\", color=cmap(2 * 3 + 2))\n",
    "        # mean\n",
    "        mu_data_pvar = np.mean(my_data_pvar, axis=0)\n",
    "        plt.plot(pca_var_values, mu_data_pvar, color=cmap(2 * 3))\n",
    "        plt.title(f\"{clusterer}, {model}\")\n",
    "        # plt.xscale(\"log\")\n",
    "        plt.xlabel(\"Variance kept\")\n",
    "        plt.ylabel(\"AMI\")\n",
    "        plt.ylim([-0.05, 1.05])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eAgJs3H-uqiJ"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "BEST_PARAMS = {\n",
    "    clusterer: {model: copy.deepcopy(DEFAULT_PARAMS[clusterer]) for model in models}\n",
    "    for clusterer in CLUSTERERS\n",
    "}\n",
    "\n",
    "# KMeans\n",
    "# Use UMAP (num dims unimportant; we select 50d for consistency) for every encoder except\n",
    "# - clip_RN50 : a little better to use PCA with 500d than UMAP. UMAP beats PCA if you\n",
    "#   reduce the PCA dims below 500.\n",
    "# - clip_vitb16 : same behaviour as clip_RN50\n",
    "# - timm_vit_base_patch16_224.mae : best is PCA 0.85 variance explained. Need at least\n",
    "#   200 PCA dims, and PCA perf beats UMAP throughout\n",
    "\n",
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    if model.startswith(\"clip\") or model == \"timm_vit_base_patch16_224.mae\":\n",
    "        continue\n",
    "    BEST_PARAMS[\"KMeans\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"KMeans\"][\"clip_RN50\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"ndim_reduced\": 500, \"zscore\": True, \"pca_variance\": None}\n",
    ")\n",
    "BEST_PARAMS[\"KMeans\"][\"clip_vitb16\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"ndim_reduced\": 500, \"zscore\": True, \"pca_variance\": None}\n",
    ")\n",
    "BEST_PARAMS[\"KMeans\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"pca_variance\": 0.85, \"zscore\": True, \"ndim_reduced\": None}\n",
    ")\n",
    "\n",
    "# AffinityPropagation\n",
    "# Use PCA with 10 dims for every encoder except\n",
    "# - resnet50 (supervised) : original embeddings, no reduction (AMI=0.62);\n",
    "#   perf gets worse if they are whitened (AMI=0.55) and although the perf increases\n",
    "#   as num dims are reduced it doesn't quite recover. PCA perf peaks at 10-20 dim (AMI=0.57).\n",
    "# - dino_resnet50 : does marginally better at UMAP 50 (AMI=0.52495) than PCA 10 (AMI=0.5044)\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.95 variance explained (AMI=0.303).\n",
    "#   Definite improvement from 10 to 20 dims, but not much improvement above that.\n",
    "\n",
    "for model in models:\n",
    "    if model in [\"resnet50\", \"dino_resnet50\", \"timm_vit_base_patch16_224.mae\"]:\n",
    "        continue\n",
    "    BEST_PARAMS[\"AffinityPropagation\"][model].update(\n",
    "        {\n",
    "            \"dim_reducer\": \"PCA\",\n",
    "            \"ndim_reduced\": 10,\n",
    "            \"zscore\": True,\n",
    "            \"pca_variance\": None,\n",
    "            \"dim_reducer_man\": \"None\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"resnet50\"].update(\n",
    "    {\"dim_reducer\": \"None\", \"dim_reducer_man\": \"None\", \"zscore\": False}\n",
    ")\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"dino_resnet50\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# AgglomerativeClustering\n",
    "# Use UMAP (num dims unimportant; we select 50d for consistency) for every encoder except\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.98 variance explained (i.e. nearly all\n",
    "#   dimensions kept), which is not noticably better than using 500 dim PCA but there is\n",
    "#   an increase compared to using less than 500d.\n",
    "\n",
    "for model in models:\n",
    "    if model == \"timm_vit_base_patch16_224.mae\":\n",
    "        continue\n",
    "    BEST_PARAMS[\"AgglomerativeClustering\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50, \"dim_reducer\": \"None\"}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"AgglomerativeClustering\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.98,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# HDBSCAN\n",
    "# Use UMAP for every encoder except\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.95 variance explained (AMI=0.085) which is\n",
    "#   not noticably better than PCA with 50 dim\n",
    "\n",
    "for model in models:\n",
    "    if model in [\"timm_vit_base_patch16_224.mae\"]:\n",
    "        continue\n",
    "    BEST_PARAMS[\"HDBSCAN\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50, \"dim_reducer\": \"None\"}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"HDBSCAN\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53fFD0J2c6e7"
   },
   "source": [
    "## AgglomerativeClustering metric and linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "2w-hy7aHQ-AP",
    "outputId": "8687d9c8-b1aa-4bfe-9f72-49a9f0cce926"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "clusterer = \"AgglomerativeClustering\"\n",
    "methods = [\"ward\", \"complete\", \"average\", \"single\"]\n",
    "metrics = [\"euclidean\", \"l1\", \"cosine\", \"chebyshev\"]  # \"arccos\"\n",
    "\n",
    "data = np.NaN * np.ones(\n",
    "    (len(models), len(VALIDATION_DATASETS), len(methods), len(metrics))\n",
    ")\n",
    "cmds = []\n",
    "for i_model, model in enumerate(models):\n",
    "    for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "        for i_method, method in enumerate(methods):\n",
    "            for i_metric, metric in enumerate(metrics):\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                    # \"dim_reducer_man\": \"UMAP\",\n",
    "                    # \"ndim_reduced_man\": 50,\n",
    "                    \"distance_metric\": metric,\n",
    "                    \"aggclust_linkage\": method,\n",
    "                    \"aggclust_dist_thresh\": None,\n",
    "                }\n",
    "                sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    if method == \"ward\" and metric not in [\"euclidean\", \"arccos\"]:\n",
    "                        # expected not to exist\n",
    "                        continue\n",
    "                    print(\"No data for\", filter)\n",
    "                    cmds.append(filter2command(filter, filter2))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                data[i_model, i_dataset, i_method, i_metric] = np.median(sdf[\"AMI\"])\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvNQovQqm-0P",
    "outputId": "2644c936-f7be-4ed1-f3a1-40d1e8d64436"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "eL4k6iWouvBJ",
    "outputId": "8f241534-dfae-42f7-ab64-b7249e9c9f14"
   },
   "outputs": [],
   "source": [
    "np.sum(np.isnan(data)) / data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Eq1ZnGtRup65",
    "outputId": "540d5190-d11a-48b2-b8b3-4217977a6d1f"
   },
   "outputs": [],
   "source": [
    "cmap = categorical_cmap(len(metrics), len(methods))\n",
    "\n",
    "width = 1 / (len(methods) * len(metrics) + 2)\n",
    "YLIM = [-0.05, 1.05]\n",
    "for i_model, model in enumerate(models):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes()\n",
    "    # for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "    i = 0\n",
    "    for i_metric, metric in enumerate(metrics):\n",
    "        for i_method, method in enumerate(methods):\n",
    "            plt.bar(\n",
    "                np.arange(len(VALIDATION_DATASETS)) + i * width,\n",
    "                data[i_model, :, i_method, i_metric],\n",
    "                width=width,\n",
    "                label=f\"{metric}: {method}\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    ax.set_xticks(\n",
    "        np.arange(len(VALIDATION_DATASETS)) + width * (i + 1) / 2, VALIDATION_DATASETS\n",
    "    )\n",
    "    plt.ylim(YLIM)\n",
    "    plt.title(model)\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "A_MjtzkG1MX4",
    "outputId": "b94d59bf-e38b-4552-98ff-82e312719c0d"
   },
   "outputs": [],
   "source": [
    "agglink_choices_rows = []\n",
    "\n",
    "cmap = categorical_cmap(len(metrics), len(methods))\n",
    "\n",
    "avg_ami = np.mean(data, axis=1)\n",
    "\n",
    "width = 1 / (len(methods) + 2)\n",
    "YLIM = [-0.05, 1.05]\n",
    "for i_model, model in enumerate(models):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = plt.axes()\n",
    "    # for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "    i = 0\n",
    "    min_ami = 1\n",
    "    max_ami = 0\n",
    "    for i_metric, metric in enumerate(metrics):\n",
    "        for i_method, method in enumerate(methods):\n",
    "            my_val = avg_ami[i_model, i_method, i_metric]\n",
    "            min_ami = np.nanmin([min_ami, my_val])\n",
    "            max_ami = np.nanmax([max_ami, my_val])\n",
    "            plt.bar(\n",
    "                i_metric + i_method * width,\n",
    "                my_val,\n",
    "                width=width,\n",
    "                label=f\"{metric}: {method}\",\n",
    "                color=cmap(i),\n",
    "            )\n",
    "            i += 1\n",
    "    best_method_idx, best_metric_idx = np.unravel_index(\n",
    "        np.nanargmax(avg_ami[i_model]),\n",
    "        avg_ami[i_model].shape,\n",
    "    )\n",
    "    ax.set_xticks(np.arange(len(metrics)) + width * (i_method + 1) / 2, metrics)\n",
    "    YLIM = np.array([min_ami, max_ami])\n",
    "    YLIM += np.array([-1, 1]) * 0.05 * (YLIM[1] - YLIM[0])\n",
    "    plt.ylim(YLIM)\n",
    "    plt.title(\n",
    "        f\"{model} : {metrics[best_metric_idx]} {methods[best_method_idx]}\"\n",
    "        f\"  (AMI={avg_ami[i_model, best_method_idx, best_metric_idx]:.3f})\"\n",
    "        f\"  ... {np.sort(avg_ami[i_model][~np.isnan(avg_ami[i_model])], axis=None)[-1:-5:-1]}\"\n",
    "    )\n",
    "    plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.show()\n",
    "    row = {\n",
    "        \"model\": model,\n",
    "        \"distance_metric\": metrics[best_metric_idx],\n",
    "        \"aggclust_linkage\": methods[best_method_idx],\n",
    "    }\n",
    "    agglink_choices_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "tzPoNNF9UB_a",
    "outputId": "8514fe39-7eeb-4d19-db76-38ceab03fc69"
   },
   "outputs": [],
   "source": [
    "avg_ami[np.array(models) == \"vicreg_resnet50\", np.array(methods) == \"average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "AAZv_uI5Ut3T",
    "outputId": "409d44c9-2d46-4672-ffcc-45fe564a7938"
   },
   "outputs": [],
   "source": [
    "avg_ami[np.array(models) == \"vitb16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "j0EVjGW3EEaN",
    "outputId": "91f5ed7c-b6b2-4229-e902-1c0fa8c461ec"
   },
   "outputs": [],
   "source": [
    "agglink_choices_df = pd.DataFrame.from_dict(agglink_choices_rows)\n",
    "agglink_choices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JgZudrwYujir"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": agglink_choices_df[agglink_choices_df[\"model\"] == model][\n",
    "                \"distance_metric\"\n",
    "            ].item(),\n",
    "            \"aggclust_linkage\": agglink_choices_df[\n",
    "                agglink_choices_df[\"model\"] == model\n",
    "            ][\"aggclust_linkage\"].item(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWdzGsvictp5"
   },
   "source": [
    "## AgglomerativeClustering distance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "-I6kIReSCGWr",
    "outputId": "c306aa65-ad9d-41ce-cabb-3e808525b09e"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "cmap = categorical_cmap(len(models), len(VALIDATION_DATASETS))\n",
    "clusterer = \"AgglomerativeClustering\"\n",
    "distance_thresholds = [\n",
    "    0.001,\n",
    "    0.002,\n",
    "    0.005,\n",
    "    0.01,\n",
    "    0.02,\n",
    "    0.05,\n",
    "    0.1,\n",
    "    0.2,\n",
    "    0.5,\n",
    "    1.0,\n",
    "    2.0,\n",
    "    5.0,\n",
    "    10.0,\n",
    "    20.0,\n",
    "    50.0,\n",
    "    100.0,\n",
    "    200.0,\n",
    "    500.0,\n",
    "    1000.0,\n",
    "    2000.0,\n",
    "    5000.0,\n",
    "]\n",
    "\n",
    "data = np.NaN * np.ones(\n",
    "    (len(models), len(VALIDATION_DATASETS), len(distance_thresholds))\n",
    ")\n",
    "cmds = []\n",
    "for i_model, model in enumerate(models):\n",
    "    for i_dataset, dataset in enumerate(VALIDATION_DATASETS):\n",
    "        for i_thr, thr in enumerate(distance_thresholds):\n",
    "            filter = {\n",
    "                \"model\": model,\n",
    "                \"dataset\": dataset,\n",
    "                \"clusterer\": clusterer,\n",
    "                \"aggclust_dist_thresh\": thr,\n",
    "            }\n",
    "            sdf = select_rows(runs_df, filter, allow_missing=False)\n",
    "            filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "            filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "            sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "            if len(sdf) < 1:\n",
    "                print(f\"No data for {filter} {filter2}\")\n",
    "                cmds.append(filter2command(filter, filter2))\n",
    "                continue\n",
    "            if len(sdf) > 1:\n",
    "                perf = sdf.iloc[0][\"AMI\"]\n",
    "                if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                    print()\n",
    "                    print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                    print(f\"for search {filter}\\nand {filter2}\")\n",
    "                    dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                    print(f\"columns which differ: {dif_cols}\")\n",
    "                    if dif_cols:\n",
    "                        for col in dif_cols:\n",
    "                            print(f\"  {col}: {list(sdf[col])}\")\n",
    "            data[i_model, i_dataset, i_thr] = np.mean(sdf[\"AMI\"])\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWmU_WHSDKU1",
    "outputId": "b02932a1-b8d4-4919-9bbe-8905e0ff8782"
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GSE2Wp52DYVV",
    "outputId": "60a3863a-6b8a-4666-f0da-e6caea77149d"
   },
   "outputs": [],
   "source": [
    "aggthresh_choices_rows = []\n",
    "\n",
    "for i_model, model in enumerate(models):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    ax = plt.axes()\n",
    "    # indiv\n",
    "    plt.plot(distance_thresholds, data[i_model].T, \":\", color=\"grey\")\n",
    "    # mean\n",
    "    mu_data = np.mean(data[i_model], axis=0)\n",
    "    if np.all(np.isnan(mu_data)):\n",
    "        print(f\"No data for {model}\")\n",
    "        continue\n",
    "    i_thr = np.nanargmax(mu_data)\n",
    "    best_thr = distance_thresholds[i_thr]\n",
    "    plt.plot(best_thr, mu_data[i_thr], \"x\")\n",
    "    plt.plot(distance_thresholds, mu_data, color=\"black\")\n",
    "    plt.title(f\"{model} (thr={best_thr}, AMI={mu_data[i_thr]})\")\n",
    "    # plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Distance threshold\")\n",
    "    plt.ylabel(\"AMI\")\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xscale(\"log\")\n",
    "    plt.show()\n",
    "    row = {\"model\": model, \"aggclust_dist_thresh\": best_thr}\n",
    "    aggthresh_choices_rows.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "QYspXfe1ifWj",
    "outputId": "dde9e4f8-7d11-4345-c714-c21536a098be"
   },
   "outputs": [],
   "source": [
    "aggthresh_choices_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "8NkFFQJ6ilMY",
    "outputId": "95cd387a-a5bc-4eef-ca77-dd7b83788bed"
   },
   "outputs": [],
   "source": [
    "aggthresh_choices_df = pd.DataFrame.from_dict(aggthresh_choices_rows)\n",
    "aggthresh_choices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "t1WAi6d_i3tA"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"aggclust_dist_thresh\": aggthresh_choices_df[\n",
    "                agglink_choices_df[\"model\"] == model\n",
    "            ][\"aggclust_dist_thresh\"].item(),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOKljXoMNGG7"
   },
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "dytOzTA3NMeF",
    "outputId": "3cf97ecd-b9af-44dc-c21b-d128ef0ba249"
   },
   "outputs": [],
   "source": [
    "# Project is specified by <entity/project-name>\n",
    "api = wandb.Api()\n",
    "runs_test = api.runs(\n",
    "    \"uoguelph_mlrg/zs-ssl-clustering\",\n",
    "    filters={\"state\": \"Finished\", \"config.partition\": \"test\"},\n",
    ")\n",
    "len(runs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "522p4kwrJd06"
   },
   "outputs": [],
   "source": [
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs_test:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "rows = []\n",
    "config_keys = set()\n",
    "summary_keys = set()\n",
    "for summary, config, name in zip(summary_list, config_list, name_list):\n",
    "    row = {\"name\": name}\n",
    "    row.update({k: v for k, v in config.items() if not k.startswith(\"_\")})\n",
    "    row.update({k: v for k, v in summary.items() if not k.startswith(\"_\")})\n",
    "    rows.append(row)\n",
    "    config_keys = config_keys.union(config.keys())\n",
    "    summary_keys = summary_keys.union(summary.keys())\n",
    "\n",
    "test_runs_df = pd.DataFrame.from_records(rows)\n",
    "\n",
    "# Handle changed default value for spectral_assigner after config arg was introduced\n",
    "if \"spectral_assigner\" not in test_runs_df.columns:\n",
    "    test_runs_df[\"spectral_assigner\"] = None\n",
    "select = test_runs_df[\"clusterer_name\"] != \"SpectralClustering\"\n",
    "test_runs_df.loc[select, \"spectral_assigner\"] = None\n",
    "select = (test_runs_df[\"clusterer_name\"] == \"SpectralClustering\") & pd.isna(\n",
    "    test_runs_df[\"spectral_assigner\"]\n",
    ")\n",
    "test_runs_df.loc[select, \"spectral_assigner\"] = \"kmeans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "k_KrOF5GNj9l",
    "outputId": "aa2cee0f-6313-4559-92b5-fc6b9a1fbfb5"
   },
   "outputs": [],
   "source": [
    "test_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Oc999K7NoA9",
    "outputId": "c6700db7-2e2f-4f73-c070-6e663e090937"
   },
   "outputs": [],
   "source": [
    "list(test_runs_df[\"dataset_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CuPbp58ONv4Z"
   },
   "outputs": [],
   "source": [
    "TEST_DATASETS = [\n",
    "    \"imagenet\",\n",
    "    \"cifar10\",\n",
    "    \"cifar100\",\n",
    "    \"mnist\",\n",
    "    \"fashionmnist\",\n",
    "    \"svhn\",\n",
    "    \"flowers102\",\n",
    "    \"aircraft\",\n",
    "    \"nabirds\",\n",
    "    \"inaturalist\",\n",
    "]\n",
    "DATASET2SH = {\n",
    "    \"aircraft\": \"Aircraft\",\n",
    "    \"cifar10\": \"C10\",\n",
    "    \"cifar100\": \"C100\",\n",
    "    \"flowers102\": \"Flowers\",\n",
    "    \"fashionmnist\": \"fMNIST\",\n",
    "    \"imagenet\": \"IN1k\",\n",
    "    \"imagenette\": \"IN10\",\n",
    "    \"imagewoof\": \"INwf\",\n",
    "    \"inaturalist\": \"iNat21\",\n",
    "    \"mnist\": \"MNIST\",\n",
    "    \"nabirds\": \"NABirds\",\n",
    "    \"svhn\": \"SVHN\",\n",
    "}\n",
    "MODEL_GROUPS = {\n",
    "    \"ResNet-50\": RESNET50_MODELS,\n",
    "    \"ViT-B\": VITB16_MODELS,\n",
    "}\n",
    "MODEL2SH = {\n",
    "    \"resnet50\": \"Supervised\",\n",
    "    \"mocov3_resnet50\": \"MoCo-v3\",\n",
    "    \"vicreg_resnet50\": \"VICReg\",\n",
    "    \"dino_resnet50\": \"DINO\",\n",
    "    \"clip_RN50\": \"CLIP\",\n",
    "    \"vitb16\": \"Supervised\",\n",
    "    \"mocov3_vit_base\": \"MoCo-v3\",\n",
    "    \"timm_vit_base_patch16_224.mae\": \"MAE\",\n",
    "    \"dino_vitb16\": \"DINO\",\n",
    "    \"clip_vitb16\": \"CLIP\",\n",
    "}\n",
    "CLUSTERER2SH = {\n",
    "    \"KMeans\": \"K-Means\",\n",
    "    \"AffinityPropagation\": \"Affinity Prop\",\n",
    "    \"AgglomerativeClustering\": \"AC\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZYGEjWvWWO2"
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cBYVKo7PZFY",
    "outputId": "eb891142-6db6-48ac-a63f-3de372ab256b"
   },
   "outputs": [],
   "source": [
    "metric_key = \"AMI\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "# KMeans  AffinityPropagation  AgglomerativeClustering  HDBSCAN\n",
    "clusterer = \"AffinityPropagation\"\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {clusterer}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    latex_table += r\"\\label{tab:\" + clusterer + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Encoder':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    for i_group, model_group_name in enumerate(list(MODEL_GROUPS.keys())):\n",
    "        if i_group > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "        for i_model, model in enumerate(MODEL_GROUPS[model_group_name]):\n",
    "            if i_model == 0:\n",
    "                latex_table += (\n",
    "                    r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                    + model_group_name\n",
    "                    + \"}}}\"\n",
    "                )\n",
    "                latex_table += \"\\n\"\n",
    "            latex_table += f\"& {MODEL2SH.get(model, model):<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += \" $\"\n",
    "                if is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                latex_table += \"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {clusterer}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-9lxUOUuhaj"
   },
   "source": [
    "### GROUPING BY SSL ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8sCItDK_2VT",
    "outputId": "0c9b0bab-68e6-4816-dfea-e417cf05e77a"
   },
   "outputs": [],
   "source": [
    "metric_key = \"AMI\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "backbone = \"ViT-B\"\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {backbone}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    latex_table += r\"\\label{tab:\" + backbone + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Clusterer':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "        print(model)\n",
    "        if i_group > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            if i_clusters == 0:\n",
    "                latex_table += (\n",
    "                    r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                    + MODEL2SH[model]\n",
    "                    + \"}}}\"\n",
    "                )\n",
    "                latex_table += \"\\n\"\n",
    "            override_fields = {}\n",
    "            clusterername = CLUSTERER2SH.get(clusterer, clusterer)\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                clusterername = \"AC w/o C\"\n",
    "            latex_table += f\"& {clusterername:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += \" $\"\n",
    "                if is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                latex_table += \"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {clusterer}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_isFUjNsuYc4"
   },
   "source": [
    "### GROUPING BY CLUSTERER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UkhJKXC5p7GE"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "MyWQRN9iqBkI",
    "outputId": "1336e7b3-1234-4ef3-cbff-a574480c54d5"
   },
   "outputs": [],
   "source": [
    "metric_key = \"num_cluster_pred\"  # AMI num_cluster_pred\n",
    "show_pc = True\n",
    "show_fmt = \"{:4.0f}\"\n",
    "highlight_best = True\n",
    "eps = 0.005\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "backbone = \"ViT-B\"  # \"ResNet-50\" or \"ViT-B\"\n",
    "\n",
    "if metric_key == \"num_cluster_pred\":\n",
    "    CLUSTERERS = [\"AgglomerativeClustering\", \"AffinityPropagation\", \"HDBSCAN\"]\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:4.0f}\"\n",
    "    highlight_best = False\n",
    "else:\n",
    "    CLUSTERERS = [\n",
    "        \"KMeans\",\n",
    "        \"AgglomerativeClustering\",\n",
    "        \"AgglomerativeClustering\",\n",
    "        \"AffinityPropagation\",\n",
    "        \"HDBSCAN\",\n",
    "    ]\n",
    "if metric_key.startswith(\"silhouette\"):\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:5.2f}\"\n",
    "\n",
    "print(MODEL2SH)\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "best_results_grouped = {k: defaultdict(lambda: []) for k in TEST_DATASETS}\n",
    "\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {backbone}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    label = backbone\n",
    "    if metric_key == \"AMI\":\n",
    "        latex_table += r\"\\label{tab:\" + label + r\"}\" + \"\\n\"\n",
    "    label = metric_key.replace(\"_\", \"-\") + \":\" + label\n",
    "    latex_table += r\"\\label{tab:\" + label + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Encoder':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    if metric_key == \"num_cluster_pred\":\n",
    "        latex_table += r\"& Num targets\"\n",
    "        for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "            sdf = select_rows(test_runs_df, {\"dataset\": dataset}, allow_missing=False)\n",
    "            sdf = sdf[~pd.isna(sdf[\"num_cluster_true\"])]\n",
    "            latex_table += r\"& \" + f\"${sdf.iloc[0]['num_cluster_true'].item()}$\"\n",
    "        latex_table += r\"\\\\\" + \"\\n\"\n",
    "        latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    elif metric_key.endswith(\"_pred\"):\n",
    "        metric_key2 = metric_key.replace(\"_pred\", \"_true\")\n",
    "        clusterername = \"G.T.\"\n",
    "        latex_table += (\n",
    "            r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "            + clusterername\n",
    "            + \"}}}\"\n",
    "        )\n",
    "        latex_table += \"\\n\"\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\"model\": model, \"dataset\": dataset}\n",
    "                if model == \"timm_vit_base_patch16_224.mae\":\n",
    "                    filter[\"dim_reducer\"] = \"PCA\"\n",
    "                    filter[\"pca_variance\"] = 0.95\n",
    "                else:\n",
    "                    filter[\"dim_reducer_man\"] = \"UMAP\"\n",
    "                    filter[\"ndim_reduced_man\"] = 50\n",
    "                    filter[\"dim_reducer_man_metric\"] = \"euclidean\"\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                sdf = sdf[~pd.isna(sdf[metric_key2])]\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "\n",
    "                if sum(sdf[metric_key2] != my_val) > 0:\n",
    "                    print()\n",
    "                    print(\n",
    "                        f\"More than one result with {metric_key2} values:\",\n",
    "                        list(sdf[metric_key2]),\n",
    "                    )\n",
    "                    print(f\"for search {filter}\")\n",
    "                    dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                    print(f\"columns which differ: {dif_cols}\")\n",
    "                    if dif_cols:\n",
    "                        for col in dif_cols:\n",
    "                            print(f\"  {col}: {list(sdf[col])}\")\n",
    "\n",
    "                if dummy:\n",
    "                    best_results_grouped[dataset][clusterername].append(my_val)\n",
    "                    continue\n",
    "                is_best_grp = my_val + eps >= np.max(\n",
    "                    best_results_grouped[dataset][clusterername]\n",
    "                )\n",
    "                latex_table += \" $\"\n",
    "                latex_table += \"     \"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best_grp:\n",
    "                    latex_table += r\"\\tcg{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                if highlight_best:\n",
    "                    latex_table += r\"}\" if is_best_grp else \" \"\n",
    "                latex_table += \"$\"\n",
    "\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "        latex_table += r\"\\toprule\" + \"\\n\"\n",
    "\n",
    "    first_agg = True\n",
    "    for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "        override_fields = {}\n",
    "        clusterername = CLUSTERER2SH.get(clusterer, clusterer)\n",
    "        if (\n",
    "            first_agg\n",
    "            and clusterer == \"AgglomerativeClustering\"\n",
    "            and metric_key != \"num_cluster_pred\"\n",
    "        ):\n",
    "            first_agg = False\n",
    "            override_fields = {\"aggclust_dist_thresh\": None}\n",
    "            clusterername = \"AC  w/ C\"\n",
    "        elif clusterer == \"AgglomerativeClustering\":\n",
    "            clusterername = \"AC w/o C\"\n",
    "\n",
    "        if i_clusters > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "        latex_table += (\n",
    "            r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "            + clusterername\n",
    "            + \"}}}\"\n",
    "        )\n",
    "        latex_table += \"\\n\"\n",
    "\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            print(model)\n",
    "\n",
    "            latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    best_results_grouped[dataset][clusterername].append(my_val)\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                is_best_grp = my_val + eps >= np.max(\n",
    "                    best_results_grouped[dataset][clusterername]\n",
    "                )\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += \" $\"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best_grp:\n",
    "                    latex_table += r\"\\tcg{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                if highlight_best:\n",
    "                    latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                    latex_table += r\"}\" if is_best_grp else \" \"\n",
    "                latex_table += \"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {metric_key}, {backbone}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWpBwhP8MOm0"
   },
   "source": [
    "### Correlation between AMI and SIlhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lU7C4-fBpl5R",
    "outputId": "910c85bf-429d-4d91-c173-31d1efbe4764"
   },
   "outputs": [],
   "source": [
    "best_results_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "Gp5BaVDxG2Il",
    "outputId": "f515a710-a8ed-402a-d618-3bf9f4f07c6c"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-euclidean_pred\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "backbone = \"ViT-B\"\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(5, 3))\n",
    "\n",
    "\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "\n",
    "correlations = {\"ResNet-50\": [], \"ViT-B\": []}\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    my_valx_overall = []\n",
    "    my_valy_overall = []\n",
    "\n",
    "    my_valx_method = {clusterer: [] in CLUSTERERS}\n",
    "    my_valy_method = {clusterer: [] in CLUSTERERS}\n",
    "    best_results = {k: [] for k in TEST_DATASETS}\n",
    "\n",
    "    for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "        my_valx = []\n",
    "        my_valy = []\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            clusterername = clusterer\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                override_fields = {}\n",
    "                clusterername = \"AC w/o C\"\n",
    "\n",
    "            for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "                if i_group == 0:\n",
    "                    latex_table += (\n",
    "                        r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                        + clusterername\n",
    "                        + \"}}}\"\n",
    "                    )\n",
    "                    latex_table += \"\\n\"\n",
    "\n",
    "                latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                my_valx.append(np.mean(sdf[metric_key1]))\n",
    "                my_valy.append(np.mean(sdf[metric_key2]))\n",
    "\n",
    "                my_valx_method[clusterer].append(np.mean(sdf[metric_key1]))\n",
    "                my_valy_method[clusterer].append(np.mean(sdf[metric_key2]))\n",
    "\n",
    "        correlations[backbone].append(np.corrcoef(my_valx, my_valy)[0, 1])\n",
    "\n",
    "        ax[i_backbone].scatter(\n",
    "            my_valy,\n",
    "            my_valx,\n",
    "            color=colors[i_dataset],\n",
    "            alpha=0.5,\n",
    "            label=TEST_DATASETS[i_dataset],\n",
    "        )\n",
    "        my_valx_overall.extend(my_valx)\n",
    "        my_valy_overall.extend(my_valy)\n",
    "        ax[i_backbone].set_xlabel(r\"$S$\")\n",
    "        if i_backbone == 0:\n",
    "            ax[i_backbone].set_ylabel(metric_key1)\n",
    "        ax[i_backbone].set_ylim(-0.05, 1.05)\n",
    "        ax[i_backbone].set_xlim(-1.05, 1.05)\n",
    "        ax[i_backbone].set_title(\n",
    "            f\"{backbone}\\nPCC: {np.corrcoef(my_valx_overall, my_valy_overall)[0,1]:.2f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "label_fn = lambda c, marker: plt.plot(  # noqa:E731\n",
    "    [], [], color=c, ls=\"None\", marker=marker, linewidth=6\n",
    ")[0]\n",
    "handles = [label_fn(colors[idx], \"o\") for idx in range(len(TEST_DATASETS))]\n",
    "data_labels = [DATASET2SH.get(dataset, dataset) for dataset in TEST_DATASETS]\n",
    "\n",
    "ax[1].legend(handles, data_labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "print(data_labels)\n",
    "print(correlations[\"ResNet-50\"], len(correlations[\"ResNet-50\"]))\n",
    "print(correlations[\"ViT-B\"], len(correlations[\"ViT-B\"]))\n",
    "\n",
    "fig.savefig(\"ami_silhouette.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "id": "eSlyPO1kbM2u",
    "outputId": "aff5b114-640b-4b22-d5fc-0a066cf288f5"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-euclidean_pred\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "backbone = \"ViT-B\"\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(5.5, 3))\n",
    "\n",
    "colors = [\n",
    "    \"tab:red\",\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "\n",
    "correlations = {\"ResNet-50\": [], \"ViT-B\": []}\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    my_valx_overall = []\n",
    "    my_valy_overall = []\n",
    "    best_results = {k: [] for k in TEST_DATASETS}\n",
    "\n",
    "    for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "        my_valx = []\n",
    "        my_valy = []\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            clusterername = clusterer\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                override_fields = {}\n",
    "                clusterername = \"AC w/o C\"\n",
    "\n",
    "            for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "                if i_group == 0:\n",
    "                    latex_table += (\n",
    "                        r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                        + clusterername\n",
    "                        + \"}}}\"\n",
    "                    )\n",
    "                    latex_table += \"\\n\"\n",
    "\n",
    "                latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                my_valx.append(np.mean(sdf[metric_key1]))\n",
    "                my_valy.append(np.mean(sdf[metric_key2]))\n",
    "\n",
    "        correlations[backbone].append(np.corrcoef(my_valx, my_valy)[0, 1])\n",
    "\n",
    "        ax[i_backbone].scatter(\n",
    "            my_valy,\n",
    "            my_valx,\n",
    "            color=colors[i_dataset],\n",
    "            alpha=0.5,\n",
    "            s=8,\n",
    "            label=TEST_DATASETS[i_dataset],\n",
    "        )\n",
    "        my_valx_overall.extend(my_valx)\n",
    "        my_valy_overall.extend(my_valy)\n",
    "\n",
    "    ax[i_backbone].set_xlabel(r\"$S$\")\n",
    "    if i_backbone == 0:\n",
    "        ax[i_backbone].set_ylabel(metric_key1)\n",
    "    ax[i_backbone].set_ylim(-0.05, 1.05)\n",
    "    ax[i_backbone].set_xlim(-1.05, 1.05)\n",
    "    ax[i_backbone].set_title(backbone)\n",
    "    ax[i_backbone].text(\n",
    "        -0.85, 0.95, f\"$r={np.corrcoef(my_valx_overall, my_valy_overall)[0,1]:.2f}$\"\n",
    "    )\n",
    "\n",
    "\n",
    "label_fn = lambda c, marker: plt.plot(  # noqa:E731\n",
    "    [], [], color=c, ls=\"None\", marker=marker, linewidth=6\n",
    ")[0]\n",
    "handles = [label_fn(colors[idx], \"o\") for idx in range(len(TEST_DATASETS))]\n",
    "data_labels = [DATASET2SH.get(dataset, dataset) for dataset in TEST_DATASETS]\n",
    "\n",
    "ax[1].legend(handles, data_labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "print(data_labels)\n",
    "print(correlations[\"ResNet-50\"], len(correlations[\"ResNet-50\"]))\n",
    "print(correlations[\"ViT-B\"], len(correlations[\"ViT-B\"]))\n",
    "\n",
    "fig.savefig(\"ami_silhouette.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "MuURKU9mMXIN",
    "outputId": "a63485cb-5785-4e17-9ec9-913047946c33"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-euclidean_pred\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "figenc, axenc = plt.subplots(1, 2, figsize=(6, 2))\n",
    "figclus, axclus = plt.subplots(1, 2, figsize=(6, 2))\n",
    "\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    result_table = np.zeros(\n",
    "        (5, len(CLUSTERERS), len(TEST_DATASETS))\n",
    "    )  # Encoders, clusteres, dataset\n",
    "    for dummy in [True, False]:\n",
    "        cmds = []\n",
    "\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            first_agg = True\n",
    "            for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "                clusterername = clusterer\n",
    "                if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                    first_agg = False\n",
    "                    override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                    clusterername = \"Agg  w/ C\"\n",
    "                elif clusterer == \"AgglomerativeClustering\":\n",
    "                    override_fields = {}\n",
    "                    clusterername = \"Agg w/o C\"\n",
    "\n",
    "                for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                    latex_table += \" &\"\n",
    "                    filter = {\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"clusterer\": clusterer,\n",
    "                    }\n",
    "                    sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                    filter2 = dict(\n",
    "                        DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model]\n",
    "                    )\n",
    "                    filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                    filter2.update(override_fields)\n",
    "                    sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                    if len(sdf) < 1:\n",
    "                        cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                        result_table[i_group, i_clusters, i_dataset] = -100.0\n",
    "                        continue\n",
    "                    result_table[i_group, i_clusters, i_dataset] = np.median(\n",
    "                        sdf[metric_key1]\n",
    "                    )\n",
    "\n",
    "    print(result_table[0])\n",
    "\n",
    "    print(backbone)\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    CLUSTERERS2 = [\"K-Means\", \"Affinity Prop\", \"Agg w/ C\", \"Agg w/o C\", \"HDBSCAN\"]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:red\", \"tab:green\", \"tab:olive\", \"tab:cyan\"]\n",
    "\n",
    "    encoder_to_color = {}\n",
    "    cluster_to_color = {\n",
    "        CLUSTERERS2[idx]: colors[idx] for idx in range(len(CLUSTERERS2))\n",
    "    }\n",
    "\n",
    "    for model in list(MODEL_GROUPS[backbone]):\n",
    "        if model == \"resnet50\" or model == \"vitb16\":\n",
    "            encoder_to_color[model] = colors[0]\n",
    "        if \"mae\" in model:\n",
    "            encoder_to_color[model] = colors[1]\n",
    "        if \"vicreg\" in model:\n",
    "            encoder_to_color[model] = colors[2]\n",
    "        if \"clip\" in model:\n",
    "            encoder_to_color[model] = colors[3]\n",
    "        if \"moco\" in model:\n",
    "            encoder_to_color[model] = colors[4]\n",
    "        if \"dino\" in model:\n",
    "            encoder_to_color[model] = colors[5]\n",
    "\n",
    "    print(encoder_to_color)\n",
    "    rank_tmp = np.asarray([1, 2, 3, 4, 5])\n",
    "    # RANK PER ENCODER - go through each dataset, look at each clusterer,\n",
    "    # and determine the rank of each encoder in that setting\n",
    "    print(list(MODEL_GROUPS[backbone]))\n",
    "    ranks_encoders = np.zeros((5, len(CLUSTERERS), len(TEST_DATASETS)))\n",
    "    for i_dataset in range(len(TEST_DATASETS)):\n",
    "        for i_clusters in range(len(CLUSTERERS)):\n",
    "            cluster_data = result_table[:, i_clusters, i_dataset]\n",
    "            rank = np.argsort(cluster_data)[::-1]\n",
    "            ranks_encoders[:, i_clusters, i_dataset] = rank_tmp[rank.argsort()]\n",
    "    mean_rank_encoders = np.mean(ranks_encoders, axis=(1, 2))\n",
    "    std_rank_encoders = np.std(ranks_encoders, axis=(1, 2))\n",
    "    order = [\n",
    "        (\n",
    "            list(MODEL_GROUPS[backbone])[idx],\n",
    "            mean_rank_encoders[idx],\n",
    "            std_rank_encoders[idx],\n",
    "        )\n",
    "        for idx in np.argsort(mean_rank_encoders)\n",
    "    ]\n",
    "\n",
    "    for idx, model in enumerate(order[::-1]):\n",
    "        axenc[i_backbone].barh(\n",
    "            idx,\n",
    "            model[1],\n",
    "            xerr=model[2],\n",
    "            align=\"center\",\n",
    "            alpha=0.6,\n",
    "            ecolor=\"black\",\n",
    "            color=encoder_to_color[model[0]],\n",
    "            capsize=2,\n",
    "            zorder=10,\n",
    "        )\n",
    "\n",
    "    axenc[i_backbone].set_yticks([])\n",
    "    axenc[i_backbone].set_yticklabels([])\n",
    "    axenc[i_backbone].set_xticks([1, 2, 3, 4, 5])\n",
    "    axenc[i_backbone].set_xticklabels([1, 2, 3, 4, 5])\n",
    "    axenc[i_backbone].xaxis.grid(True, zorder=1, alpha=0.5)\n",
    "    axenc[i_backbone].set_title(f\"{backbone}\")\n",
    "\n",
    "    # RANK PER CLUSTERER - go through each dataset, look at each encoder,\n",
    "    # and determine the rank of each clusterer in that setting\n",
    "\n",
    "    print(CLUSTERERS2)\n",
    "    ranks_clusterers = np.zeros((5, len(CLUSTERERS2), len(TEST_DATASETS)))\n",
    "    for i_dataset in range(len(TEST_DATASETS)):\n",
    "        for i_encoder in range(len(list(MODEL_GROUPS[backbone]))):\n",
    "            encoder_data = result_table[i_encoder, :, i_dataset]\n",
    "            rank = np.argsort(encoder_data)[::-1]\n",
    "            ranks_clusterers[i_encoder, :, i_dataset] = rank_tmp[rank.argsort()]\n",
    "    mean_rank_clusters = np.mean(ranks_clusterers, axis=(0, 2))\n",
    "    std_rank_clusters = np.std(ranks_clusterers, axis=(0, 2))\n",
    "    order = [\n",
    "        (CLUSTERERS2[idx], mean_rank_clusters[idx], std_rank_clusters[idx])\n",
    "        for idx in np.argsort(mean_rank_clusters)\n",
    "    ]\n",
    "\n",
    "    for idx, model in enumerate(order[::-1]):\n",
    "        axclus[i_backbone].barh(\n",
    "            idx,\n",
    "            model[1],\n",
    "            xerr=model[2],\n",
    "            align=\"center\",\n",
    "            alpha=0.6,\n",
    "            ecolor=\"black\",\n",
    "            color=cluster_to_color[model[0]],\n",
    "            capsize=2,\n",
    "            zorder=10,\n",
    "        )\n",
    "\n",
    "    axclus[i_backbone].set_yticks([])\n",
    "    axclus[i_backbone].set_yticklabels([])\n",
    "    axclus[i_backbone].set_xticks([1, 2, 3, 4, 5])\n",
    "    axclus[i_backbone].set_xticklabels([1, 2, 3, 4, 5])\n",
    "    axclus[i_backbone].xaxis.grid(True, zorder=1, alpha=0.5)\n",
    "    axclus[i_backbone].set_title(f\"{backbone}\")\n",
    "\n",
    "    axclus[i_backbone].set_xlabel(\"Rank\")\n",
    "    axenc[i_backbone].set_xlabel(\"Rank\")\n",
    "\n",
    "    print(order)\n",
    "\n",
    "\n",
    "encoder_to_color[\"vicreg_resnet50\"] = colors[2]\n",
    "\n",
    "label_fn = lambda c, ls: plt.plot([], [], color=c, ls=ls, linewidth=3)[0]  # noqa:E731\n",
    "handles_clus = [label_fn(cluster_to_color[idx], \"-\") for idx in CLUSTERERS2]\n",
    "handles_enc = [\n",
    "    label_fn(encoder_to_color[idx], \"-\")\n",
    "    for idx in list(MODEL_GROUPS[backbone]) + [\"vicreg_resnet50\"]\n",
    "]\n",
    "\n",
    "axenc[1].legend(\n",
    "    handles_enc,\n",
    "    [MODEL2SH[x] for x in list(MODEL_GROUPS[backbone]) + [\"vicreg_resnet50\"]],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "axclus[1].legend(handles_clus, CLUSTERERS2, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "figenc.savefig(\"ranking_enc.pdf\", bbox_inches=\"tight\")\n",
    "figclus.savefig(\"ranking_clus.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
