{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnxDlvP8szOj"
   },
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9BelQPaJVo2"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9AH-GlrfS4Pf"
   },
   "outputs": [],
   "source": [
    "VALIDATION_DATASETS = [\"imagenet\", \"imagenette\", \"imagewoof\"]\n",
    "RESNET50_MODELS = [\n",
    "    \"resnet50\",\n",
    "    \"mocov3_resnet50\",\n",
    "    \"vicreg_resnet50\",\n",
    "    \"dino_resnet50\",\n",
    "    \"clip_RN50\",\n",
    "]\n",
    "VITB16_MODELS = [\n",
    "    \"vitb16\",\n",
    "    \"mocov3_vit_base\",\n",
    "    \"timm_vit_base_patch16_224.mae\",\n",
    "    \"dino_vitb16\",\n",
    "    \"clip_vitb16\",\n",
    "]\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"SpectralClustering\",\n",
    "    \"HDBSCAN\",\n",
    "    \"OPTICS\",\n",
    "]\n",
    "ALL_CLUSTERERS = copy.deepcopy(CLUSTERERS)\n",
    "DISTANCE_METRICS = [\n",
    "    \"euclidean\",\n",
    "    \"l1\",\n",
    "    \"chebyshev\",\n",
    "    \"cosine\",\n",
    "    \"arccos\",\n",
    "    \"braycurtis\",\n",
    "    \"canberra\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0mJrqF3FAbEG"
   },
   "outputs": [],
   "source": [
    "DATASET2LS = {\n",
    "    \"imagenet\": \"-.\",\n",
    "    \"imagenette\": \"--\",\n",
    "    \"imagewoof\": \":\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OqPoCd4kbokG"
   },
   "outputs": [],
   "source": [
    "DEFAULT_PARAMS = {\n",
    "    \"all\": {\n",
    "        \"dim_reducer\": \"None\",\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "        \"zscore\": False,\n",
    "        \"normalize\": False,\n",
    "        \"zscore2\": False,\n",
    "        \"ndim_correction\": False,\n",
    "    },\n",
    "    \"KMeans\": {\"clusterer\": \"KMeans\"},\n",
    "    \"AffinityPropagation\": {\n",
    "        \"clusterer\": \"AffinityPropagation\",\n",
    "        \"affinity_damping\": 0.5,\n",
    "        \"affinity_conv_iter\": 15,\n",
    "    },\n",
    "    \"SpectralClustering\": {\n",
    "        \"clusterer\": \"SpectralClustering\",\n",
    "        \"spectral_assigner\": \"kmeans\",\n",
    "    },\n",
    "    \"AgglomerativeClustering\": {\n",
    "        \"clusterer\": \"AgglomerativeClustering\",\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "        \"aggclust_linkage\": \"ward\",\n",
    "    },\n",
    "    \"HDBSCAN\": {\n",
    "        \"clusterer\": \"HDBSCAN\",\n",
    "        \"hdbscan_method\": \"eom\",\n",
    "        \"min_samples\": 5,\n",
    "        \"max_samples\": 0.2,\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "    },\n",
    "    \"OPTICS\": {\n",
    "        \"clusterer\": \"OPTICS\",\n",
    "        \"optics_method\": \"xi\",\n",
    "        \"optics_xi\": 0.05,\n",
    "        \"distance_metric\": \"euclidean\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VKTbU-Oasdl"
   },
   "source": [
    "## Set best params\n",
    "\n",
    "These were discovered by the search that follows, but we move the definitions here to make the code more modular, so you don't have to re-run the hyperparameter search analysis code to define these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MLuhE2xibLOC"
   },
   "source": [
    "### Num dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eAgJs3H-uqiJ"
   },
   "outputs": [],
   "source": [
    "models = RESNET50_MODELS + VITB16_MODELS\n",
    "BEST_PARAMS = {\n",
    "    clusterer: {model: copy.deepcopy(DEFAULT_PARAMS[clusterer]) for model in models}\n",
    "    for clusterer in ALL_CLUSTERERS\n",
    "}\n",
    "\n",
    "# KMeans\n",
    "# Use UMAP (num dims unimportant; we select 50d for consistency) for every encoder except\n",
    "# - clip_RN50 : a little better to use PCA with 500d than UMAP. UMAP beats PCA if you\n",
    "#   reduce the PCA dims below 500.\n",
    "# - clip_vitb16 : same behaviour as clip_RN50\n",
    "# - timm_vit_base_patch16_224.mae : best is PCA 0.85 variance explained. Need at least\n",
    "#   200 PCA dims, and PCA perf beats UMAP throughout\n",
    "\n",
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    if model.startswith(\"clip\") or model == \"timm_vit_base_patch16_224.mae\":\n",
    "        continue\n",
    "    BEST_PARAMS[\"KMeans\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"KMeans\"][\"clip_RN50\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"ndim_reduced\": 500, \"zscore\": True, \"pca_variance\": None}\n",
    ")\n",
    "BEST_PARAMS[\"KMeans\"][\"clip_vitb16\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"ndim_reduced\": 500, \"zscore\": True, \"pca_variance\": None}\n",
    ")\n",
    "BEST_PARAMS[\"KMeans\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"pca_variance\": 0.85, \"zscore\": True, \"ndim_reduced\": None}\n",
    ")\n",
    "\n",
    "# AffinityPropagation\n",
    "# Use PCA with 10 dims for every encoder except\n",
    "# - resnet50 (supervised) : original embeddings, no reduction (AMI=0.62);\n",
    "#   perf gets worse if they are whitened (AMI=0.55) and although the perf increases\n",
    "#   as num dims are reduced it doesn't quite recover. PCA perf peaks at 10-20 dim (AMI=0.57).\n",
    "# - dino_resnet50 : does marginally better at UMAP 50 (AMI=0.52495) than PCA 10 (AMI=0.5044)\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.95 variance explained (AMI=0.303).\n",
    "#   Definite improvement from 10 to 20 dims, but not much improvement above that.\n",
    "\n",
    "for model in models:\n",
    "    if model in [\"resnet50\", \"dino_resnet50\", \"timm_vit_base_patch16_224.mae\"]:\n",
    "        continue\n",
    "    BEST_PARAMS[\"AffinityPropagation\"][model].update(\n",
    "        {\n",
    "            \"dim_reducer\": \"PCA\",\n",
    "            \"ndim_reduced\": 10,\n",
    "            \"zscore\": True,\n",
    "            \"pca_variance\": None,\n",
    "            \"dim_reducer_man\": \"None\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"resnet50\"].update(\n",
    "    {\"dim_reducer\": \"None\", \"dim_reducer_man\": \"None\", \"zscore\": False}\n",
    ")\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"dino_resnet50\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "BEST_PARAMS[\"AffinityPropagation\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# AgglomerativeClustering\n",
    "# Use UMAP (num dims unimportant; we select 50d for consistency) for every encoder except\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.98 variance explained (i.e. nearly all\n",
    "#   dimensions kept), which is not noticably better than using 500 dim PCA but there is\n",
    "#   an increase compared to using less than 500d.\n",
    "\n",
    "for model in models:\n",
    "    if model == \"timm_vit_base_patch16_224.mae\":\n",
    "        continue\n",
    "    BEST_PARAMS[\"AgglomerativeClustering\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50, \"dim_reducer\": \"None\"}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"AgglomerativeClustering\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.98,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# HDBSCAN\n",
    "# Use UMAP for every encoder except\n",
    "# - timm_vit_base_patch16_224.mae : PCA 0.95 variance explained (AMI=0.085) which is\n",
    "#   not noticably better than PCA with 50 dim\n",
    "\n",
    "for model in models:\n",
    "    if model in [\"timm_vit_base_patch16_224.mae\"]:\n",
    "        continue\n",
    "    BEST_PARAMS[\"HDBSCAN\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50, \"dim_reducer\": \"None\"}\n",
    "    )\n",
    "\n",
    "BEST_PARAMS[\"HDBSCAN\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\n",
    "        \"dim_reducer\": \"PCA\",\n",
    "        \"pca_variance\": 0.95,\n",
    "        \"zscore\": True,\n",
    "        \"ndim_reduced\": None,\n",
    "        \"dim_reducer_man\": \"None\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# OPTICS\n",
    "# Use UMAP for every encoder, no exceptions necessary\n",
    "for model in models:\n",
    "    BEST_PARAMS[\"OPTICS\"][model].update(\n",
    "        {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50, \"dim_reducer\": \"None\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2nA5YxFqFo7x",
    "outputId": "3b02ac29-9036-42a0-8c5d-a888d9794865"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_v1 = copy.deepcopy(BEST_PARAMS)\n",
    "BEST_PARAMS_v2 = BEST_PARAMS\n",
    "\n",
    "print(\"Updating dim choices for new method\")\n",
    "# Updated dim choices\n",
    "# (changed to this when we swapped to using weighted average instead of straight\n",
    "# average between Imagenet-1k, Imagenette, Imagewoof)\n",
    "\n",
    "# Changed KMeans clip_RN50 from PCA 500 to UMAP 50, so it uses fewer dimensions\n",
    "# (probably more stable than using 500-d which is what PCA needs to marginally beat UMAP)\n",
    "BEST_PARAMS_v2[\"KMeans\"][\"clip_RN50\"].update(\n",
    "    {\"dim_reducer\": None, \"ndim_reduced\": None, \"zscore\": False, \"pca_variance\": None}\n",
    ")\n",
    "BEST_PARAMS_v2[\"KMeans\"][\"clip_RN50\"].update(\n",
    "    {\"dim_reducer_man\": \"UMAP\", \"ndim_reduced_man\": 50}\n",
    ")\n",
    "# Changed KMeans MAE from PCA 85% to PCA 200\n",
    "# (since we see perf above plateaus at 200-d, there is no point going above that)\n",
    "BEST_PARAMS_v2[\"KMeans\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"zscore\": True, \"ndim_reduced\": 200, \"pca_variance\": None}\n",
    ")\n",
    "# Changed KMeans clip_vitb16 from PCA 500 to PCA 75%\n",
    "# (gives a notably better train set AMI measurement above)\n",
    "BEST_PARAMS_v2[\"KMeans\"][\"clip_vitb16\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"zscore\": True, \"pca_variance\": 0.75, \"ndim_reduced\": None}\n",
    ")\n",
    "\n",
    "# Changed AffinityPropagation dino_resnet50 from PCA 95% to PCA 10\n",
    "# (performance is basically equal, so no point using higher-dim space;\n",
    "# could have done UMAP 50 instead with basically equal train AMI to PCA 10,\n",
    "# but didn't for consistency with other models)\n",
    "BEST_PARAMS_v2[\"AffinityPropagation\"][\"dino_resnet50\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"zscore\": True, \"ndim_reduced\": 10, \"pca_variance\": None}\n",
    ")\n",
    "# Changed AffinityPropagation MAE from PCA 95% to PCA 100\n",
    "BEST_PARAMS_v2[\"AffinityPropagation\"][\"timm_vit_base_patch16_224.mae\"].update(\n",
    "    {\"dim_reducer\": \"PCA\", \"zscore\": True, \"ndim_reduced\": 100, \"pca_variance\": None}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9scRlYvoa9tr"
   },
   "source": [
    "### Agglomerative specific settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv8_GiZ5PfDF"
   },
   "outputs": [],
   "source": [
    "for model in [\n",
    "    \"resnet50\",\n",
    "    \"mocov3_resnet50\",\n",
    "    \"vicreg_resnet50\",\n",
    "    \"vitb16\",\n",
    "    \"timm_vit_base_patch16_224.mae\",\n",
    "]:\n",
    "    BEST_PARAMS_v1[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"aggclust_linkage\": \"ward\",\n",
    "        }\n",
    "    )\n",
    "for model in [\"dino_resnet50\", \"clip_RN50\", \"dino_vitb16\"]:\n",
    "    BEST_PARAMS_v1[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"aggclust_linkage\": \"average\",\n",
    "        }\n",
    "    )\n",
    "for model in [\"mocov3_vit_base\", \"clip_vitb16\"]:\n",
    "    BEST_PARAMS_v1[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"chebyshev\",\n",
    "            \"aggclust_linkage\": \"average\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4CouZvuSjPvc"
   },
   "outputs": [],
   "source": [
    "# vicreg_resnet50 is the only change from v1 to v2\n",
    "for model in [\"resnet50\", \"mocov3_resnet50\", \"vitb16\", \"timm_vit_base_patch16_224.mae\"]:\n",
    "    BEST_PARAMS_v2[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"aggclust_linkage\": \"ward\",\n",
    "        }\n",
    "    )\n",
    "for model in [\"vicreg_resnet50\", \"dino_resnet50\", \"clip_RN50\", \"dino_vitb16\"]:\n",
    "    BEST_PARAMS_v2[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"aggclust_linkage\": \"average\",\n",
    "        }\n",
    "    )\n",
    "for model in [\"mocov3_vit_base\", \"clip_vitb16\"]:\n",
    "    BEST_PARAMS_v2[\"AgglomerativeClustering\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"chebyshev\",\n",
    "            \"aggclust_linkage\": \"average\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Thn1g4rpeoo"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_v1[\"AC w/ C\"] = copy.deepcopy(BEST_PARAMS_v1[\"AgglomerativeClustering\"])\n",
    "BEST_PARAMS_v1[\"AC w/o C\"] = copy.deepcopy(BEST_PARAMS_v1[\"AgglomerativeClustering\"])\n",
    "BEST_PARAMS_v2[\"AC w/ C\"] = copy.deepcopy(BEST_PARAMS_v2[\"AgglomerativeClustering\"])\n",
    "BEST_PARAMS_v2[\"AC w/o C\"] = copy.deepcopy(BEST_PARAMS_v2[\"AgglomerativeClustering\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Gixn5KGtuNr"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS_v1[\"AC w/ C\"][model].update({\"aggclust_dist_thresh\": None})\n",
    "    BEST_PARAMS_v2[\"AC w/ C\"][model].update({\"aggclust_dist_thresh\": None})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EqXneH6kv27"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS_v2[\"AC w/o C\"][model].update(\n",
    "        {\"zscore2\": \"average\", \"ndim_correction\": True}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yrmctdctSRgu"
   },
   "outputs": [],
   "source": [
    "# Run AgglomerativeClustering experiments with number of clusters unknown\n",
    "# \tresnet50        \t20.0\n",
    "# \tmocov3_resnet50 \t20.0\n",
    "# \tvicreg_resnet50 \t20.0\n",
    "# \tvitb16 \t            20.0\n",
    "# \tdino_resnet50     \t 1.0\n",
    "# \tclip_RN50 \t         1.0\n",
    "# \tdino_vitb16 \t     2.0\n",
    "# \tmocov3_vit_base \t 1.0\n",
    "# \tclip_vitb16 \t     0.5\n",
    "# \ttimm_vit_base_patch16_224.mae \t200.0\n",
    "\n",
    "for model in [\"resnet50\", \"mocov3_resnet50\", \"vicreg_resnet50\", \"vitb16\"]:\n",
    "    BEST_PARAMS_v1[\"AC w/o C\"][model].update({\"aggclust_dist_thresh\": 20.0})\n",
    "for model in [\"dino_resnet50\", \"clip_RN50\", \"mocov3_vit_base\"]:\n",
    "    BEST_PARAMS_v1[\"AC w/o C\"][model].update({\"aggclust_dist_thresh\": 1.0})\n",
    "BEST_PARAMS_v1[\"AC w/o C\"][\"dino_vitb16\"][\"aggclust_dist_thresh\"] = 2.0\n",
    "BEST_PARAMS_v1[\"AC w/o C\"][\"clip_vitb16\"][\"aggclust_dist_thresh\"] = 0.5\n",
    "BEST_PARAMS_v1[\"AC w/o C\"][\"timm_vit_base_patch16_224.mae\"][\n",
    "    \"aggclust_dist_thresh\"\n",
    "] = 200.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEW3rz_5aQ70"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_v2[\"AC w/o C\"][\"resnet50\"][\"aggclust_dist_thresh\"] = 2.0\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"mocov3_resnet50\"][\"aggclust_dist_thresh\"] = 10.0\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"vicreg_resnet50\"][\"aggclust_dist_thresh\"] = 0.5\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"dino_resnet50\"][\"aggclust_dist_thresh\"] = 0.5\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"clip_RN50\"][\"aggclust_dist_thresh\"] = 0.5\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"vitb16\"][\"aggclust_dist_thresh\"] = 2.0\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"mocov3_vit_base\"][\"aggclust_dist_thresh\"] = 1.0\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"timm_vit_base_patch16_224.mae\"][\n",
    "    \"aggclust_dist_thresh\"\n",
    "] = 5.0\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"dino_vitb16\"][\"aggclust_dist_thresh\"] = 0.2\n",
    "BEST_PARAMS_v2[\"AC w/o C\"][\"clip_vitb16\"][\"aggclust_dist_thresh\"] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KeuptU7acB0d"
   },
   "source": [
    "### HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YHODpPwVL0FT"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS_v1[\"HDBSCAN\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"hdbscan_method\": \"eom\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoUxa6TG03b9"
   },
   "source": [
    "v2 selection\n",
    "\n",
    "|    | model                         | distance_metric   | hdbscan_method   |      AMI |\n",
    "|---:|:------------------------------|:------------------|:-----------------|---------:|\n",
    "|  0 | resnet50                      | euclidean         | eom              | 0.828368 |\n",
    "|  1 | mocov3_resnet50               | euclidean         | eom              | 0.531644 |\n",
    "|  2 | vicreg_resnet50               | l1                | eom              | 0.472324 |\n",
    "|  3 | dino_resnet50                 | l1                | eom              | 0.503147 |\n",
    "|  4 | clip_RN50                     | l1                | eom              | 0.461363 |\n",
    "|  5 | vitb16                        | chebyshev         | eom              | 0.906110 |\n",
    "|  6 | mocov3_vit_base               | euclidean         | eom              | 0.629966 |\n",
    "|  7 | timm_vit_base_patch16_224.mae | euclidean         | eom              | 0.070495 |\n",
    "|  8 | dino_vitb16                   | l1                | eom              | 0.691547 |\n",
    "|  9 | clip_vitb16                   | l1                | eom              | 0.592489 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDMQjXpoKb6_"
   },
   "outputs": [],
   "source": [
    "for model in RESNET50_MODELS + VITB16_MODELS:\n",
    "    BEST_PARAMS_v2[\"HDBSCAN\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"euclidean\",\n",
    "            \"hdbscan_method\": \"eom\",\n",
    "        }\n",
    "    )\n",
    "for model in [\n",
    "    \"vicreg_resnet50\",\n",
    "    \"dino_resnet50\",\n",
    "    \"clip_RN50\",\n",
    "    \"dino_vitb16\",\n",
    "    \"clip_vitb16\",\n",
    "]:\n",
    "    BEST_PARAMS_v2[\"HDBSCAN\"][model].update(\n",
    "        {\n",
    "            \"distance_metric\": \"l1\",\n",
    "        }\n",
    "    )\n",
    "BEST_PARAMS_v2[\"HDBSCAN\"][\"vitb16\"][\"distance_metric\"] = \"chebyshev\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZvtYtaScF7V"
   },
   "source": [
    "### Define placeholder for interactive hp search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAKdeknla6FZ"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_vX = {\n",
    "    clusterer: {\n",
    "        model: copy.deepcopy(DEFAULT_PARAMS[clusterer])\n",
    "        for model in RESNET50_MODELS + VITB16_MODELS\n",
    "    }\n",
    "    for clusterer in ALL_CLUSTERERS\n",
    "}\n",
    "BEST_PARAMS = BEST_PARAMS_vX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSVZM4cns-gm"
   },
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w21wu6JUk4d"
   },
   "outputs": [],
   "source": [
    "def categorical_cmap(nc, nsc, cmap=\"tab10\", continuous=False):\n",
    "    \"\"\"\n",
    "    Create a colormap with a certain number of shades of colours.\n",
    "\n",
    "    https://stackoverflow.com/a/47232942/1960959\n",
    "    \"\"\"\n",
    "    if nc > plt.get_cmap(cmap).N:\n",
    "        raise ValueError(\"Too many categories for colormap.\")\n",
    "    if continuous:\n",
    "        ccolors = plt.get_cmap(cmap)(np.linspace(0, 1, nc))\n",
    "    else:\n",
    "        ccolors = plt.get_cmap(cmap)(np.arange(nc, dtype=int))\n",
    "    cols = np.zeros((nc * nsc, 3))\n",
    "    for i, c in enumerate(ccolors):\n",
    "        chsv = matplotlib.colors.rgb_to_hsv(c[:3])\n",
    "        arhsv = np.tile(chsv, nsc).reshape(nsc, 3)\n",
    "        arhsv[:, 1] = np.linspace(chsv[1], 0.25, nsc)\n",
    "        arhsv[:, 2] = np.linspace(chsv[2], 1, nsc)\n",
    "        rgb = matplotlib.colors.hsv_to_rgb(arhsv)\n",
    "        cols[i * nsc : (i + 1) * nsc, :] = rgb\n",
    "    cmap = matplotlib.colors.ListedColormap(cols)\n",
    "    return cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "id": "Zt-xAviSUwWV",
    "outputId": "0feb0c9b-c97d-4ec7-955f-8fdcc521be3c"
   },
   "outputs": [],
   "source": [
    "categorical_cmap(len(RESNET50_MODELS), len(VALIDATION_DATASETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5hY2oc2I-PO"
   },
   "outputs": [],
   "source": [
    "def select_rows(df, filters, allow_missing=True):\n",
    "    select = np.ones(len(df), dtype=bool)\n",
    "    for col, val in filters.items():\n",
    "        if col == \"dataset\":\n",
    "            col = \"dataset_name\"\n",
    "        if col == \"clusterer\":\n",
    "            col = \"clusterer_name\"\n",
    "        if val is None or val == \"None\" or val == \"none\":\n",
    "            select_i = pd.isna(df[col])\n",
    "            select_i |= df[col] == \"None\"\n",
    "            select_i |= df[col] == \"none\"\n",
    "        else:\n",
    "            select_i = df[col] == val\n",
    "            select_i |= df[col] == str(val)\n",
    "            if allow_missing or val == \"None\" or val == \"none\":\n",
    "                select_i |= pd.isna(df[col])\n",
    "        select &= select_i\n",
    "    return df[select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iOVrUnC_Jg-"
   },
   "outputs": [],
   "source": [
    "def find_differing_columns(df, cols=None):\n",
    "    if cols is None:\n",
    "        cols = df.columns\n",
    "    my_cols = []\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            continue\n",
    "        if df[col].nunique(dropna=False) > 1:\n",
    "            my_cols.append(col)\n",
    "    return my_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wI7MkSQiz89O"
   },
   "outputs": [],
   "source": [
    "def filter2command(*filters, partition=\"val\"):\n",
    "    f = {}\n",
    "    for filter in filters:\n",
    "        for k, v in filter.items():\n",
    "            f[k] = v\n",
    "    dataset = f.get(\"dataset\", \"\")\n",
    "    clusterer = f.get(\"clusterer\", \"\")\n",
    "    mem = 4\n",
    "    if dataset != \"imagenet\":\n",
    "        pass\n",
    "    elif clusterer == \"AgglomerativeClustering\":\n",
    "        mem = 20\n",
    "    if partition == \"val\":\n",
    "        seed = 100\n",
    "    elif partition == \"test\":\n",
    "        seed = 1\n",
    "    else:\n",
    "        seed = 0\n",
    "    s = (\n",
    "        f\"sbatch --array={seed} --mem={mem}G\"\n",
    "        f' --job-name=\"zsc-{f.get(\"model\", \"\")}-{dataset}-{clusterer}\"'\n",
    "        f\" slurm/cluster.slrm --partition={partition}\"\n",
    "    )\n",
    "    for k, v in f.items():\n",
    "        if v is None:\n",
    "            continue\n",
    "        if k == \"zscore\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-zscore\"\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --zscore\"\n",
    "            continue\n",
    "        if k == \"normalize\":\n",
    "            if v == \"False\" or not v:\n",
    "                pass\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --normalize\"\n",
    "            continue\n",
    "        if k == \"zscore2\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-zscore2\"\n",
    "            elif v == \"average\":\n",
    "                s += \" --azscore2\"\n",
    "            elif v == \"standard\" or v:\n",
    "                s += \" --zscore2\"\n",
    "            continue\n",
    "        if k == \"ndim_correction\":\n",
    "            if v == \"False\" or not v:\n",
    "                s += \" --no-ndim-correction\"\n",
    "            elif v == \"True\" or v:\n",
    "                s += \" --ndim-correction\"\n",
    "            continue\n",
    "        s += f\" --{k.replace('_', '-')}={v}\"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOKljXoMNGG7"
   },
   "source": [
    "# Final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CuPbp58ONv4Z"
   },
   "outputs": [],
   "source": [
    "TEST_DATASETS = [\n",
    "    \"imagenet\",\n",
    "    \"cifar10\",\n",
    "    \"cifar100\",\n",
    "    \"mnist\",\n",
    "    \"fashionmnist\",\n",
    "    \"svhn\",\n",
    "    \"flowers102\",\n",
    "    \"aircraft\",\n",
    "    \"nabirds\",\n",
    "    \"inaturalist\",\n",
    "]\n",
    "DATASET2SH = {\n",
    "    \"aircraft\": \"Aircraft\",\n",
    "    \"cifar10\": \"C10\",\n",
    "    \"cifar100\": \"C100\",\n",
    "    \"flowers102\": \"Flowers\",\n",
    "    \"fashionmnist\": \"fMNIST\",\n",
    "    \"imagenet\": \"IN1k\",\n",
    "    \"imagenette\": \"IN10\",\n",
    "    \"imagewoof\": \"INwf\",\n",
    "    \"inaturalist\": \"iNat21\",\n",
    "    \"mnist\": \"MNIST\",\n",
    "    \"nabirds\": \"NABirds\",\n",
    "    \"svhn\": \"SVHN\",\n",
    "}\n",
    "MODEL_GROUPS = {\n",
    "    \"ResNet-50\": RESNET50_MODELS,\n",
    "    \"ViT-B\": VITB16_MODELS,\n",
    "}\n",
    "MODEL2SH = {\n",
    "    \"resnet50\": \"Supervised\",\n",
    "    \"mocov3_resnet50\": \"MoCo-v3\",\n",
    "    \"vicreg_resnet50\": \"VICReg\",\n",
    "    \"dino_resnet50\": \"DINO\",\n",
    "    \"clip_RN50\": \"CLIP\",\n",
    "    \"vitb16\": \"Supervised\",\n",
    "    \"mocov3_vit_base\": \"MoCo-v3\",\n",
    "    \"timm_vit_base_patch16_224.mae\": \"MAE\",\n",
    "    \"dino_vitb16\": \"DINO\",\n",
    "    \"clip_vitb16\": \"CLIP\",\n",
    "}\n",
    "CLUSTERER2SH = {\n",
    "    \"KMeans\": \"K-Means\",\n",
    "    \"AffinityPropagation\": \"Affinity Prop\",\n",
    "    \"AgglomerativeClustering\": \"AC\",\n",
    "    \"AC w/ C\": \"AC w/  C\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GRNXaeD-tWUo"
   },
   "source": [
    "## Fetch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dytOzTA3NMeF",
    "outputId": "19a7efdd-c32a-4f3d-c467-092870aba23e"
   },
   "outputs": [],
   "source": [
    "# Project is specified by <entity/project-name>\n",
    "api = wandb.Api()\n",
    "runs_test = api.runs(\n",
    "    \"uoguelph_mlrg/zs-ssl-clustering\",\n",
    "    filters={\"state\": \"Finished\", \"config.partition\": \"test\"},\n",
    ")\n",
    "len(runs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "522p4kwrJd06"
   },
   "outputs": [],
   "source": [
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs_test:\n",
    "    # .summary contains the output keys/values for metrics like accuracy.\n",
    "    #  We call ._json_dict to omit large files\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith(\"_\")})\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "rows = []\n",
    "config_keys = set()\n",
    "summary_keys = set()\n",
    "for summary, config, name in zip(summary_list, config_list, name_list):\n",
    "    row = {\"name\": name}\n",
    "    row.update({k: v for k, v in config.items() if not k.startswith(\"_\")})\n",
    "    row.update({k: v for k, v in summary.items() if not k.startswith(\"_\")})\n",
    "    row[\"_timestamp\"] = summary[\"_timestamp\"]\n",
    "    rows.append(row)\n",
    "    config_keys = config_keys.union(config.keys())\n",
    "    summary_keys = summary_keys.union(summary.keys())\n",
    "\n",
    "test_runs_df = pd.DataFrame.from_records(rows)\n",
    "\n",
    "# Handle changed default value for spectral_assigner after config arg was introduced\n",
    "if \"spectral_assigner\" not in test_runs_df.columns:\n",
    "    test_runs_df[\"spectral_assigner\"] = None\n",
    "select = test_runs_df[\"clusterer_name\"] != \"SpectralClustering\"\n",
    "test_runs_df.loc[select, \"spectral_assigner\"] = None\n",
    "select = (test_runs_df[\"clusterer_name\"] == \"SpectralClustering\") & pd.isna(\n",
    "    test_runs_df[\"spectral_assigner\"]\n",
    ")\n",
    "test_runs_df.loc[select, \"spectral_assigner\"] = \"kmeans\"\n",
    "\n",
    "if \"zscore2\" not in test_runs_df.columns:\n",
    "    test_runs_df[\"zscore2\"] = False\n",
    "test_runs_df.loc[pd.isna(test_runs_df[\"zscore2\"]), \"zscore2\"] = False\n",
    "\n",
    "if \"ndim_correction\" not in test_runs_df.columns:\n",
    "    test_runs_df[\"ndim_correction\"] = False\n",
    "test_runs_df.loc[pd.isna(test_runs_df[\"ndim_correction\"]), \"ndim_correction\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "6bohRRomX9gO"
   },
   "outputs": [],
   "source": [
    "config_keys = config_keys.difference(\n",
    "    {\"workers\", \"memory_avail_GB\", \"memory_total_GB\", \"memory_slurm\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "k_KrOF5GNj9l",
    "outputId": "7649f12f-19ed-4113-bc66-88681d41ba3a"
   },
   "outputs": [],
   "source": [
    "test_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_Oc999K7NoA9",
    "outputId": "21153a3e-b1b7-4799-f054-020356c1a777"
   },
   "outputs": [],
   "source": [
    "list(test_runs_df[\"dataset_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "_cBYVKo7PZFY",
    "outputId": "a1b016d5-a137-4100-b22b-67482af9ce74",
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_key = \"AMI\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:5.1f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "    \"predictions_dir\": \"y_pred\",\n",
    "}\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "# KMeans  AffinityPropagation  AgglomerativeClustering  HDBSCAN\n",
    "clusterer = \"AgglomerativeClustering\"\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {clusterer}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    latex_table += r\"\\label{tab:\" + clusterer + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Encoder':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    for i_group, model_group_name in enumerate(list(MODEL_GROUPS.keys())):\n",
    "        if i_group > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "        for i_model, model in enumerate(MODEL_GROUPS[model_group_name]):\n",
    "            if i_model == 0:\n",
    "                latex_table += (\n",
    "                    r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                    + model_group_name\n",
    "                    + \"}}}\"\n",
    "                )\n",
    "                latex_table += \"\\n\"\n",
    "            latex_table += f\"& {MODEL2SH.get(model, model):<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    if clusterer == \"AffinityPropagation\" and dataset in [\n",
    "                        \"imagenet\",\n",
    "                        \"inaturalist\",\n",
    "                    ]:\n",
    "                        continue\n",
    "                        pass\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += \" $\"\n",
    "                if is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                latex_table += \"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {clusterer}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-9lxUOUuhaj"
   },
   "source": [
    "## Grouping by encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "n8sCItDK_2VT",
    "outputId": "18c89619-30d7-44fb-8f43-897901b62704",
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric_key = \"AMI\"\n",
    "show_pc = True\n",
    "show_fmt = \"{:4.0f}\"\n",
    "eps = 0.001\n",
    "override_fields = {\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "    \"predictions_dir\": \"y_pred\",\n",
    "}\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "backbone = \"ResNet-50\"\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {backbone}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    latex_table += r\"\\label{tab:\" + backbone + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Clusterer':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "        print(model)\n",
    "        if i_group > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            if i_clusters == 0:\n",
    "                latex_table += (\n",
    "                    r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                    + MODEL2SH[model]\n",
    "                    + \"}}}\"\n",
    "                )\n",
    "                latex_table += \"\\n\"\n",
    "            override_fields = {}\n",
    "            clusterername = CLUSTERER2SH.get(clusterer, clusterer)\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                clusterername = \"AC w/o C\"\n",
    "            latex_table += f\"& {clusterername:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.median(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += \" $\"\n",
    "                if is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                latex_table += \"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {clusterer}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_isFUjNsuYc4"
   },
   "source": [
    "## Grouping by clusterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTERERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MyWQRN9iqBkI",
    "outputId": "2642efe3-b0ef-46f3-dc70-f2f5c69645d4"
   },
   "outputs": [],
   "source": [
    "metric_key = \"AMI\"  # AMI  num_cluster_pred  silhouette-euclidean_pred  silhouette-og-euclidean_pred\n",
    "show_pc = True\n",
    "show_fmt = \"{:4.0f}\"\n",
    "highlight_best = True\n",
    "use_si_num = False\n",
    "eps = 0.005\n",
    "override_fields = {\n",
    "    \"predictions_dir\": \"y_pred\",\n",
    "    # \"aggclust_dist_thresh\": None,  # to flip between unknown/known n clusters for AC\n",
    "}\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "backbone = \"ResNet-50\"  # \"ResNet-50\" or \"ViT-B\"\n",
    "\n",
    "if metric_key == \"num_cluster_pred\":\n",
    "    CLUSTERERS = [\"AC w/o C\", \"AffinityPropagation\", \"HDBSCAN\"]\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:4.0f}\"\n",
    "    highlight_best = False\n",
    "    use_si_num = True\n",
    "else:\n",
    "    CLUSTERERS = [\"KMeans\", \"AC w/ C\", \"AC w/o C\", \"AffinityPropagation\", \"HDBSCAN\"]\n",
    "if metric_key.startswith(\"silhouette\"):\n",
    "    show_pc = False\n",
    "    show_fmt = \"{:5.2f}\"\n",
    "\n",
    "print(MODEL2SH)\n",
    "\n",
    "best_results = {k: [] for k in TEST_DATASETS}\n",
    "best_results_grouped = {k: defaultdict(list) for k in TEST_DATASETS}\n",
    "\n",
    "for dummy in [True, False]:\n",
    "    cmds = []\n",
    "    latex_table = r\"% Results for \" + f\"{metric_key}, {backbone}\" + \"\\n\"\n",
    "    now_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    latex_table += r\"% Generated \" + now_str + \"\\n\"\n",
    "    label = backbone\n",
    "    if metric_key == \"AMI\":\n",
    "        latex_table += r\"\\label{tab:\" + label + r\"}\" + \"\\n\"\n",
    "    label = metric_key.replace(\"_\", \"-\") + \":\" + label\n",
    "    latex_table += r\"\\label{tab:\" + label + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\resizebox{\\textwidth}{!}{%\" + \"\\n\"\n",
    "    latex_table += r\"\\begin{tabular}{ll\" + r\"r\" * len(TEST_DATASETS) + r\"}\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    latex_table += r\"& \" + f\"{'Encoder':<11s}\"\n",
    "    for dataset in TEST_DATASETS:\n",
    "        latex_table += r\"&\" + \"{:^15s}\".format(DATASET2SH.get(dataset, dataset))\n",
    "    latex_table += r\"\\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    if metric_key == \"num_cluster_pred\":\n",
    "        latex_table += r\"& Num targets\"\n",
    "        for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "            sdf = select_rows(test_runs_df, {\"dataset\": dataset}, allow_missing=False)\n",
    "            sdf = sdf[~pd.isna(sdf[\"num_cluster_true\"])]\n",
    "            latex_table += r\"& \"\n",
    "            latex_table += r\"\\num{\" if use_si_num else r\"$\"\n",
    "            latex_table += f\"{sdf.iloc[0]['num_cluster_true'].item()}\"\n",
    "            latex_table += r\"}\" if use_si_num else r\"$\"\n",
    "        latex_table += r\"\\\\\" + \"\\n\"\n",
    "        latex_table += r\"\\toprule\" + \"\\n\"\n",
    "    elif metric_key.endswith(\"_pred\"):\n",
    "        metric_key2 = metric_key.replace(\"_pred\", \"_true\")\n",
    "        clusterername = \"G.T.\"\n",
    "        latex_table += (\n",
    "            r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "            + clusterername\n",
    "            + \"}}}\"\n",
    "        )\n",
    "        latex_table += \"\\n\"\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\"model\": model, \"dataset\": dataset}\n",
    "                if model == \"timm_vit_base_patch16_224.mae\":\n",
    "                    filter[\"dim_reducer\"] = \"PCA\"\n",
    "                    filter[\"pca_variance\"] = 0.95\n",
    "                else:\n",
    "                    filter[\"dim_reducer_man\"] = \"UMAP\"\n",
    "                    filter[\"ndim_reduced_man\"] = 50\n",
    "                    filter[\"dim_reducer_man_metric\"] = \"euclidean\"\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                sdf = sdf[~pd.isna(sdf[metric_key2])]\n",
    "                my_val = np.nanmedian(sdf[metric_key])\n",
    "                if sum(sdf[metric_key2] != my_val) > 0:\n",
    "                    pass\n",
    "                if dummy:\n",
    "                    best_results_grouped[dataset][clusterername].append(my_val)\n",
    "                    continue\n",
    "                is_best_grp = my_val + eps >= np.max(\n",
    "                    best_results_grouped[dataset][clusterername]\n",
    "                )\n",
    "                latex_table += r\"\\num{\" if use_si_num else r\"$\"\n",
    "                latex_table += \"     \"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best_grp:\n",
    "                    latex_table += r\"\\tcg{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                if highlight_best:\n",
    "                    latex_table += r\"}\" if is_best_grp else \" \"\n",
    "                latex_table += r\"}\" if use_si_num else r\"$\"\n",
    "\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "        latex_table += r\"\\toprule\" + \"\\n\"\n",
    "\n",
    "    first_agg = True\n",
    "    for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "        clusterername = CLUSTERER2SH.get(clusterer, clusterer)\n",
    "        if (\n",
    "            first_agg\n",
    "            and clusterer == \"AgglomerativeClustering\"\n",
    "            and metric_key != \"num_cluster_pred\"\n",
    "        ):\n",
    "            first_agg = False\n",
    "            override_fields = {\"aggclust_dist_thresh\": None}\n",
    "            clusterername = \"AC  w/ C\"\n",
    "        elif clusterer == \"AgglomerativeClustering\":\n",
    "            clusterername = \"AC w/o C\"\n",
    "            if \"aggclust_dist_thresh\" in override_fields:\n",
    "                del override_fields[\"aggclust_dist_thresh\"]\n",
    "\n",
    "        if i_clusters > 0:\n",
    "            latex_table += r\"\\midrule\" + \"\\n\"\n",
    "\n",
    "        latex_table += (\n",
    "            r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "            + clusterername\n",
    "            + \"}}}\"\n",
    "        )\n",
    "        latex_table += \"\\n\"\n",
    "\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            print(model)\n",
    "\n",
    "            latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "            for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    print(f\"No data for {filter} {filter2}\")\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    if not dummy:\n",
    "                        # latex_table += r\"\\multicolumn{1}{c}{--}\"\n",
    "                        latex_table += r\"   --  \"\n",
    "                    continue\n",
    "                if len(sdf) > 1:\n",
    "                    perf = sdf.iloc[0][\"AMI\"]\n",
    "                    if sum(sdf[\"AMI\"] != perf) > 0:\n",
    "                        print()\n",
    "                        print(\"More than one result with AMIs:\", list(sdf[\"AMI\"]))\n",
    "                        print(f\"for search {filter}\\nand {filter2}\")\n",
    "                        dif_cols = find_differing_columns(sdf, config_keys)\n",
    "                        print(f\"columns which differ: {dif_cols}\")\n",
    "                        if dif_cols:\n",
    "                            for col in dif_cols:\n",
    "                                print(f\"  {col}: {list(sdf[col])}\")\n",
    "                my_val = np.nanmedian(sdf[metric_key])\n",
    "                if dummy:\n",
    "                    best_results[dataset].append(my_val)\n",
    "                    best_results_grouped[dataset][clusterername].append(my_val)\n",
    "                    continue\n",
    "                if np.isnan(my_val):\n",
    "                    latex_table += r\"   --  \"\n",
    "                    continue\n",
    "                is_best = my_val + eps >= np.max(best_results[dataset])\n",
    "                if len(best_results[dataset]) > 1:\n",
    "                    is_secd = my_val + eps >= np.sort(best_results[dataset])[-2]\n",
    "                else:\n",
    "                    is_secd = False\n",
    "                is_best_grp = my_val + eps >= np.max(\n",
    "                    best_results_grouped[dataset][clusterername]\n",
    "                )\n",
    "                if show_pc:\n",
    "                    my_val = my_val * 100\n",
    "                latex_table += r\"\\num{\" if use_si_num else r\"$\"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best:\n",
    "                    latex_table += r\"\\tcf{\"\n",
    "                elif is_secd:\n",
    "                    latex_table += r\"\\tcs{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                if not highlight_best:\n",
    "                    pass\n",
    "                elif is_best_grp:\n",
    "                    latex_table += r\"\\tcg{\"\n",
    "                else:\n",
    "                    latex_table += \"     \"\n",
    "                latex_table += show_fmt.format(my_val)\n",
    "                if highlight_best:\n",
    "                    latex_table += r\"}\" if is_best or is_secd else \" \"\n",
    "                    latex_table += r\"}\" if is_best_grp else \" \"\n",
    "                latex_table += r\"}\" if use_si_num else r\"$\"\n",
    "            latex_table += r\" \\\\\" + \"\\n\"\n",
    "    latex_table += r\"\\bottomrule\" + \"\\n\"\n",
    "    latex_table += r\"\\end{tabular}\" + \"\\n\"\n",
    "    latex_table += r\"}\" + \"\\n\"\n",
    "\n",
    "\n",
    "if len(cmds) > 0:\n",
    "    print()\n",
    "for cmd in cmds:\n",
    "    print(cmd)\n",
    "\n",
    "print()\n",
    "print(\"Done!\")\n",
    "print()\n",
    "print(f\"Here is your results table for {metric_key}, {backbone}:\")\n",
    "print()\n",
    "print()\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "override_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Jy3UtWxJr77Z",
    "outputId": "4c5f43e6-2868-4048-f6da-c47c082320d0"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS[\"AC w/o C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DQaIfaxhf0ok",
    "outputId": "b014826f-9780-4c50-9060-423e81c6eef7"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS[\"AgglomerativeClustering\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "OH8-dIRcjdb5"
   },
   "outputs": [],
   "source": [
    "model = \"resnet50\"\n",
    "clusterer = \"AgglomerativeClustering\"\n",
    "filter = {\n",
    "    \"model\": model,\n",
    "    \"dataset\": \"imagenet\",\n",
    "    \"clusterer\": clusterer,\n",
    "}\n",
    "sdf = select_rows(test_runs_df, filter, allow_missing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "qzRAPZtwj253",
    "outputId": "2ab292b0-50c5-4074-c72f-c9b9a9d21ea6"
   },
   "outputs": [],
   "source": [
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "VQcqTBVhj1V2"
   },
   "outputs": [],
   "source": [
    "filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "I8esDzOwkMz2",
    "outputId": "2e25762a-eba8-445c-fb62-6e2ac82f9311"
   },
   "outputs": [],
   "source": [
    "filter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "RdpuOfkkkLaa"
   },
   "outputs": [],
   "source": [
    "filter2 = {k: v for k, v in filter2.items() if k not in filter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "m9DKKJmakgFU",
    "outputId": "8bdd3b86-89ff-45ba-d2f8-583adf5aeeb7"
   },
   "outputs": [],
   "source": [
    "filter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "naOZuGDpouJ1",
    "outputId": "c0d8e83b-60df-4690-cd11-3127e8cb6a4d"
   },
   "outputs": [],
   "source": [
    "override_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "E0As3Sl3keQc",
    "outputId": "002dfed7-3911-4422-c7a6-a59f514179c5"
   },
   "outputs": [],
   "source": [
    "sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "miKoNJi9oz6P",
    "outputId": "6a684af0-e925-4c78-928b-601f1f321020"
   },
   "outputs": [],
   "source": [
    "sdf[\"AMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dWl74HCQsvMY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IyRFsqaMsvOj",
    "outputId": "febce711-9a37-4bfd-d296-911c32f27090"
   },
   "outputs": [],
   "source": [
    "model = \"resnet50\"\n",
    "clusterer = \"AC w/o C\"\n",
    "filter = {\n",
    "    \"model\": model,\n",
    "    \"dataset\": \"imagenet\",\n",
    "}\n",
    "sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Q7loJaicsvRL",
    "outputId": "9e5ba249-d07e-4ace-9638-43c88d2552ef"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS[clusterer][model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "T0mDXwxys2VY",
    "outputId": "7cd2b368-62e1-4e26-d985-a93889b3a3ad"
   },
   "outputs": [],
   "source": [
    "filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "filter2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "WDVt2-nZtCfE",
    "outputId": "9df24087-3557-41c3-eb36-9aec07936f29"
   },
   "outputs": [],
   "source": [
    "override_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "PKTtDsS7tLcT",
    "outputId": "ef327c8a-5436-4a59-ba21-b43b139a5c5b"
   },
   "outputs": [],
   "source": [
    "sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bOOfDLY5tQDX",
    "outputId": "2e48ddf7-9e48-4fe1-fdd5-54c26d93a322"
   },
   "outputs": [],
   "source": [
    "sdf[\"AMI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Hw_tf6AKtLe1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "z3sIvLEbLHQE",
    "outputId": "f0f0f139-7942-4176-dfac-978e205549ca"
   },
   "outputs": [],
   "source": [
    "BEST_PARAMS_v2[\"AgglomerativeClustering\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWpBwhP8MOm0"
   },
   "source": [
    "## Correlation between AMI and SIlhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lU7C4-fBpl5R",
    "outputId": "ff6fd5e1-dbc9-413e-9dd2-7d110b26aa87"
   },
   "outputs": [],
   "source": [
    "best_results_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Gp5BaVDxG2Il",
    "outputId": "2ea12a0e-f294-47fa-8830-d59fbfd547b5"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-euclidean_pred\"\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(5, 3))\n",
    "\n",
    "\n",
    "colors = [\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:red\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "\n",
    "correlations = {\"ResNet-50\": [], \"ViT-B\": []}\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    my_valx_overall = []\n",
    "    my_valy_overall = []\n",
    "\n",
    "    my_valx_method = {clusterer: [] for clusterer in CLUSTERERS}\n",
    "    my_valy_method = {clusterer: [] for clusterer in CLUSTERERS}\n",
    "    best_results = {k: [] for k in TEST_DATASETS}\n",
    "\n",
    "    for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "        my_valx = []\n",
    "        my_valy = []\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            clusterername = clusterer\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                override_fields = {}\n",
    "                clusterername = \"AC w/o C\"\n",
    "\n",
    "            for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "                if i_group == 0:\n",
    "                    latex_table += (\n",
    "                        r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                        + clusterername\n",
    "                        + \"}}}\"\n",
    "                    )\n",
    "                    latex_table += \"\\n\"\n",
    "\n",
    "                latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                my_valx.append(np.nanmedian(sdf[metric_key1]))\n",
    "                my_valy.append(np.nanmedian(sdf[metric_key2]))\n",
    "\n",
    "                my_valx_method[clusterer].append(np.nanmedian(sdf[metric_key1]))\n",
    "                my_valy_method[clusterer].append(np.nanmedian(sdf[metric_key2]))\n",
    "\n",
    "        correlations[backbone].append(np.corrcoef(my_valx, my_valy)[0, 1])\n",
    "\n",
    "        ax[i_backbone].scatter(\n",
    "            my_valy,\n",
    "            my_valx,\n",
    "            color=colors[i_dataset],\n",
    "            alpha=0.5,\n",
    "            label=TEST_DATASETS[i_dataset],\n",
    "        )\n",
    "        my_valx_overall.extend(my_valx)\n",
    "        my_valy_overall.extend(my_valy)\n",
    "        ax[i_backbone].set_xlabel(r\"$S$\")\n",
    "        if i_backbone == 0:\n",
    "            ax[i_backbone].set_ylabel(metric_key1)\n",
    "        ax[i_backbone].set_ylim(-0.05, 1.05)\n",
    "        ax[i_backbone].set_xlim(-1.05, 1.05)\n",
    "        ax[i_backbone].set_title(\n",
    "            f\"{backbone}\\nPCC: {np.corrcoef(my_valx_overall, my_valy_overall)[0,1]:.2f}\"\n",
    "        )\n",
    "\n",
    "\n",
    "label_fn = lambda c, marker: plt.plot(  # noqa:E731\n",
    "    [], [], color=c, ls=\"None\", marker=marker, linewidth=6\n",
    ")[0]\n",
    "handles = [label_fn(colors[idx], \"o\") for idx in range(len(TEST_DATASETS))]\n",
    "data_labels = [DATASET2SH.get(dataset, dataset) for dataset in TEST_DATASETS]\n",
    "\n",
    "ax[1].legend(handles, data_labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "print(data_labels)\n",
    "print(correlations[\"ResNet-50\"], len(correlations[\"ResNet-50\"]))\n",
    "print(correlations[\"ViT-B\"], len(correlations[\"ViT-B\"]))\n",
    "\n",
    "fig.savefig(\"ami_silhouette.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "eSlyPO1kbM2u",
    "outputId": "76000a12-8c9d-4120-e2dc-518ad06ce3c1"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-og-euclidean_pred\"\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, sharey=True, figsize=(5.5, 3))\n",
    "\n",
    "colors = [\n",
    "    \"tab:red\",\n",
    "    \"tab:blue\",\n",
    "    \"tab:orange\",\n",
    "    \"tab:green\",\n",
    "    \"tab:purple\",\n",
    "    \"tab:brown\",\n",
    "    \"tab:pink\",\n",
    "    \"tab:gray\",\n",
    "    \"tab:olive\",\n",
    "    \"tab:cyan\",\n",
    "]\n",
    "\n",
    "correlations = {\"ResNet-50\": [], \"ViT-B\": []}\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    my_valx_overall = []\n",
    "    my_valy_overall = []\n",
    "    best_results = {k: [] for k in TEST_DATASETS}\n",
    "\n",
    "    for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "        my_valx = []\n",
    "        my_valy = []\n",
    "        first_agg = True\n",
    "        for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "            clusterername = clusterer\n",
    "            if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                first_agg = False\n",
    "                override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                clusterername = \"AC  w/ C\"\n",
    "            elif clusterer == \"AgglomerativeClustering\":\n",
    "                override_fields = {}\n",
    "                clusterername = \"AC w/o C\"\n",
    "\n",
    "            for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "                if i_group == 0:\n",
    "                    latex_table += (\n",
    "                        r\"\\parbox[t]{2mm}{\\multirow{5}{*}{\\rotatebox[origin=c]{90}{\"\n",
    "                        + clusterername\n",
    "                        + \"}}}\"\n",
    "                    )\n",
    "                    latex_table += \"\\n\"\n",
    "\n",
    "                latex_table += f\"& {MODEL2SH[model]:<10s}\"\n",
    "                latex_table += \" &\"\n",
    "                filter = {\n",
    "                    \"model\": model,\n",
    "                    \"dataset\": dataset,\n",
    "                    \"clusterer\": clusterer,\n",
    "                }\n",
    "                sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                filter2 = dict(DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model])\n",
    "                filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                filter2.update(override_fields)\n",
    "                sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                if len(sdf) < 1:\n",
    "                    cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                    continue\n",
    "                my_valx.append(np.nanmedian(sdf[metric_key1]))\n",
    "                my_valy.append(np.nanmedian(sdf[metric_key2]))\n",
    "\n",
    "        correlations[backbone].append(np.corrcoef(my_valx, my_valy)[0, 1])\n",
    "\n",
    "        ax[i_backbone].scatter(\n",
    "            my_valy,\n",
    "            my_valx,\n",
    "            color=colors[i_dataset],\n",
    "            alpha=0.5,\n",
    "            s=8,\n",
    "            label=TEST_DATASETS[i_dataset],\n",
    "        )\n",
    "        my_valx_overall.extend(my_valx)\n",
    "        my_valy_overall.extend(my_valy)\n",
    "\n",
    "    ax[i_backbone].set_xlabel(r\"$S$\")\n",
    "    if i_backbone == 0:\n",
    "        ax[i_backbone].set_ylabel(metric_key1)\n",
    "    ax[i_backbone].set_ylim(-0.05, 1.05)\n",
    "    ax[i_backbone].set_xlim(-1.05, 1.05)\n",
    "    ax[i_backbone].set_title(backbone)\n",
    "    my_valx_overall = np.array(my_valx_overall)\n",
    "    my_valy_overall = np.array(my_valy_overall)\n",
    "    select = ~(np.isnan(my_valx_overall) | np.isnan(my_valy_overall))\n",
    "    cor = np.corrcoef(my_valx_overall[select], my_valy_overall[select])\n",
    "    ax[i_backbone].text(-0.85, 0.95, f\"$r={cor[0,1]:.2f}$\")\n",
    "\n",
    "\n",
    "label_fn = lambda c, marker: plt.plot(  # noqa:E731\n",
    "    [], [], color=c, ls=\"None\", marker=marker, linewidth=6\n",
    ")[0]\n",
    "handles = [label_fn(colors[idx], \"o\") for idx in range(len(TEST_DATASETS))]\n",
    "data_labels = [DATASET2SH.get(dataset, dataset) for dataset in TEST_DATASETS]\n",
    "\n",
    "ax[1].legend(handles, data_labels, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "print(data_labels)\n",
    "print(correlations[\"ResNet-50\"], len(correlations[\"ResNet-50\"]))\n",
    "print(correlations[\"ViT-B\"], len(correlations[\"ViT-B\"]))\n",
    "\n",
    "fig.savefig(\n",
    "    f\"{metric_key1}_{metric_key2.replace('-euclidean', '')}.pdf\", bbox_inches=\"tight\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ZCuo294WiED8",
    "outputId": "9a7200e0-52e1-4444-b37b-958852e6d7d9"
   },
   "outputs": [],
   "source": [
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "MuURKU9mMXIN",
    "outputId": "72833c72-a908-43cd-a4f9-d0030733fb0d"
   },
   "outputs": [],
   "source": [
    "metric_key1 = \"AMI\"\n",
    "metric_key2 = \"silhouette-euclidean_pred\"\n",
    "BEST_PARAMS = BEST_PARAMS_v2\n",
    "\n",
    "CLUSTERERS = [\n",
    "    \"KMeans\",\n",
    "    \"AffinityPropagation\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"AgglomerativeClustering\",\n",
    "    \"HDBSCAN\",\n",
    "]\n",
    "print(MODEL2SH)\n",
    "\n",
    "figenc, axenc = plt.subplots(1, 2, figsize=(6, 2))\n",
    "figclus, axclus = plt.subplots(1, 2, figsize=(6, 2))\n",
    "\n",
    "for i_backbone, backbone in enumerate([\"ResNet-50\", \"ViT-B\"]):\n",
    "    result_table = np.zeros(\n",
    "        (5, len(CLUSTERERS), len(TEST_DATASETS))\n",
    "    )  # Encoders, clusteres, dataset\n",
    "    for dummy in [True, False]:\n",
    "        cmds = []\n",
    "\n",
    "        for i_group, model in enumerate(list(MODEL_GROUPS[backbone])):\n",
    "            first_agg = True\n",
    "            for i_clusters, clusterer in enumerate(CLUSTERERS):\n",
    "                clusterername = clusterer\n",
    "                if first_agg and clusterer == \"AgglomerativeClustering\":\n",
    "                    first_agg = False\n",
    "                    override_fields = {\"aggclust_dist_thresh\": None}\n",
    "                    clusterername = \"Agg  w/ C\"\n",
    "                elif clusterer == \"AgglomerativeClustering\":\n",
    "                    override_fields = {}\n",
    "                    clusterername = \"Agg w/o C\"\n",
    "\n",
    "                for i_dataset, dataset in enumerate(TEST_DATASETS):\n",
    "                    latex_table += \" &\"\n",
    "                    filter = {\n",
    "                        \"model\": model,\n",
    "                        \"dataset\": dataset,\n",
    "                        \"clusterer\": clusterer,\n",
    "                    }\n",
    "                    sdf = select_rows(test_runs_df, filter, allow_missing=False)\n",
    "                    filter2 = dict(\n",
    "                        DEFAULT_PARAMS[\"all\"], **BEST_PARAMS[clusterer][model]\n",
    "                    )\n",
    "                    filter2 = {k: v for k, v in filter2.items() if k not in filter}\n",
    "                    filter2.update(override_fields)\n",
    "                    sdf = select_rows(sdf, filter2, allow_missing=False)\n",
    "                    if len(sdf) < 1:\n",
    "                        cmds.append(filter2command(filter, filter2, partition=\"test\"))\n",
    "                        result_table[i_group, i_clusters, i_dataset] = -100.0\n",
    "                        continue\n",
    "                    result_table[i_group, i_clusters, i_dataset] = np.median(\n",
    "                        sdf[metric_key1]\n",
    "                    )\n",
    "\n",
    "    print(result_table[0])\n",
    "\n",
    "    print(backbone)\n",
    "    print(MODEL_GROUPS[backbone])\n",
    "    CLUSTERERS2 = [\"K-Means\", \"Affinity Prop\", \"Agg w/ C\", \"Agg w/o C\", \"HDBSCAN\"]\n",
    "    colors = [\"tab:blue\", \"tab:orange\", \"tab:red\", \"tab:green\", \"tab:olive\", \"tab:cyan\"]\n",
    "\n",
    "    encoder_to_color = {}\n",
    "    cluster_to_color = {\n",
    "        CLUSTERERS2[idx]: colors[idx] for idx in range(len(CLUSTERERS2))\n",
    "    }\n",
    "\n",
    "    for model in list(MODEL_GROUPS[backbone]):\n",
    "        if model == \"resnet50\" or model == \"vitb16\":\n",
    "            encoder_to_color[model] = colors[0]\n",
    "        if \"mae\" in model:\n",
    "            encoder_to_color[model] = colors[1]\n",
    "        if \"vicreg\" in model:\n",
    "            encoder_to_color[model] = colors[2]\n",
    "        if \"clip\" in model:\n",
    "            encoder_to_color[model] = colors[3]\n",
    "        if \"moco\" in model:\n",
    "            encoder_to_color[model] = colors[4]\n",
    "        if \"dino\" in model:\n",
    "            encoder_to_color[model] = colors[5]\n",
    "\n",
    "    print(encoder_to_color)\n",
    "    rank_tmp = np.asarray([1, 2, 3, 4, 5])\n",
    "    # RANK PER ENCODER - go through each dataset, look at each clusterer,\n",
    "    # and determine the rank of each encoder in that setting\n",
    "    print(list(MODEL_GROUPS[backbone]))\n",
    "    ranks_encoders = np.zeros((5, len(CLUSTERERS), len(TEST_DATASETS)))\n",
    "    for i_dataset in range(len(TEST_DATASETS)):\n",
    "        for i_clusters in range(len(CLUSTERERS)):\n",
    "            cluster_data = result_table[:, i_clusters, i_dataset]\n",
    "            rank = np.argsort(cluster_data)[::-1]\n",
    "            ranks_encoders[:, i_clusters, i_dataset] = rank_tmp[rank.argsort()]\n",
    "    mean_rank_encoders = np.mean(ranks_encoders, axis=(1, 2))\n",
    "    std_rank_encoders = np.std(ranks_encoders, axis=(1, 2))\n",
    "    order = [\n",
    "        (\n",
    "            list(MODEL_GROUPS[backbone])[idx],\n",
    "            mean_rank_encoders[idx],\n",
    "            std_rank_encoders[idx],\n",
    "        )\n",
    "        for idx in np.argsort(mean_rank_encoders)\n",
    "    ]\n",
    "\n",
    "    for idx, model in enumerate(order[::-1]):\n",
    "        axenc[i_backbone].barh(\n",
    "            idx,\n",
    "            model[1],\n",
    "            xerr=model[2],\n",
    "            align=\"center\",\n",
    "            alpha=0.6,\n",
    "            ecolor=\"black\",\n",
    "            color=encoder_to_color[model[0]],\n",
    "            capsize=2,\n",
    "            zorder=10,\n",
    "        )\n",
    "\n",
    "    axenc[i_backbone].set_yticks([])\n",
    "    axenc[i_backbone].set_yticklabels([])\n",
    "    axenc[i_backbone].set_xticks([1, 2, 3, 4, 5])\n",
    "    axenc[i_backbone].set_xticklabels([1, 2, 3, 4, 5])\n",
    "    axenc[i_backbone].xaxis.grid(True, zorder=1, alpha=0.5)\n",
    "    axenc[i_backbone].set_title(f\"{backbone}\")\n",
    "\n",
    "    # RANK PER CLUSTERER - go through each dataset, look at each encoder,\n",
    "    # and determine the rank of each clusterer in that setting\n",
    "\n",
    "    print(CLUSTERERS2)\n",
    "    ranks_clusterers = np.zeros((5, len(CLUSTERERS2), len(TEST_DATASETS)))\n",
    "    for i_dataset in range(len(TEST_DATASETS)):\n",
    "        for i_encoder in range(len(list(MODEL_GROUPS[backbone]))):\n",
    "            encoder_data = result_table[i_encoder, :, i_dataset]\n",
    "            rank = np.argsort(encoder_data)[::-1]\n",
    "            ranks_clusterers[i_encoder, :, i_dataset] = rank_tmp[rank.argsort()]\n",
    "    mean_rank_clusters = np.mean(ranks_clusterers, axis=(0, 2))\n",
    "    std_rank_clusters = np.std(ranks_clusterers, axis=(0, 2))\n",
    "    order = [\n",
    "        (CLUSTERERS2[idx], mean_rank_clusters[idx], std_rank_clusters[idx])\n",
    "        for idx in np.argsort(mean_rank_clusters)\n",
    "    ]\n",
    "\n",
    "    for idx, model in enumerate(order[::-1]):\n",
    "        axclus[i_backbone].barh(\n",
    "            idx,\n",
    "            model[1],\n",
    "            xerr=model[2],\n",
    "            align=\"center\",\n",
    "            alpha=0.6,\n",
    "            ecolor=\"black\",\n",
    "            color=cluster_to_color[model[0]],\n",
    "            capsize=2,\n",
    "            zorder=10,\n",
    "        )\n",
    "\n",
    "    axclus[i_backbone].set_yticks([])\n",
    "    axclus[i_backbone].set_yticklabels([])\n",
    "    axclus[i_backbone].set_xticks([1, 2, 3, 4, 5])\n",
    "    axclus[i_backbone].set_xticklabels([1, 2, 3, 4, 5])\n",
    "    axclus[i_backbone].xaxis.grid(True, zorder=1, alpha=0.5)\n",
    "    axclus[i_backbone].set_title(f\"{backbone}\")\n",
    "\n",
    "    axclus[i_backbone].set_xlabel(\"Rank\")\n",
    "    axenc[i_backbone].set_xlabel(\"Rank\")\n",
    "\n",
    "    print(order)\n",
    "\n",
    "\n",
    "encoder_to_color[\"vicreg_resnet50\"] = colors[2]\n",
    "\n",
    "label_fn = lambda c, ls: plt.plot([], [], color=c, ls=ls, linewidth=3)[0]  # noqa:E731\n",
    "handles_clus = [label_fn(cluster_to_color[idx], \"-\") for idx in CLUSTERERS2]\n",
    "handles_enc = [\n",
    "    label_fn(encoder_to_color[idx], \"-\")\n",
    "    for idx in list(MODEL_GROUPS[backbone]) + [\"vicreg_resnet50\"]\n",
    "]\n",
    "\n",
    "axenc[1].legend(\n",
    "    handles_enc,\n",
    "    [MODEL2SH[x] for x in list(MODEL_GROUPS[backbone]) + [\"vicreg_resnet50\"]],\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "axclus[1].legend(handles_clus, CLUSTERERS2, loc=\"center left\", bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "figenc.savefig(\"ranking_enc.pdf\", bbox_inches=\"tight\")\n",
    "figclus.savefig(\"ranking_clus.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4vS4LHHiHKCG"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
